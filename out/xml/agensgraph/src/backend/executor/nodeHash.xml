<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<unit xmlns="http://www.srcML.org/srcML/src" xmlns:cpp="http://www.srcML.org/srcML/cpp" revision="1.0.0" language="C" filename="/cloned_projects/agensgraph/src/backend/executor/nodeHash.c"><comment type="block">/*-------------------------------------------------------------------------
 *
 * nodeHash.c
 *	  Routines to hash relations for hashjoin
 *
 * Portions Copyright (c) 1996-2020, PostgreSQL Global Development Group
 * Portions Copyright (c) 1994, Regents of the University of California
 *
 *
 * IDENTIFICATION
 *	  src/backend/executor/nodeHash.c
 *
 * See note on parallelism in nodeHashjoin.c.
 *
 *-------------------------------------------------------------------------
 */</comment>
<comment type="block">/*
 * INTERFACE ROUTINES
 *		MultiExecHash	- generate an in-memory hash table of the relation
 *		ExecInitHash	- initialize node and subnodes
 *		ExecEndHash		- shutdown node and subnodes
 */</comment>

<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"postgres.h"</cpp:file></cpp:include>

<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>&lt;math.h&gt;</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>&lt;limits.h&gt;</cpp:file></cpp:include>

<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"access/htup_details.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"access/parallel.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"catalog/pg_statistic.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"commands/tablespace.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"executor/execdebug.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"executor/hashjoin.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"executor/nodeHash.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"executor/nodeHashjoin.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"miscadmin.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"pgstat.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"port/atomics.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"port/pg_bitutils.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"utils/dynahash.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"utils/guc.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"utils/lsyscache.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"utils/memutils.h"</cpp:file></cpp:include>
<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>"utils/syscache.h"</cpp:file></cpp:include>

<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecHashIncreaseNumBatches</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecHashIncreaseNumBuckets</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecParallelHashIncreaseNumBatches</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecParallelHashIncreaseNumBuckets</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecHashBuildSkewHash</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>Hash</name> <modifier>*</modifier></type><name>node</name></decl></parameter>,
								  <parameter><decl><type><name>int</name></type> <name>mcvsToUse</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecHashSkewTableInsert</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>,
									<parameter><decl><type><name>TupleTableSlot</name> <modifier>*</modifier></type><name>slot</name></decl></parameter>,
									<parameter><decl><type><name>uint32</name></type> <name>hashvalue</name></decl></parameter>,
									<parameter><decl><type><name>int</name></type> <name>bucketNumber</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecHashRemoveNextSkewBucket</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>;</function_decl>

<function_decl><type><specifier>static</specifier> <name>void</name> <modifier>*</modifier></type><name>dense_alloc</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>Size</name></type> <name>size</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>HashJoinTuple</name></type> <name>ExecParallelHashTupleAlloc</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>,
												<parameter><decl><type><name>size_t</name></type> <name>size</name></decl></parameter>,
												<parameter><decl><type><name>dsa_pointer</name> <modifier>*</modifier></type><name>shared</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>MultiExecPrivateHash</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>MultiExecParallelHash</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <specifier>inline</specifier> <name>HashJoinTuple</name></type> <name>ExecParallelHashFirstTuple</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>table</name></decl></parameter>,
													   <parameter><decl><type><name>int</name></type> <name>bucketno</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <specifier>inline</specifier> <name>HashJoinTuple</name></type> <name>ExecParallelHashNextTuple</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>table</name></decl></parameter>,
													  <parameter><decl><type><name>HashJoinTuple</name></type> <name>tuple</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <specifier>inline</specifier> <name>void</name></type> <name>ExecParallelHashPushTuple</name><parameter_list>(<parameter><decl><type><name>dsa_pointer_atomic</name> <modifier>*</modifier></type><name>head</name></decl></parameter>,
											 <parameter><decl><type><name>HashJoinTuple</name></type> <name>tuple</name></decl></parameter>,
											 <parameter><decl><type><name>dsa_pointer</name></type> <name>tuple_shared</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecParallelHashJoinSetUpBatches</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>int</name></type> <name>nbatch</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecParallelHashEnsureBatchAccessors</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecParallelHashRepartitionFirst</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecParallelHashRepartitionRest</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>HashMemoryChunk</name></type> <name>ExecParallelHashPopChunkQueue</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>table</name></decl></parameter>,
													 <parameter><decl><type><name>dsa_pointer</name> <modifier>*</modifier></type><name>shared</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>bool</name></type> <name>ExecParallelHashTuplePrealloc</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>,
										  <parameter><decl><type><name>int</name></type> <name>batchno</name></decl></parameter>,
										  <parameter><decl><type><name>size_t</name></type> <name>size</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecParallelHashMergeCounters</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>;</function_decl>
<function_decl><type><specifier>static</specifier> <name>void</name></type> <name>ExecParallelHashCloseBatchAccessors</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>;</function_decl>


<comment type="block">/* ----------------------------------------------------------------
 *		ExecHash
 *
 *		stub for pro forma compliance
 * ----------------------------------------------------------------
 */</comment>
<function><type><specifier>static</specifier> <name>TupleTableSlot</name> <modifier>*</modifier></type>
<name>ExecHash</name><parameter_list>(<parameter><decl><type><name>PlanState</name> <modifier>*</modifier></type><name>pstate</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<expr_stmt><expr><call><name>elog</name><argument_list>(<argument><expr><name>ERROR</name></expr></argument>, <argument><expr><literal type="string">"Hash node does not support ExecProcNode call convention"</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<return>return <expr><name>NULL</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/* ----------------------------------------------------------------
 *		MultiExecHash
 *
 *		build hash table for hashjoin, doing partitioning if more
 *		than one batch is required.
 * ----------------------------------------------------------------
 */</comment>
<function><type><name>Node</name> <modifier>*</modifier></type>
<name>MultiExecHash</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<comment type="block">/* must provide our own instrumentation support */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>instrument</name></name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>InstrStartNode</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>instrument</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>

	<if_stmt><if>if <condition>(<expr><name><name>node</name><operator>-&gt;</operator><name>parallel_state</name></name> <operator>!=</operator> <name>NULL</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>MultiExecParallelHash</name><argument_list>(<argument><expr><name>node</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if>
	<else>else<block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>MultiExecPrivateHash</name><argument_list>(<argument><expr><name>node</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></else></if_stmt>

	<comment type="block">/* must provide our own instrumentation support */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>instrument</name></name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>InstrStopNode</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>instrument</name></name></expr></argument>, <argument><expr><name><name>node</name><operator>-&gt;</operator><name>hashtable</name><operator>-&gt;</operator><name>partialTuples</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>

	<comment type="block">/*
	 * We do not return the hash table directly because it's not a subtype of
	 * Node, and so would violate the MultiExecProcNode API.  Instead, our
	 * parent Hashjoin node is expected to know how to fish it out of our node
	 * state.  Ugly but not really worth cleaning up, since Hashjoin knows
	 * quite a bit more about Hash besides that.
	 */</comment>
	<return>return <expr><name>NULL</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/* ----------------------------------------------------------------
 *		MultiExecPrivateHash
 *
 *		parallel-oblivious version, building a backend-private
 *		hash table and (if necessary) batch files.
 * ----------------------------------------------------------------
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>MultiExecPrivateHash</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>PlanState</name>  <modifier>*</modifier></type><name>outerNode</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>List</name>	   <modifier>*</modifier></type><name>hashkeys</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>TupleTableSlot</name> <modifier>*</modifier></type><name>slot</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>ExprContext</name> <modifier>*</modifier></type><name>econtext</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>uint32</name></type>		<name>hashvalue</name></decl>;</decl_stmt>

	<comment type="block">/*
	 * get state info from node
	 */</comment>
	<expr_stmt><expr><name>outerNode</name> <operator>=</operator> <call><name>outerPlanState</name><argument_list>(<argument><expr><name>node</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>hashtable</name> <operator>=</operator> <name><name>node</name><operator>-&gt;</operator><name>hashtable</name></name></expr>;</expr_stmt>

	<comment type="block">/*
	 * set expression context
	 */</comment>
	<expr_stmt><expr><name>hashkeys</name> <operator>=</operator> <name><name>node</name><operator>-&gt;</operator><name>hashkeys</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name>econtext</name> <operator>=</operator> <name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>ps_ExprContext</name></name></expr>;</expr_stmt>

	<comment type="block">/*
	 * Get all tuples from the node below the Hash node and insert into the
	 * hash table (or temp files).
	 */</comment>
	<for>for <control>(<init>;</init><condition>;</condition><incr/>)</control>
	<block>{<block_content>
		<expr_stmt><expr><name>slot</name> <operator>=</operator> <call><name>ExecProcNode</name><argument_list>(<argument><expr><name>outerNode</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<if_stmt><if>if <condition>(<expr><call><name>TupIsNull</name><argument_list>(<argument><expr><name>slot</name></expr></argument>)</argument_list></call></expr>)</condition><block type="pseudo"><block_content>
			<break>break;</break></block_content></block></if></if_stmt>
		<comment type="block">/* We have to compute the hash value */</comment>
		<expr_stmt><expr><name><name>econtext</name><operator>-&gt;</operator><name>ecxt_outertuple</name></name> <operator>=</operator> <name>slot</name></expr>;</expr_stmt>
		<if_stmt><if>if <condition>(<expr><call><name>ExecHashGetHashValue</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>econtext</name></expr></argument>, <argument><expr><name>hashkeys</name></expr></argument>,
								 <argument><expr><name>false</name></expr></argument>, <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>keepNulls</name></name></expr></argument>,
								 <argument><expr><operator>&amp;</operator><name>hashvalue</name></expr></argument>)</argument_list></call></expr>)</condition>
		<block>{<block_content>
			<decl_stmt><decl><type><name>int</name></type>			<name>bucketNumber</name></decl>;</decl_stmt>

			<expr_stmt><expr><name>bucketNumber</name> <operator>=</operator> <call><name>ExecHashGetSkewBucket</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>hashvalue</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<if_stmt><if>if <condition>(<expr><name>bucketNumber</name> <operator>!=</operator> <name>INVALID_SKEW_BUCKET_NO</name></expr>)</condition>
			<block>{<block_content>
				<comment type="block">/* It's a skew tuple, so put it into that hash table */</comment>
				<expr_stmt><expr><call><name>ExecHashSkewTableInsert</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>slot</name></expr></argument>, <argument><expr><name>hashvalue</name></expr></argument>,
										<argument><expr><name>bucketNumber</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewTuples</name></name> <operator>+=</operator> <literal type="number">1</literal></expr>;</expr_stmt>
			</block_content>}</block></if>
			<else>else
			<block>{<block_content>
				<comment type="block">/* Not subject to skew optimization, so insert normally */</comment>
				<expr_stmt><expr><call><name>ExecHashTableInsert</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>slot</name></expr></argument>, <argument><expr><name>hashvalue</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			</block_content>}</block></else></if_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>totalTuples</name></name> <operator>+=</operator> <literal type="number">1</literal></expr>;</expr_stmt>
		</block_content>}</block></if></if_stmt>
	</block_content>}</block></for>

	<comment type="block">/* resize the hash table if needed (NTUP_PER_BUCKET exceeded) */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>!=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>ExecHashIncreaseNumBuckets</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>

	<comment type="block">/* Account for the buckets in spaceUsed (reported in EXPLAIN ANALYZE) */</comment>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>+=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof></expr>;</expr_stmt>
	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>&gt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name></expr>;</expr_stmt></block_content></block></if></if_stmt>

	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>partialTuples</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>totalTuples</name></name></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/* ----------------------------------------------------------------
 *		MultiExecParallelHash
 *
 *		parallel-aware version, building a shared hash table and
 *		(if necessary) batch files using the combined effort of
 *		a set of co-operating backends.
 * ----------------------------------------------------------------
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>MultiExecParallelHash</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>PlanState</name>  <modifier>*</modifier></type><name>outerNode</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>List</name>	   <modifier>*</modifier></type><name>hashkeys</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>TupleTableSlot</name> <modifier>*</modifier></type><name>slot</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>ExprContext</name> <modifier>*</modifier></type><name>econtext</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>uint32</name></type>		<name>hashvalue</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>Barrier</name>    <modifier>*</modifier></type><name>build_barrier</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

	<comment type="block">/*
	 * get state info from node
	 */</comment>
	<expr_stmt><expr><name>outerNode</name> <operator>=</operator> <call><name>outerPlanState</name><argument_list>(<argument><expr><name>node</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>hashtable</name> <operator>=</operator> <name><name>node</name><operator>-&gt;</operator><name>hashtable</name></name></expr>;</expr_stmt>

	<comment type="block">/*
	 * set expression context
	 */</comment>
	<expr_stmt><expr><name>hashkeys</name> <operator>=</operator> <name><name>node</name><operator>-&gt;</operator><name>hashkeys</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name>econtext</name> <operator>=</operator> <name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>ps_ExprContext</name></name></expr>;</expr_stmt>

	<comment type="block">/*
	 * Synchronize the parallel hash table build.  At this stage we know that
	 * the shared hash table has been or is being set up by
	 * ExecHashTableCreate(), but we don't know if our peers have returned
	 * from there or are here in MultiExecParallelHash(), and if so how far
	 * through they are.  To find out, we check the build_barrier phase then
	 * and jump to the right step in the build algorithm.
	 */</comment>
	<expr_stmt><expr><name>pstate</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name>build_barrier</name> <operator>=</operator> <operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>build_barrier</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><name>build_barrier</name></expr></argument>)</argument_list></call> <operator>&gt;=</operator> <name>PHJ_BUILD_ALLOCATING</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<switch>switch <condition>(<expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><name>build_barrier</name></expr></argument>)</argument_list></call></expr>)</condition>
	<block>{<block_content>
		<case>case <expr><name>PHJ_BUILD_ALLOCATING</name></expr>:</case>

			<comment type="block">/*
			 * Either I just allocated the initial hash table in
			 * ExecHashTableCreate(), or someone else is doing that.  Either
			 * way, wait for everyone to arrive here so we can proceed.
			 */</comment>
			<expr_stmt><expr><call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><name>build_barrier</name></expr></argument>, <argument><expr><name>WAIT_EVENT_HASH_BUILD_ALLOCATE</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<comment type="block">/* Fall through. */</comment>

		<case>case <expr><name>PHJ_BUILD_HASHING_INNER</name></expr>:</case>

			<comment type="block">/*
			 * It's time to begin hashing, or if we just arrived here then
			 * hashing is already underway, so join in that effort.  While
			 * hashing we have to be prepared to help increase the number of
			 * batches or buckets at any time, and if we arrived here when
			 * that was already underway we'll have to help complete that work
			 * immediately so that it's safe to access batches and buckets
			 * below.
			 */</comment>
			<if_stmt><if>if <condition>(<expr><call><name>PHJ_GROW_BATCHES_PHASE</name><argument_list>(<argument><expr><call><name>BarrierAttach</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_batches_barrier</name></name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call> <operator>!=</operator>
				<name>PHJ_GROW_BATCHES_ELECTING</name></expr>)</condition><block type="pseudo"><block_content>
				<expr_stmt><expr><call><name>ExecParallelHashIncreaseNumBatches</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
			<if_stmt><if>if <condition>(<expr><call><name>PHJ_GROW_BUCKETS_PHASE</name><argument_list>(<argument><expr><call><name>BarrierAttach</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_buckets_barrier</name></name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call> <operator>!=</operator>
				<name>PHJ_GROW_BUCKETS_ELECTING</name></expr>)</condition><block type="pseudo"><block_content>
				<expr_stmt><expr><call><name>ExecParallelHashIncreaseNumBuckets</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
			<expr_stmt><expr><call><name>ExecParallelHashEnsureBatchAccessors</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>ExecParallelHashTableSetCurrentBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<for>for <control>(<init>;</init><condition>;</condition><incr/>)</control>
			<block>{<block_content>
				<expr_stmt><expr><name>slot</name> <operator>=</operator> <call><name>ExecProcNode</name><argument_list>(<argument><expr><name>outerNode</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<if_stmt><if>if <condition>(<expr><call><name>TupIsNull</name><argument_list>(<argument><expr><name>slot</name></expr></argument>)</argument_list></call></expr>)</condition><block type="pseudo"><block_content>
					<break>break;</break></block_content></block></if></if_stmt>
				<expr_stmt><expr><name><name>econtext</name><operator>-&gt;</operator><name>ecxt_outertuple</name></name> <operator>=</operator> <name>slot</name></expr>;</expr_stmt>
				<if_stmt><if>if <condition>(<expr><call><name>ExecHashGetHashValue</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>econtext</name></expr></argument>, <argument><expr><name>hashkeys</name></expr></argument>,
										 <argument><expr><name>false</name></expr></argument>, <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>keepNulls</name></name></expr></argument>,
										 <argument><expr><operator>&amp;</operator><name>hashvalue</name></expr></argument>)</argument_list></call></expr>)</condition><block type="pseudo"><block_content>
					<expr_stmt><expr><call><name>ExecParallelHashTableInsert</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>slot</name></expr></argument>, <argument><expr><name>hashvalue</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
				<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>partialTuples</name></name><operator>++</operator></expr>;</expr_stmt>
			</block_content>}</block></for>

			<comment type="block">/*
			 * Make sure that any tuples we wrote to disk are visible to
			 * others before anyone tries to load them.
			 */</comment>
			<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control><block type="pseudo"><block_content>
				<expr_stmt><expr><call><name>sts_end_write</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name><operator>.</operator><name>inner_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></for>

			<comment type="block">/*
			 * Update shared counters.  We need an accurate total tuple count
			 * to control the empty table optimization.
			 */</comment>
			<expr_stmt><expr><call><name>ExecParallelHashMergeCounters</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<expr_stmt><expr><call><name>BarrierDetach</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_buckets_barrier</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>BarrierDetach</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_batches_barrier</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<comment type="block">/*
			 * Wait for everyone to finish building and flushing files and
			 * counters.
			 */</comment>
			<if_stmt><if>if <condition>(<expr><call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><name>build_barrier</name></expr></argument>,
									 <argument><expr><name>WAIT_EVENT_HASH_BUILD_HASH_INNER</name></expr></argument>)</argument_list></call></expr>)</condition>
			<block>{<block_content>
				<comment type="block">/*
				 * Elect one backend to disable any further growth.  Batches
				 * are now fixed.  While building them we made sure they'd fit
				 * in our memory budget when we load them back in later (or we
				 * tried to do that and gave up because we detected extreme
				 * skew).
				 */</comment>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>=</operator> <name>PHJ_GROWTH_DISABLED</name></expr>;</expr_stmt>
			</block_content>}</block></if></if_stmt>
	</block_content>}</block></switch>

	<comment type="block">/*
	 * We're not yet attached to a batch.  We all agree on the dimensions and
	 * number of inner tuples (for the empty table optimization).
	 */</comment>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name> <operator>=</operator> <operator>-</operator><literal type="number">1</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>=</operator> <name><name>pstate</name><operator>-&gt;</operator><name>nbuckets</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>log2_nbuckets</name></name> <operator>=</operator> <call><name>my_log2</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>totalTuples</name></name> <operator>=</operator> <name><name>pstate</name><operator>-&gt;</operator><name>total_tuples</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>ExecParallelHashEnsureBatchAccessors</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * The next synchronization point is in ExecHashJoin's HJ_BUILD_HASHTABLE
	 * case, which will bring the build phase to PHJ_BUILD_DONE (if it isn't
	 * there already).
	 */</comment>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><name>build_barrier</name></expr></argument>)</argument_list></call> <operator>==</operator> <name>PHJ_BUILD_HASHING_OUTER</name> <operator>||</operator>
		   <call><name>BarrierPhase</name><argument_list>(<argument><expr><name>build_barrier</name></expr></argument>)</argument_list></call> <operator>==</operator> <name>PHJ_BUILD_DONE</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/* ----------------------------------------------------------------
 *		ExecInitHash
 *
 *		Init routine for Hash node
 * ----------------------------------------------------------------
 */</comment>
<function><type><name>HashState</name> <modifier>*</modifier></type>
<name>ExecInitHash</name><parameter_list>(<parameter><decl><type><name>Hash</name> <modifier>*</modifier></type><name>node</name></decl></parameter>, <parameter><decl><type><name>EState</name> <modifier>*</modifier></type><name>estate</name></decl></parameter>, <parameter><decl><type><name>int</name></type> <name>eflags</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>HashState</name>  <modifier>*</modifier></type><name>hashstate</name></decl>;</decl_stmt>

	<comment type="block">/* check for unsupported flags */</comment>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><operator>!</operator><operator>(</operator><name>eflags</name> <operator>&amp;</operator> <operator>(</operator><name>EXEC_FLAG_BACKWARD</name> <operator>|</operator> <name>EXEC_FLAG_MARK</name><operator>)</operator><operator>)</operator></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * create state structure
	 */</comment>
	<expr_stmt><expr><name>hashstate</name> <operator>=</operator> <call><name>makeNode</name><argument_list>(<argument><expr><name>HashState</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashstate</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>plan</name></name> <operator>=</operator> <operator>(</operator><name>Plan</name> <operator>*</operator><operator>)</operator> <name>node</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashstate</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>state</name></name> <operator>=</operator> <name>estate</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashstate</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>ExecProcNode</name></name> <operator>=</operator> <name>ExecHash</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashstate</name><operator>-&gt;</operator><name>hashtable</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashstate</name><operator>-&gt;</operator><name>hashkeys</name></name> <operator>=</operator> <name>NIL</name></expr>;</expr_stmt>	<comment type="block">/* will be set by parent HashJoin */</comment>

	<comment type="block">/*
	 * Miscellaneous initialization
	 *
	 * create expression context for node
	 */</comment>
	<expr_stmt><expr><call><name>ExecAssignExprContext</name><argument_list>(<argument><expr><name>estate</name></expr></argument>, <argument><expr><operator>&amp;</operator><name><name>hashstate</name><operator>-&gt;</operator><name>ps</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * initialize child nodes
	 */</comment>
	<expr_stmt><expr><call><name>outerPlanState</name><argument_list>(<argument><expr><name>hashstate</name></expr></argument>)</argument_list></call> <operator>=</operator> <call><name>ExecInitNode</name><argument_list>(<argument><expr><call><name>outerPlan</name><argument_list>(<argument><expr><name>node</name></expr></argument>)</argument_list></call></expr></argument>, <argument><expr><name>estate</name></expr></argument>, <argument><expr><name>eflags</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * initialize our result slot and type. No need to build projection
	 * because this node doesn't do projections.
	 */</comment>
	<expr_stmt><expr><call><name>ExecInitResultTupleSlotTL</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>hashstate</name><operator>-&gt;</operator><name>ps</name></name></expr></argument>, <argument><expr><operator>&amp;</operator><name>TTSOpsMinimalTuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashstate</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>ps_ProjInfo</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>

	<comment type="block">/*
	 * initialize child expressions
	 */</comment>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>plan</name><operator>.</operator><name>qual</name></name> <operator>==</operator> <name>NIL</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashstate</name><operator>-&gt;</operator><name>hashkeys</name></name> <operator>=</operator>
		<call><name>ExecInitExprList</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>hashkeys</name></name></expr></argument>, <argument><expr><operator>(</operator><name>PlanState</name> <operator>*</operator><operator>)</operator> <name>hashstate</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<return>return <expr><name>hashstate</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/* ---------------------------------------------------------------
 *		ExecEndHash
 *
 *		clean up routine for Hash node
 * ----------------------------------------------------------------
 */</comment>
<function><type><name>void</name></type>
<name>ExecEndHash</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>PlanState</name>  <modifier>*</modifier></type><name>outerPlan</name></decl>;</decl_stmt>

	<comment type="block">/*
	 * free exprcontext
	 */</comment>
	<expr_stmt><expr><call><name>ExecFreeExprContext</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>node</name><operator>-&gt;</operator><name>ps</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * shut down the subplan
	 */</comment>
	<expr_stmt><expr><name>outerPlan</name> <operator>=</operator> <call><name>outerPlanState</name><argument_list>(<argument><expr><name>node</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>ExecEndNode</name><argument_list>(<argument><expr><name>outerPlan</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>


<comment type="block">/* ----------------------------------------------------------------
 *		ExecHashTableCreate
 *
 *		create an empty hashtable data structure for hashjoin.
 * ----------------------------------------------------------------
 */</comment>
<function><type><name>HashJoinTable</name></type>
<name>ExecHashTableCreate</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>state</name></decl></parameter>, <parameter><decl><type><name>List</name> <modifier>*</modifier></type><name>hashOperators</name></decl></parameter>, <parameter><decl><type><name>List</name> <modifier>*</modifier></type><name>hashCollations</name></decl></parameter>, <parameter><decl><type><name>bool</name></type> <name>keepNulls</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>Hash</name>	   <modifier>*</modifier></type><name>node</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>Plan</name>	   <modifier>*</modifier></type><name>outerNode</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>size_t</name></type>		<name>space_allowed</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>nbuckets</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>nbatch</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>double</name></type>		<name>rows</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>num_skew_mcvs</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>log2_nbuckets</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>nkeys</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>ListCell</name>   <modifier>*</modifier></type><name>ho</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>ListCell</name>   <modifier>*</modifier></type><name>hc</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>MemoryContext</name></type> <name>oldcxt</name></decl>;</decl_stmt>

	<comment type="block">/*
	 * Get information about the size of the relation to be hashed (it's the
	 * "outer" subtree of this node, but the inner relation of the hashjoin).
	 * Compute the appropriate size of the hash table.
	 */</comment>
	<expr_stmt><expr><name>node</name> <operator>=</operator> <operator>(</operator><name>Hash</name> <operator>*</operator><operator>)</operator> <name><name>state</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>plan</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name>outerNode</name> <operator>=</operator> <call><name>outerPlan</name><argument_list>(<argument><expr><name>node</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * If this is shared hash table with a partial plan, then we can't use
	 * outerNode-&gt;plan_rows to estimate its size.  We need an estimate of the
	 * total number of rows across all copies of the partial plan.
	 */</comment>
	<expr_stmt><expr><name>rows</name> <operator>=</operator> <ternary><condition><expr><name><name>node</name><operator>-&gt;</operator><name>plan</name><operator>.</operator><name>parallel_aware</name></name></expr> ?</condition><then> <expr><name><name>node</name><operator>-&gt;</operator><name>rows_total</name></name></expr> </then><else>: <expr><name><name>outerNode</name><operator>-&gt;</operator><name>plan_rows</name></name></expr></else></ternary></expr>;</expr_stmt>

	<expr_stmt><expr><call><name>ExecChooseHashTableSize</name><argument_list>(<argument><expr><name>rows</name></expr></argument>, <argument><expr><name><name>outerNode</name><operator>-&gt;</operator><name>plan_width</name></name></expr></argument>,
							<argument><expr><call><name>OidIsValid</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>skewTable</name></name></expr></argument>)</argument_list></call></expr></argument>,
							<argument><expr><name><name>state</name><operator>-&gt;</operator><name>parallel_state</name></name> <operator>!=</operator> <name>NULL</name></expr></argument>,
							<argument><expr><ternary><condition><expr><name><name>state</name><operator>-&gt;</operator><name>parallel_state</name></name> <operator>!=</operator> <name>NULL</name></expr> ?</condition><then>
							<expr><name><name>state</name><operator>-&gt;</operator><name>parallel_state</name><operator>-&gt;</operator><name>nparticipants</name></name> <operator>-</operator> <literal type="number">1</literal></expr> </then><else>: <expr><literal type="number">0</literal></expr></else></ternary></expr></argument>,
							<argument><expr><operator>&amp;</operator><name>space_allowed</name></expr></argument>,
							<argument><expr><operator>&amp;</operator><name>nbuckets</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>nbatch</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>num_skew_mcvs</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* nbuckets must be a power of 2 */</comment>
	<expr_stmt><expr><name>log2_nbuckets</name> <operator>=</operator> <call><name>my_log2</name><argument_list>(<argument><expr><name>nbuckets</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>nbuckets</name> <operator>==</operator> <operator>(</operator><literal type="number">1</literal> <operator>&lt;&lt;</operator> <name>log2_nbuckets</name><operator>)</operator></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * Initialize the hash table control block.
	 *
	 * The hashtable control block is just palloc'd from the executor's
	 * per-query memory context.  Everything else should be kept inside the
	 * subsidiary hashCxt or batchCxt.
	 */</comment>
	<expr_stmt><expr><name>hashtable</name> <operator>=</operator> <operator>(</operator><name>HashJoinTable</name><operator>)</operator> <call><name>palloc</name><argument_list>(<argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTableData</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>=</operator> <name>nbuckets</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_original</name></name> <operator>=</operator> <name>nbuckets</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name> <operator>=</operator> <name>nbuckets</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>log2_nbuckets</name></name> <operator>=</operator> <name>log2_nbuckets</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>log2_nbuckets_optimal</name></name> <operator>=</operator> <name>log2_nbuckets</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>keepNulls</name></name> <operator>=</operator> <name>keepNulls</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewEnabled</name></name> <operator>=</operator> <name>false</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketLen</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nSkewBuckets</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketNums</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>=</operator> <name>nbatch</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch_original</name></name> <operator>=</operator> <name>nbatch</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch_outstart</name></name> <operator>=</operator> <name>nbatch</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>growEnabled</name></name> <operator>=</operator> <name>true</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>totalTuples</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>partialTuples</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewTuples</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>outerBatchFile</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceAllowed</name></name> <operator>=</operator> <name>space_allowed</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsedSkew</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceAllowedSkew</name></name> <operator>=</operator>
		<name><name>hashtable</name><operator>-&gt;</operator><name>spaceAllowed</name></name> <operator>*</operator> <name>SKEW_HASH_MEM_PERCENT</name> <operator>/</operator> <literal type="number">100</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>current_chunk</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name> <operator>=</operator> <name><name>state</name><operator>-&gt;</operator><name>parallel_state</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name> <operator>=</operator> <name><name>state</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>state</name><operator>-&gt;</operator><name>es_query_dsa</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>

<cpp:ifdef>#<cpp:directive>ifdef</cpp:directive> <name>HJDEBUG</name></cpp:ifdef>
	<expr_stmt><expr><call><name>printf</name><argument_list>(<argument><expr><literal type="string">"Hashjoin %p: initial nbatch = %d, nbuckets = %d\n"</literal></expr></argument>,
		   <argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>nbatch</name></expr></argument>, <argument><expr><name>nbuckets</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
<cpp:endif>#<cpp:directive>endif</cpp:directive></cpp:endif>

	<comment type="block">/*
	 * Create temporary memory contexts in which to keep the hashtable working
	 * storage.  See notes in executor/hashjoin.h.
	 */</comment>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>hashCxt</name></name> <operator>=</operator> <call><name>AllocSetContextCreate</name><argument_list>(<argument><expr><name>CurrentMemoryContext</name></expr></argument>,
											   <argument><expr><literal type="string">"HashTableContext"</literal></expr></argument>,
											   <argument><expr><name>ALLOCSET_DEFAULT_SIZES</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batchCxt</name></name> <operator>=</operator> <call><name>AllocSetContextCreate</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>hashCxt</name></name></expr></argument>,
												<argument><expr><literal type="string">"HashBatchContext"</literal></expr></argument>,
												<argument><expr><name>ALLOCSET_DEFAULT_SIZES</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Allocate data that will live for the life of the hashjoin */</comment>

	<expr_stmt><expr><name>oldcxt</name> <operator>=</operator> <call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>hashCxt</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * Get info about the hash functions to be used for each hash key. Also
	 * remember whether the join operators are strict.
	 */</comment>
	<expr_stmt><expr><name>nkeys</name> <operator>=</operator> <call><name>list_length</name><argument_list>(<argument><expr><name>hashOperators</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>outer_hashfunctions</name></name> <operator>=</operator>
		<operator>(</operator><name>FmgrInfo</name> <operator>*</operator><operator>)</operator> <call><name>palloc</name><argument_list>(<argument><expr><name>nkeys</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>FmgrInfo</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>inner_hashfunctions</name></name> <operator>=</operator>
		<operator>(</operator><name>FmgrInfo</name> <operator>*</operator><operator>)</operator> <call><name>palloc</name><argument_list>(<argument><expr><name>nkeys</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>FmgrInfo</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>hashStrict</name></name> <operator>=</operator> <operator>(</operator><name>bool</name> <operator>*</operator><operator>)</operator> <call><name>palloc</name><argument_list>(<argument><expr><name>nkeys</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>bool</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>collations</name></name> <operator>=</operator> <operator>(</operator><name>Oid</name> <operator>*</operator><operator>)</operator> <call><name>palloc</name><argument_list>(<argument><expr><name>nkeys</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>Oid</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<macro><name>forboth</name><argument_list>(<argument>ho</argument>, <argument>hashOperators</argument>, <argument>hc</argument>, <argument>hashCollations</argument>)</argument_list></macro>
	<block>{<block_content>
		<decl_stmt><decl><type><name>Oid</name></type>			<name>hashop</name> <init>= <expr><call><name>lfirst_oid</name><argument_list>(<argument><expr><name>ho</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>Oid</name></type>			<name>left_hashfn</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>Oid</name></type>			<name>right_hashfn</name></decl>;</decl_stmt>

		<if_stmt><if>if <condition>(<expr><operator>!</operator><call><name>get_op_hash_functions</name><argument_list>(<argument><expr><name>hashop</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>left_hashfn</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>right_hashfn</name></expr></argument>)</argument_list></call></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><call><name>elog</name><argument_list>(<argument><expr><name>ERROR</name></expr></argument>, <argument><expr><literal type="string">"could not find hash function for hash operator %u"</literal></expr></argument>,
				 <argument><expr><name>hashop</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
		<expr_stmt><expr><call><name>fmgr_info</name><argument_list>(<argument><expr><name>left_hashfn</name></expr></argument>, <argument><expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>outer_hashfunctions</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>fmgr_info</name><argument_list>(<argument><expr><name>right_hashfn</name></expr></argument>, <argument><expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>inner_hashfunctions</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>hashStrict</name><index>[<expr><name>i</name></expr>]</index></name> <operator>=</operator> <call><name>op_strict</name><argument_list>(<argument><expr><name>hashop</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>collations</name><index>[<expr><name>i</name></expr>]</index></name> <operator>=</operator> <call><name>lfirst_oid</name><argument_list>(<argument><expr><name>hc</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name>i</name><operator>++</operator></expr>;</expr_stmt>
	</block_content>}</block>

	<if_stmt><if>if <condition>(<expr><name>nbatch</name> <operator>&gt;</operator> <literal type="number">1</literal> <operator>&amp;&amp;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name> <operator>==</operator> <name>NULL</name></expr>)</condition>
	<block>{<block_content>
		<comment type="block">/*
		 * allocate and initialize the file arrays in hashCxt (not needed for
		 * parallel case which uses shared tuplestores instead of raw files)
		 */</comment>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name></name> <operator>=</operator> <operator>(</operator><name>BufFile</name> <operator>*</operator><operator>*</operator><operator>)</operator>
			<call><name>palloc0</name><argument_list>(<argument><expr><name>nbatch</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>BufFile</name> <operator>*</operator></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>outerBatchFile</name></name> <operator>=</operator> <operator>(</operator><name>BufFile</name> <operator>*</operator><operator>*</operator><operator>)</operator>
			<call><name>palloc0</name><argument_list>(<argument><expr><name>nbatch</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>BufFile</name> <operator>*</operator></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<comment type="block">/* The files will not be opened until needed... */</comment>
		<comment type="block">/* ... but make sure we have temp tablespaces established for them */</comment>
		<expr_stmt><expr><call><name>PrepareTempTablespaces</name><argument_list>()</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></if></if_stmt>

	<expr_stmt><expr><call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name>oldcxt</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr>)</condition>
	<block>{<block_content>
		<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></init></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>Barrier</name>    <modifier>*</modifier></type><name>build_barrier</name></decl>;</decl_stmt>

		<comment type="block">/*
		 * Attach to the build barrier.  The corresponding detach operation is
		 * in ExecHashTableDetach.  Note that we won't attach to the
		 * batch_barrier for batch 0 yet.  We'll attach later and start it out
		 * in PHJ_BATCH_PROBING phase, because batch 0 is allocated up front
		 * and then loaded while hashing (the standard hybrid hash join
		 * algorithm), and we'll coordinate that using build_barrier.
		 */</comment>
		<expr_stmt><expr><name>build_barrier</name> <operator>=</operator> <operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>build_barrier</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>BarrierAttach</name><argument_list>(<argument><expr><name>build_barrier</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/*
		 * So far we have no idea whether there are any other participants,
		 * and if so, what phase they are working on.  The only thing we care
		 * about at this point is whether someone has already created the
		 * SharedHashJoinBatch objects and the hash table for batch 0.  One
		 * backend will be elected to do that now if necessary.
		 */</comment>
		<if_stmt><if>if <condition>(<expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><name>build_barrier</name></expr></argument>)</argument_list></call> <operator>==</operator> <name>PHJ_BUILD_ELECTING</name> <operator>&amp;&amp;</operator>
			<call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><name>build_barrier</name></expr></argument>, <argument><expr><name>WAIT_EVENT_HASH_BUILD_ELECT</name></expr></argument>)</argument_list></call></expr>)</condition>
		<block>{<block_content>
			<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>=</operator> <name>nbatch</name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>space_allowed</name></name> <operator>=</operator> <name>space_allowed</name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>=</operator> <name>PHJ_GROWTH_OK</name></expr>;</expr_stmt>

			<comment type="block">/* Set up the shared state for coordinating batches. */</comment>
			<expr_stmt><expr><call><name>ExecParallelHashJoinSetUpBatches</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>nbatch</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<comment type="block">/*
			 * Allocate batch 0's hash table up front so we can load it
			 * directly while hashing.
			 */</comment>
			<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>=</operator> <name>nbuckets</name></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>ExecParallelHashTableAlloc</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		</block_content>}</block></if></if_stmt>

		<comment type="block">/*
		 * The next Parallel Hash synchronization point is in
		 * MultiExecParallelHash(), which will progress it all the way to
		 * PHJ_BUILD_DONE.  The caller must not return control from this
		 * executor node between now and then.
		 */</comment>
	</block_content>}</block></if>
	<else>else
	<block>{<block_content>
		<comment type="block">/*
		 * Prepare context for the first-scan space allocations; allocate the
		 * hashbucket array therein, and set each bucket "empty".
		 */</comment>
		<expr_stmt><expr><call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batchCxt</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name></name> <operator>=</operator> <operator>(</operator><name>HashJoinTuple</name> <operator>*</operator><operator>)</operator>
			<call><name>palloc0</name><argument_list>(<argument><expr><name>nbuckets</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/*
		 * Set up for skew optimization, if possible and there's a need for
		 * more than one batch.  (In a one-batch join, there's no point in
		 * it.)
		 */</comment>
		<if_stmt><if>if <condition>(<expr><name>nbatch</name> <operator>&gt;</operator> <literal type="number">1</literal></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><call><name>ExecHashBuildSkewHash</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>node</name></expr></argument>, <argument><expr><name>num_skew_mcvs</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>

		<expr_stmt><expr><call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name>oldcxt</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></else></if_stmt>

	<return>return <expr><name>hashtable</name></expr>;</return>
</block_content>}</block></function>


<comment type="block">/*
 * Compute appropriate size for hashtable given the estimated size of the
 * relation to be hashed (number of rows and average row width).
 *
 * This is exported so that the planner's costsize.c can use it.
 */</comment>

<comment type="block">/* Target bucket loading (tuples per bucket) */</comment>
<cpp:define>#<cpp:directive>define</cpp:directive> <cpp:macro><name>NTUP_PER_BUCKET</name></cpp:macro>			<cpp:value>1</cpp:value></cpp:define>

<function><type><name>void</name></type>
<name>ExecChooseHashTableSize</name><parameter_list>(<parameter><decl><type><name>double</name></type> <name>ntuples</name></decl></parameter>, <parameter><decl><type><name>int</name></type> <name>tupwidth</name></decl></parameter>, <parameter><decl><type><name>bool</name></type> <name>useskew</name></decl></parameter>,
						<parameter><decl><type><name>bool</name></type> <name>try_combined_hash_mem</name></decl></parameter>,
						<parameter><decl><type><name>int</name></type> <name>parallel_workers</name></decl></parameter>,
						<parameter><decl><type><name>size_t</name> <modifier>*</modifier></type><name>space_allowed</name></decl></parameter>,
						<parameter><decl><type><name>int</name> <modifier>*</modifier></type><name>numbuckets</name></decl></parameter>,
						<parameter><decl><type><name>int</name> <modifier>*</modifier></type><name>numbatches</name></decl></parameter>,
						<parameter><decl><type><name>int</name> <modifier>*</modifier></type><name>num_skew_mcvs</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>int</name></type>			<name>tupsize</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>double</name></type>		<name>inner_rel_bytes</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>size_t</name></type>		<name>hash_table_bytes</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>size_t</name></type>		<name>bucket_bytes</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>size_t</name></type>		<name>max_pointers</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>nbatch</name> <init>= <expr><literal type="number">1</literal></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>nbuckets</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>double</name></type>		<name>dbuckets</name></decl>;</decl_stmt>

	<comment type="block">/* Force a plausible relation size if no info */</comment>
	<if_stmt><if>if <condition>(<expr><name>ntuples</name> <operator>&lt;=</operator> <literal type="number">0.0</literal></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><name>ntuples</name> <operator>=</operator> <literal type="number">1000.0</literal></expr>;</expr_stmt></block_content></block></if></if_stmt>

	<comment type="block">/*
	 * Estimate tupsize based on footprint of tuple in hashtable... note this
	 * does not allow for any palloc overhead.  The manipulations of spaceUsed
	 * don't count palloc overhead either.
	 */</comment>
	<expr_stmt><expr><name>tupsize</name> <operator>=</operator> <name>HJTUPLE_OVERHEAD</name> <operator>+</operator>
		<call><name>MAXALIGN</name><argument_list>(<argument><expr><name>SizeofMinimalTupleHeader</name></expr></argument>)</argument_list></call> <operator>+</operator>
		<call><name>MAXALIGN</name><argument_list>(<argument><expr><name>tupwidth</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>inner_rel_bytes</name> <operator>=</operator> <name>ntuples</name> <operator>*</operator> <name>tupsize</name></expr>;</expr_stmt>

	<comment type="block">/*
	 * Compute in-memory hashtable size limit from GUCs.
	 */</comment>
	<expr_stmt><expr><name>hash_table_bytes</name> <operator>=</operator> <call><name>get_hash_memory_limit</name><argument_list>()</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * Parallel Hash tries to use the combined hash_mem of all workers to
	 * avoid the need to batch.  If that won't work, it falls back to hash_mem
	 * per worker and tries to process batches in parallel.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name>try_combined_hash_mem</name></expr>)</condition>
	<block>{<block_content>
		<comment type="block">/* Careful, this could overflow size_t */</comment>
		<decl_stmt><decl><type><name>double</name></type>		<name>newlimit</name></decl>;</decl_stmt>

		<expr_stmt><expr><name>newlimit</name> <operator>=</operator> <operator>(</operator><name>double</name><operator>)</operator> <name>hash_table_bytes</name> <operator>*</operator> <operator>(</operator><name>double</name><operator>)</operator> <operator>(</operator><name>parallel_workers</name> <operator>+</operator> <literal type="number">1</literal><operator>)</operator></expr>;</expr_stmt>
		<expr_stmt><expr><name>newlimit</name> <operator>=</operator> <call><name>Min</name><argument_list>(<argument><expr><name>newlimit</name></expr></argument>, <argument><expr><operator>(</operator><name>double</name><operator>)</operator> <name>SIZE_MAX</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name>hash_table_bytes</name> <operator>=</operator> <operator>(</operator><name>size_t</name><operator>)</operator> <name>newlimit</name></expr>;</expr_stmt>
	</block_content>}</block></if></if_stmt>

	<expr_stmt><expr><operator>*</operator><name>space_allowed</name> <operator>=</operator> <name>hash_table_bytes</name></expr>;</expr_stmt>

	<comment type="block">/*
	 * If skew optimization is possible, estimate the number of skew buckets
	 * that will fit in the memory allowed, and decrement the assumed space
	 * available for the main hash table accordingly.
	 *
	 * We make the optimistic assumption that each skew bucket will contain
	 * one inner-relation tuple.  If that turns out to be low, we will recover
	 * at runtime by reducing the number of skew buckets.
	 *
	 * hashtable-&gt;skewBucket will have up to 8 times as many HashSkewBucket
	 * pointers as the number of MCVs we allow, since ExecHashBuildSkewHash
	 * will round up to the next power of 2 and then multiply by 4 to reduce
	 * collisions.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name>useskew</name></expr>)</condition>
	<block>{<block_content>
		<decl_stmt><decl><type><name>size_t</name></type>		<name>bytes_per_mcv</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>size_t</name></type>		<name>skew_mcvs</name></decl>;</decl_stmt>

		<comment type="block">/*----------
		 * Compute number of MCVs we could hold in hash_table_bytes
		 *
		 * Divisor is:
		 * size of a hash tuple +
		 * worst-case size of skewBucket[] per MCV +
		 * size of skewBucketNums[] entry +
		 * size of skew bucket struct itself
		 *----------
		 */</comment>
		<expr_stmt><expr><name>bytes_per_mcv</name> <operator>=</operator> <name>tupsize</name> <operator>+</operator>
			<operator>(</operator><literal type="number">8</literal> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashSkewBucket</name> <operator>*</operator></expr></argument>)</argument_list></sizeof><operator>)</operator> <operator>+</operator>
			<sizeof>sizeof<argument_list>(<argument><expr><name>int</name></expr></argument>)</argument_list></sizeof> <operator>+</operator>
			<name>SKEW_BUCKET_OVERHEAD</name></expr>;</expr_stmt>
		<expr_stmt><expr><name>skew_mcvs</name> <operator>=</operator> <name>hash_table_bytes</name> <operator>/</operator> <name>bytes_per_mcv</name></expr>;</expr_stmt>

		<comment type="block">/*
		 * Now scale by SKEW_HASH_MEM_PERCENT (we do it in this order so as
		 * not to worry about size_t overflow in the multiplication)
		 */</comment>
		<expr_stmt><expr><name>skew_mcvs</name> <operator>=</operator> <operator>(</operator><name>skew_mcvs</name> <operator>*</operator> <name>SKEW_HASH_MEM_PERCENT</name><operator>)</operator> <operator>/</operator> <literal type="number">100</literal></expr>;</expr_stmt>

		<comment type="block">/* Now clamp to integer range */</comment>
		<expr_stmt><expr><name>skew_mcvs</name> <operator>=</operator> <call><name>Min</name><argument_list>(<argument><expr><name>skew_mcvs</name></expr></argument>, <argument><expr><name>INT_MAX</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<expr_stmt><expr><operator>*</operator><name>num_skew_mcvs</name> <operator>=</operator> <operator>(</operator><name>int</name><operator>)</operator> <name>skew_mcvs</name></expr>;</expr_stmt>

		<comment type="block">/* Reduce hash_table_bytes by the amount needed for the skew table */</comment>
		<if_stmt><if>if <condition>(<expr><name>skew_mcvs</name> <operator>&gt;</operator> <literal type="number">0</literal></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><name>hash_table_bytes</name> <operator>-=</operator> <name>skew_mcvs</name> <operator>*</operator> <name>bytes_per_mcv</name></expr>;</expr_stmt></block_content></block></if></if_stmt>
	</block_content>}</block></if>
	<else>else<block type="pseudo"><block_content>
		<expr_stmt><expr><operator>*</operator><name>num_skew_mcvs</name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt></block_content></block></else></if_stmt>

	<comment type="block">/*
	 * Set nbuckets to achieve an average bucket load of NTUP_PER_BUCKET when
	 * memory is filled, assuming a single batch; but limit the value so that
	 * the pointer arrays we'll try to allocate do not exceed hash_table_bytes
	 * nor MaxAllocSize.
	 *
	 * Note that both nbuckets and nbatch must be powers of 2 to make
	 * ExecHashGetBucketAndBatch fast.
	 */</comment>
	<expr_stmt><expr><name>max_pointers</name> <operator>=</operator> <name>hash_table_bytes</name> <operator>/</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof></expr>;</expr_stmt>
	<expr_stmt><expr><name>max_pointers</name> <operator>=</operator> <call><name>Min</name><argument_list>(<argument><expr><name>max_pointers</name></expr></argument>, <argument><expr><name>MaxAllocSize</name> <operator>/</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<comment type="block">/* If max_pointers isn't a power of 2, must round it down to one */</comment>
	<expr_stmt><expr><name>max_pointers</name> <operator>=</operator> <call><name>pg_prevpower2_size_t</name><argument_list>(<argument><expr><name>max_pointers</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Also ensure we avoid integer overflow in nbatch and nbuckets */</comment>
	<comment type="block">/* (this step is redundant given the current value of MaxAllocSize) */</comment>
	<expr_stmt><expr><name>max_pointers</name> <operator>=</operator> <call><name>Min</name><argument_list>(<argument><expr><name>max_pointers</name></expr></argument>, <argument><expr><name>INT_MAX</name> <operator>/</operator> <literal type="number">2</literal> <operator>+</operator> <literal type="number">1</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><name>dbuckets</name> <operator>=</operator> <call><name>ceil</name><argument_list>(<argument><expr><name>ntuples</name> <operator>/</operator> <name>NTUP_PER_BUCKET</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>dbuckets</name> <operator>=</operator> <call><name>Min</name><argument_list>(<argument><expr><name>dbuckets</name></expr></argument>, <argument><expr><name>max_pointers</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>nbuckets</name> <operator>=</operator> <operator>(</operator><name>int</name><operator>)</operator> <name>dbuckets</name></expr>;</expr_stmt>
	<comment type="block">/* don't let nbuckets be really small, though ... */</comment>
	<expr_stmt><expr><name>nbuckets</name> <operator>=</operator> <call><name>Max</name><argument_list>(<argument><expr><name>nbuckets</name></expr></argument>, <argument><expr><literal type="number">1024</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<comment type="block">/* ... and force it to be a power of 2. */</comment>
	<expr_stmt><expr><name>nbuckets</name> <operator>=</operator> <call><name>pg_nextpower2_32</name><argument_list>(<argument><expr><name>nbuckets</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * If there's not enough space to store the projected number of tuples and
	 * the required bucket headers, we will need multiple batches.
	 */</comment>
	<expr_stmt><expr><name>bucket_bytes</name> <operator>=</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof> <operator>*</operator> <name>nbuckets</name></expr>;</expr_stmt>
	<if_stmt><if>if <condition>(<expr><name>inner_rel_bytes</name> <operator>+</operator> <name>bucket_bytes</name> <operator>&gt;</operator> <name>hash_table_bytes</name></expr>)</condition>
	<block>{<block_content>
		<comment type="block">/* We'll need multiple batches */</comment>
		<decl_stmt><decl><type><name>size_t</name></type>		<name>sbuckets</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>double</name></type>		<name>dbatch</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>int</name></type>			<name>minbatch</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>size_t</name></type>		<name>bucket_size</name></decl>;</decl_stmt>

		<comment type="block">/*
		 * If Parallel Hash with combined hash_mem would still need multiple
		 * batches, we'll have to fall back to regular hash_mem budget.
		 */</comment>
		<if_stmt><if>if <condition>(<expr><name>try_combined_hash_mem</name></expr>)</condition>
		<block>{<block_content>
			<expr_stmt><expr><call><name>ExecChooseHashTableSize</name><argument_list>(<argument><expr><name>ntuples</name></expr></argument>, <argument><expr><name>tupwidth</name></expr></argument>, <argument><expr><name>useskew</name></expr></argument>,
									<argument><expr><name>false</name></expr></argument>, <argument><expr><name>parallel_workers</name></expr></argument>,
									<argument><expr><name>space_allowed</name></expr></argument>,
									<argument><expr><name>numbuckets</name></expr></argument>,
									<argument><expr><name>numbatches</name></expr></argument>,
									<argument><expr><name>num_skew_mcvs</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<return>return;</return>
		</block_content>}</block></if></if_stmt>

		<comment type="block">/*
		 * Estimate the number of buckets we'll want to have when hash_mem is
		 * entirely full.  Each bucket will contain a bucket pointer plus
		 * NTUP_PER_BUCKET tuples, whose projected size already includes
		 * overhead for the hash code, pointer to the next tuple, etc.
		 */</comment>
		<expr_stmt><expr><name>bucket_size</name> <operator>=</operator> <operator>(</operator><name>tupsize</name> <operator>*</operator> <name>NTUP_PER_BUCKET</name> <operator>+</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof><operator>)</operator></expr>;</expr_stmt>
		<expr_stmt><expr><name>sbuckets</name> <operator>=</operator> <call><name>pg_nextpower2_size_t</name><argument_list>(<argument><expr><name>hash_table_bytes</name> <operator>/</operator> <name>bucket_size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name>sbuckets</name> <operator>=</operator> <call><name>Min</name><argument_list>(<argument><expr><name>sbuckets</name></expr></argument>, <argument><expr><name>max_pointers</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name>nbuckets</name> <operator>=</operator> <operator>(</operator><name>int</name><operator>)</operator> <name>sbuckets</name></expr>;</expr_stmt>
		<expr_stmt><expr><name>nbuckets</name> <operator>=</operator> <call><name>pg_nextpower2_32</name><argument_list>(<argument><expr><name>nbuckets</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name>bucket_bytes</name> <operator>=</operator> <name>nbuckets</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof></expr>;</expr_stmt>

		<comment type="block">/*
		 * Buckets are simple pointers to hashjoin tuples, while tupsize
		 * includes the pointer, hash code, and MinimalTupleData.  So buckets
		 * should never really exceed 25% of hash_mem (even for
		 * NTUP_PER_BUCKET=1); except maybe for hash_mem values that are not
		 * 2^N bytes, where we might get more because of doubling. So let's
		 * look for 50% here.
		 */</comment>
		<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>bucket_bytes</name> <operator>&lt;=</operator> <name>hash_table_bytes</name> <operator>/</operator> <literal type="number">2</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/* Calculate required number of batches. */</comment>
		<expr_stmt><expr><name>dbatch</name> <operator>=</operator> <call><name>ceil</name><argument_list>(<argument><expr><name>inner_rel_bytes</name> <operator>/</operator> <operator>(</operator><name>hash_table_bytes</name> <operator>-</operator> <name>bucket_bytes</name><operator>)</operator></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name>dbatch</name> <operator>=</operator> <call><name>Min</name><argument_list>(<argument><expr><name>dbatch</name></expr></argument>, <argument><expr><name>max_pointers</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name>minbatch</name> <operator>=</operator> <operator>(</operator><name>int</name><operator>)</operator> <name>dbatch</name></expr>;</expr_stmt>
		<expr_stmt><expr><name>nbatch</name> <operator>=</operator> <call><name>pg_nextpower2_32</name><argument_list>(<argument><expr><call><name>Max</name><argument_list>(<argument><expr><literal type="number">2</literal></expr></argument>, <argument><expr><name>minbatch</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></if></if_stmt>

	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>nbuckets</name> <operator>&gt;</operator> <literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>nbatch</name> <operator>&gt;</operator> <literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><operator>*</operator><name>numbuckets</name> <operator>=</operator> <name>nbuckets</name></expr>;</expr_stmt>
	<expr_stmt><expr><operator>*</operator><name>numbatches</name> <operator>=</operator> <name>nbatch</name></expr>;</expr_stmt>
</block_content>}</block></function>


<comment type="block">/* ----------------------------------------------------------------
 *		ExecHashTableDestroy
 *
 *		destroy a hash table
 * ----------------------------------------------------------------
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashTableDestroy</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

	<comment type="block">/*
	 * Make sure all the temp files are closed.  We skip batch 0, since it
	 * can't have any temp files (and the arrays might not even exist if
	 * nbatch is only 1).  Parallel hash joins don't use these files.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name></name> <operator>!=</operator> <name>NULL</name></expr>)</condition>
	<block>{<block_content>
		<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">1</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr>;</condition> <incr><expr><name>i</name><operator>++</operator></expr></incr>)</control>
		<block>{<block_content>
			<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name><index>[<expr><name>i</name></expr>]</index></name></expr>)</condition><block type="pseudo"><block_content>
				<expr_stmt><expr><call><name>BufFileClose</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
			<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>outerBatchFile</name><index>[<expr><name>i</name></expr>]</index></name></expr>)</condition><block type="pseudo"><block_content>
				<expr_stmt><expr><call><name>BufFileClose</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>outerBatchFile</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
		</block_content>}</block></for>
	</block_content>}</block></if></if_stmt>

	<comment type="block">/* Release working memory (batchCxt is a child, so it goes away too) */</comment>
	<expr_stmt><expr><call><name>MemoryContextDelete</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>hashCxt</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* And drop the control block */</comment>
	<expr_stmt><expr><call><name>pfree</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * ExecHashIncreaseNumBatches
 *		increase the original number of batches in order to reduce
 *		current memory consumption
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecHashIncreaseNumBatches</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>int</name></type>			<name>oldnbatch</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>curbatch</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>nbatch</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>MemoryContext</name></type> <name>oldcxt</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>long</name></type>		<name>ninmemory</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>long</name></type>		<name>nfreed</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashMemoryChunk</name></type> <name>oldchunks</name></decl>;</decl_stmt>

	<comment type="block">/* do nothing if we've decided to shut off growth */</comment>
	<if_stmt><if>if <condition>(<expr><operator>!</operator><name><name>hashtable</name><operator>-&gt;</operator><name>growEnabled</name></name></expr>)</condition><block type="pseudo"><block_content>
		<return>return;</return></block_content></block></if></if_stmt>

	<comment type="block">/* safety check to avoid overflow */</comment>
	<if_stmt><if>if <condition>(<expr><name>oldnbatch</name> <operator>&gt;</operator> <call><name>Min</name><argument_list>(<argument><expr><name>INT_MAX</name> <operator>/</operator> <literal type="number">2</literal></expr></argument>, <argument><expr><name>MaxAllocSize</name> <operator>/</operator> <operator>(</operator><sizeof>sizeof<argument_list>(<argument><expr><name>void</name> <operator>*</operator></expr></argument>)</argument_list></sizeof> <operator>*</operator> <literal type="number">2</literal><operator>)</operator></expr></argument>)</argument_list></call></expr>)</condition><block type="pseudo"><block_content>
		<return>return;</return></block_content></block></if></if_stmt>

	<expr_stmt><expr><name>nbatch</name> <operator>=</operator> <name>oldnbatch</name> <operator>*</operator> <literal type="number">2</literal></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>nbatch</name> <operator>&gt;</operator> <literal type="number">1</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>

<cpp:ifdef>#<cpp:directive>ifdef</cpp:directive> <name>HJDEBUG</name></cpp:ifdef>
	<expr_stmt><expr><call><name>printf</name><argument_list>(<argument><expr><literal type="string">"Hashjoin %p: increasing nbatch to %d because space = %zu\n"</literal></expr></argument>,
		   <argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>nbatch</name></expr></argument>, <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
<cpp:endif>#<cpp:directive>endif</cpp:directive></cpp:endif>

	<expr_stmt><expr><name>oldcxt</name> <operator>=</operator> <call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>hashCxt</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name></name> <operator>==</operator> <name>NULL</name></expr>)</condition>
	<block>{<block_content>
		<comment type="block">/* we had no file arrays before */</comment>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name></name> <operator>=</operator> <operator>(</operator><name>BufFile</name> <operator>*</operator><operator>*</operator><operator>)</operator>
			<call><name>palloc0</name><argument_list>(<argument><expr><name>nbatch</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>BufFile</name> <operator>*</operator></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>outerBatchFile</name></name> <operator>=</operator> <operator>(</operator><name>BufFile</name> <operator>*</operator><operator>*</operator><operator>)</operator>
			<call><name>palloc0</name><argument_list>(<argument><expr><name>nbatch</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>BufFile</name> <operator>*</operator></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<comment type="block">/* time to establish the temp tablespaces, too */</comment>
		<expr_stmt><expr><call><name>PrepareTempTablespaces</name><argument_list>()</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></if>
	<else>else
	<block>{<block_content>
		<comment type="block">/* enlarge arrays and zero out added entries */</comment>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name></name> <operator>=</operator> <operator>(</operator><name>BufFile</name> <operator>*</operator><operator>*</operator><operator>)</operator>
			<call><name>repalloc</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name></name></expr></argument>, <argument><expr><name>nbatch</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>BufFile</name> <operator>*</operator></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>outerBatchFile</name></name> <operator>=</operator> <operator>(</operator><name>BufFile</name> <operator>*</operator><operator>*</operator><operator>)</operator>
			<call><name>repalloc</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>outerBatchFile</name></name></expr></argument>, <argument><expr><name>nbatch</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>BufFile</name> <operator>*</operator></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>MemSet</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name></name> <operator>+</operator> <name>oldnbatch</name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>,
			   <argument><expr><operator>(</operator><name>nbatch</name> <operator>-</operator> <name>oldnbatch</name><operator>)</operator> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>BufFile</name> <operator>*</operator></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>MemSet</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>outerBatchFile</name></name> <operator>+</operator> <name>oldnbatch</name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>,
			   <argument><expr><operator>(</operator><name>nbatch</name> <operator>-</operator> <name>oldnbatch</name><operator>)</operator> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>BufFile</name> <operator>*</operator></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></else></if_stmt>

	<expr_stmt><expr><call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name>oldcxt</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>=</operator> <name>nbatch</name></expr>;</expr_stmt>

	<comment type="block">/*
	 * Scan through the existing hash table entries and dump out any that are
	 * no longer of the current batch.
	 */</comment>
	<expr_stmt><expr><name>ninmemory</name> <operator>=</operator> <name>nfreed</name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>

	<comment type="block">/* If know we need to resize nbuckets, we can do it while rebatching. */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name> <operator>!=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr>)</condition>
	<block>{<block_content>
		<comment type="block">/* we never decrease the number of buckets */</comment>
		<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name> <operator>&gt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>log2_nbuckets</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>log2_nbuckets_optimal</name></name></expr>;</expr_stmt>

		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name></name> <operator>=</operator>
			<call><name>repalloc</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name></name></expr></argument>,
					 <argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof> <operator>*</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></if></if_stmt>

	<comment type="block">/*
	 * We will scan through the chunks directly, so that we can reset the
	 * buckets now and not have to keep track which tuples in the buckets have
	 * already been processed. We will free the old chunks as we go.
	 */</comment>
	<expr_stmt><expr><call><name>memset</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name></name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>,
		   <argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof> <operator>*</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>oldchunks</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>

	<comment type="block">/* so, let's scan through the old chunks, and all tuples in each chunk */</comment>
	<while>while <condition>(<expr><name>oldchunks</name> <operator>!=</operator> <name>NULL</name></expr>)</condition>
	<block>{<block_content>
		<decl_stmt><decl><type><name>HashMemoryChunk</name></type> <name>nextchunk</name> <init>= <expr><name><name>oldchunks</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name></expr></init></decl>;</decl_stmt>

		<comment type="block">/* position within the buffer (up to oldchunks-&gt;used) */</comment>
		<decl_stmt><decl><type><name>size_t</name></type>		<name>idx</name> <init>= <expr><literal type="number">0</literal></expr></init></decl>;</decl_stmt>

		<comment type="block">/* process all tuples stored in this chunk (and then free it) */</comment>
		<while>while <condition>(<expr><name>idx</name> <operator>&lt;</operator> <name><name>oldchunks</name><operator>-&gt;</operator><name>used</name></name></expr>)</condition>
		<block>{<block_content>
			<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name> <init>= <expr><operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <operator>(</operator><call><name>HASH_CHUNK_DATA</name><argument_list>(<argument><expr><name>oldchunks</name></expr></argument>)</argument_list></call> <operator>+</operator> <name>idx</name><operator>)</operator></expr></init></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>MinimalTuple</name></type> <name>tuple</name> <init>= <expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>int</name></type>			<name>hashTupleSize</name> <init>= <expr><operator>(</operator><name>HJTUPLE_OVERHEAD</name> <operator>+</operator> <name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name><operator>)</operator></expr></init></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>int</name></type>			<name>bucketno</name></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>int</name></type>			<name>batchno</name></decl>;</decl_stmt>

			<expr_stmt><expr><name>ninmemory</name><operator>++</operator></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>ExecHashGetBucketAndBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name></expr></argument>,
									  <argument><expr><operator>&amp;</operator><name>bucketno</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>batchno</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<if_stmt><if>if <condition>(<expr><name>batchno</name> <operator>==</operator> <name>curbatch</name></expr>)</condition>
			<block>{<block_content>
				<comment type="block">/* keep tuple in memory - copy it into the new chunk */</comment>
				<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>copyTuple</name></decl>;</decl_stmt>

				<expr_stmt><expr><name>copyTuple</name> <operator>=</operator> <operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <call><name>dense_alloc</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>hashTupleSize</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>memcpy</name><argument_list>(<argument><expr><name>copyTuple</name></expr></argument>, <argument><expr><name>hashTuple</name></expr></argument>, <argument><expr><name>hashTupleSize</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

				<comment type="block">/* and add it back to the appropriate bucket */</comment>
				<expr_stmt><expr><name><name>copyTuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name><index>[<expr><name>bucketno</name></expr>]</index></name></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name><index>[<expr><name>bucketno</name></expr>]</index></name> <operator>=</operator> <name>copyTuple</name></expr>;</expr_stmt>
			</block_content>}</block></if>
			<else>else
			<block>{<block_content>
				<comment type="block">/* dump it out */</comment>
				<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>batchno</name> <operator>&gt;</operator> <name>curbatch</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>ExecHashJoinSaveTuple</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>,
									  <argument><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name></expr></argument>,
									  <argument><expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name><index>[<expr><name>batchno</name></expr>]</index></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

				<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>-=</operator> <name>hashTupleSize</name></expr>;</expr_stmt>
				<expr_stmt><expr><name>nfreed</name><operator>++</operator></expr>;</expr_stmt>
			</block_content>}</block></else></if_stmt>

			<comment type="block">/* next tuple in this chunk */</comment>
			<expr_stmt><expr><name>idx</name> <operator>+=</operator> <call><name>MAXALIGN</name><argument_list>(<argument><expr><name>hashTupleSize</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<comment type="block">/* allow this loop to be cancellable */</comment>
			<expr_stmt><expr><call><name>CHECK_FOR_INTERRUPTS</name><argument_list>()</argument_list></call></expr>;</expr_stmt>
		</block_content>}</block></while>

		<comment type="block">/* we're done with this chunk - free it and proceed to the next one */</comment>
		<expr_stmt><expr><call><name>pfree</name><argument_list>(<argument><expr><name>oldchunks</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name>oldchunks</name> <operator>=</operator> <name>nextchunk</name></expr>;</expr_stmt>
	</block_content>}</block></while>

<cpp:ifdef>#<cpp:directive>ifdef</cpp:directive> <name>HJDEBUG</name></cpp:ifdef>
	<expr_stmt><expr><call><name>printf</name><argument_list>(<argument><expr><literal type="string">"Hashjoin %p: freed %ld of %ld tuples, space now %zu\n"</literal></expr></argument>,
		   <argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>nfreed</name></expr></argument>, <argument><expr><name>ninmemory</name></expr></argument>, <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
<cpp:endif>#<cpp:directive>endif</cpp:directive></cpp:endif>

	<comment type="block">/*
	 * If we dumped out either all or none of the tuples in the table, disable
	 * further expansion of nbatch.  This situation implies that we have
	 * enough tuples of identical hashvalues to overflow spaceAllowed.
	 * Increasing nbatch will not fix it since there's no way to subdivide the
	 * group any more finely. We have to just gut it out and hope the server
	 * has enough RAM.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name>nfreed</name> <operator>==</operator> <literal type="number">0</literal> <operator>||</operator> <name>nfreed</name> <operator>==</operator> <name>ninmemory</name></expr>)</condition>
	<block>{<block_content>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>growEnabled</name></name> <operator>=</operator> <name>false</name></expr>;</expr_stmt>
<cpp:ifdef>#<cpp:directive>ifdef</cpp:directive> <name>HJDEBUG</name></cpp:ifdef>
		<expr_stmt><expr><call><name>printf</name><argument_list>(<argument><expr><literal type="string">"Hashjoin %p: disabling further increase of nbatch\n"</literal></expr></argument>,
			   <argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
<cpp:endif>#<cpp:directive>endif</cpp:directive></cpp:endif>
	</block_content>}</block></if></if_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * ExecParallelHashIncreaseNumBatches
 *		Every participant attached to grow_batches_barrier must run this
 *		function when it observes growth == PHJ_GROWTH_NEED_MORE_BATCHES.
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecParallelHashIncreaseNumBatches</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>build_barrier</name></name></expr></argument>)</argument_list></call> <operator>==</operator> <name>PHJ_BUILD_HASHING_INNER</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * It's unlikely, but we need to be prepared for new participants to show
	 * up while we're in the middle of this operation so we need to switch on
	 * barrier phase here.
	 */</comment>
	<switch>switch <condition>(<expr><call><name>PHJ_GROW_BATCHES_PHASE</name><argument_list>(<argument><expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_batches_barrier</name></name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>)</condition>
	<block>{<block_content>
		<case>case <expr><name>PHJ_GROW_BATCHES_ELECTING</name></expr>:</case>

			<comment type="block">/*
			 * Elect one participant to prepare to grow the number of batches.
			 * This involves reallocating or resetting the buckets of batch 0
			 * in preparation for all participants to begin repartitioning the
			 * tuples.
			 */</comment>
			<if_stmt><if>if <condition>(<expr><call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_batches_barrier</name></name></expr></argument>,
									 <argument><expr><name>WAIT_EVENT_HASH_GROW_BATCHES_ELECT</name></expr></argument>)</argument_list></call></expr>)</condition>
			<block>{<block_content>
				<decl_stmt><decl><type><name>dsa_pointer_atomic</name> <modifier>*</modifier></type><name>buckets</name></decl>;</decl_stmt>
				<decl_stmt><decl><type><name>ParallelHashJoinBatch</name> <modifier>*</modifier></type><name>old_batch0</name></decl>;</decl_stmt>
				<decl_stmt><decl><type><name>int</name></type>			<name>new_nbatch</name></decl>;</decl_stmt>
				<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

				<comment type="block">/* Move the old batch out of the way. */</comment>
				<expr_stmt><expr><name>old_batch0</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name>shared</name></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>old_batches</name></name> <operator>=</operator> <name><name>pstate</name><operator>-&gt;</operator><name>batches</name></name></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>old_nbatch</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>batches</name></name> <operator>=</operator> <name>InvalidDsaPointer</name></expr>;</expr_stmt>

				<comment type="block">/* Free this backend's old accessors. */</comment>
				<expr_stmt><expr><call><name>ExecParallelHashCloseBatchAccessors</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

				<comment type="block">/* Figure out how many batches to use. */</comment>
				<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>==</operator> <literal type="number">1</literal></expr>)</condition>
				<block>{<block_content>
					<comment type="block">/*
					 * We are going from single-batch to multi-batch.  We need
					 * to switch from one large combined memory budget to the
					 * regular hash_mem budget.
					 */</comment>
					<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>space_allowed</name></name> <operator>=</operator> <call><name>get_hash_memory_limit</name><argument_list>()</argument_list></call></expr>;</expr_stmt>

					<comment type="block">/*
					 * The combined hash_mem of all participants wasn't
					 * enough. Therefore one batch per participant would be
					 * approximately equivalent and would probably also be
					 * insufficient.  So try two batches per participant,
					 * rounded up to a power of two.
					 */</comment>
					<expr_stmt><expr><name>new_nbatch</name> <operator>=</operator> <call><name>pg_nextpower2_32</name><argument_list>(<argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>nparticipants</name></name> <operator>*</operator> <literal type="number">2</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				</block_content>}</block></if>
				<else>else
				<block>{<block_content>
					<comment type="block">/*
					 * We were already multi-batched.  Try doubling the number
					 * of batches.
					 */</comment>
					<expr_stmt><expr><name>new_nbatch</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>*</operator> <literal type="number">2</literal></expr>;</expr_stmt>
				</block_content>}</block></else></if_stmt>

				<comment type="block">/* Allocate new larger generation of batches. */</comment>
				<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>==</operator> <name><name>pstate</name><operator>-&gt;</operator><name>nbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>ExecParallelHashJoinSetUpBatches</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>new_nbatch</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>==</operator> <name><name>pstate</name><operator>-&gt;</operator><name>nbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

				<comment type="block">/* Replace or recycle batch 0's bucket array. */</comment>
				<if_stmt><if>if <condition>(<expr><name><name>pstate</name><operator>-&gt;</operator><name>old_nbatch</name></name> <operator>==</operator> <literal type="number">1</literal></expr>)</condition>
				<block>{<block_content>
					<decl_stmt><decl><type><name>double</name></type>		<name>dtuples</name></decl>;</decl_stmt>
					<decl_stmt><decl><type><name>double</name></type>		<name>dbuckets</name></decl>;</decl_stmt>
					<decl_stmt><decl><type><name>int</name></type>			<name>new_nbuckets</name></decl>;</decl_stmt>

					<comment type="block">/*
					 * We probably also need a smaller bucket array.  How many
					 * tuples do we expect per batch, assuming we have only
					 * half of them so far?  Normally we don't need to change
					 * the bucket array's size, because the size of each batch
					 * stays the same as we add more batches, but in this
					 * special case we move from a large batch to many smaller
					 * batches and it would be wasteful to keep the large
					 * array.
					 */</comment>
					<expr_stmt><expr><name>dtuples</name> <operator>=</operator> <operator>(</operator><name><name>old_batch0</name><operator>-&gt;</operator><name>ntuples</name></name> <operator>*</operator> <literal type="number">2.0</literal><operator>)</operator> <operator>/</operator> <name>new_nbatch</name></expr>;</expr_stmt>
					<expr_stmt><expr><name>dbuckets</name> <operator>=</operator> <call><name>ceil</name><argument_list>(<argument><expr><name>dtuples</name> <operator>/</operator> <name>NTUP_PER_BUCKET</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
					<expr_stmt><expr><name>dbuckets</name> <operator>=</operator> <call><name>Min</name><argument_list>(<argument><expr><name>dbuckets</name></expr></argument>,
								   <argument><expr><name>MaxAllocSize</name> <operator>/</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>dsa_pointer_atomic</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
					<expr_stmt><expr><name>new_nbuckets</name> <operator>=</operator> <operator>(</operator><name>int</name><operator>)</operator> <name>dbuckets</name></expr>;</expr_stmt>
					<expr_stmt><expr><name>new_nbuckets</name> <operator>=</operator> <call><name>Max</name><argument_list>(<argument><expr><name>new_nbuckets</name></expr></argument>, <argument><expr><literal type="number">1024</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
					<expr_stmt><expr><name>new_nbuckets</name> <operator>=</operator> <call><name>pg_nextpower2_32</name><argument_list>(<argument><expr><name>new_nbuckets</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
					<expr_stmt><expr><call><name>dsa_free</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>old_batch0</name><operator>-&gt;</operator><name>buckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
					<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>buckets</name></name> <operator>=</operator>
						<call><name>dsa_allocate</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>,
									 <argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>dsa_pointer_atomic</name></expr></argument>)</argument_list></sizeof> <operator>*</operator> <name>new_nbuckets</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
					<expr_stmt><expr><name>buckets</name> <operator>=</operator> <operator>(</operator><name>dsa_pointer_atomic</name> <operator>*</operator><operator>)</operator>
						<call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>,
										<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>buckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
					<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name>new_nbuckets</name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control><block type="pseudo"><block_content>
						<expr_stmt><expr><call><name>dsa_pointer_atomic_init</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>buckets</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>, <argument><expr><name>InvalidDsaPointer</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></for>
					<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>=</operator> <name>new_nbuckets</name></expr>;</expr_stmt>
				</block_content>}</block></if>
				<else>else
				<block>{<block_content>
					<comment type="block">/* Recycle the existing bucket array. */</comment>
					<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>buckets</name></name> <operator>=</operator> <name><name>old_batch0</name><operator>-&gt;</operator><name>buckets</name></name></expr>;</expr_stmt>
					<expr_stmt><expr><name>buckets</name> <operator>=</operator> <operator>(</operator><name>dsa_pointer_atomic</name> <operator>*</operator><operator>)</operator>
						<call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>old_batch0</name><operator>-&gt;</operator><name>buckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
					<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control><block type="pseudo"><block_content>
						<expr_stmt><expr><call><name>dsa_pointer_atomic_write</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>buckets</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>, <argument><expr><name>InvalidDsaPointer</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></for>
				</block_content>}</block></else></if_stmt>

				<comment type="block">/* Move all chunks to the work queue for parallel processing. */</comment>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>chunk_work_queue</name></name> <operator>=</operator> <name><name>old_batch0</name><operator>-&gt;</operator><name>chunks</name></name></expr>;</expr_stmt>

				<comment type="block">/* Disable further growth temporarily while we're growing. */</comment>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>=</operator> <name>PHJ_GROWTH_DISABLED</name></expr>;</expr_stmt>
			</block_content>}</block></if>
			<else>else
			<block>{<block_content>
				<comment type="block">/* All other participants just flush their tuples to disk. */</comment>
				<expr_stmt><expr><call><name>ExecParallelHashCloseBatchAccessors</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			</block_content>}</block></else></if_stmt>
			<comment type="block">/* Fall through. */</comment>

		<case>case <expr><name>PHJ_GROW_BATCHES_ALLOCATING</name></expr>:</case>
			<comment type="block">/* Wait for the above to be finished. */</comment>
			<expr_stmt><expr><call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_batches_barrier</name></name></expr></argument>,
								 <argument><expr><name>WAIT_EVENT_HASH_GROW_BATCHES_ALLOCATE</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<comment type="block">/* Fall through. */</comment>

		<case>case <expr><name>PHJ_GROW_BATCHES_REPARTITIONING</name></expr>:</case>
			<comment type="block">/* Make sure that we have the current dimensions and buckets. */</comment>
			<expr_stmt><expr><call><name>ExecParallelHashEnsureBatchAccessors</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>ExecParallelHashTableSetCurrentBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<comment type="block">/* Then partition, flush counters. */</comment>
			<expr_stmt><expr><call><name>ExecParallelHashRepartitionFirst</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>ExecParallelHashRepartitionRest</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>ExecParallelHashMergeCounters</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<comment type="block">/* Wait for the above to be finished. */</comment>
			<expr_stmt><expr><call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_batches_barrier</name></name></expr></argument>,
								 <argument><expr><name>WAIT_EVENT_HASH_GROW_BATCHES_REPARTITION</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<comment type="block">/* Fall through. */</comment>

		<case>case <expr><name>PHJ_GROW_BATCHES_DECIDING</name></expr>:</case>

			<comment type="block">/*
			 * Elect one participant to clean up and decide whether further
			 * repartitioning is needed, or should be disabled because it's
			 * not helping.
			 */</comment>
			<if_stmt><if>if <condition>(<expr><call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_batches_barrier</name></name></expr></argument>,
									 <argument><expr><name>WAIT_EVENT_HASH_GROW_BATCHES_DECIDE</name></expr></argument>)</argument_list></call></expr>)</condition>
			<block>{<block_content>
				<decl_stmt><decl><type><name>bool</name></type>		<name>space_exhausted</name> <init>= <expr><name>false</name></expr></init></decl>;</decl_stmt>
				<decl_stmt><decl><type><name>bool</name></type>		<name>extreme_skew_detected</name> <init>= <expr><name>false</name></expr></init></decl>;</decl_stmt>

				<comment type="block">/* Make sure that we have the current dimensions and buckets. */</comment>
				<expr_stmt><expr><call><name>ExecParallelHashEnsureBatchAccessors</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>ExecParallelHashTableSetCurrentBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>

				<comment type="block">/* Are any of the new generation of batches exhausted? */</comment>
				<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control>
				<block>{<block_content>
					<decl_stmt><decl><type><name>ParallelHashJoinBatch</name> <modifier>*</modifier></type><name>batch</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name><operator>.</operator><name>shared</name></expr></init></decl>;</decl_stmt>

					<if_stmt><if>if <condition>(<expr><name><name>batch</name><operator>-&gt;</operator><name>space_exhausted</name></name> <operator>||</operator>
						<name><name>batch</name><operator>-&gt;</operator><name>estimated_size</name></name> <operator>&gt;</operator> <name><name>pstate</name><operator>-&gt;</operator><name>space_allowed</name></name></expr>)</condition>
					<block>{<block_content>
						<decl_stmt><decl><type><name>int</name></type>			<name>parent</name></decl>;</decl_stmt>

						<expr_stmt><expr><name>space_exhausted</name> <operator>=</operator> <name>true</name></expr>;</expr_stmt>

						<comment type="block">/*
						 * Did this batch receive ALL of the tuples from its
						 * parent batch?  That would indicate that further
						 * repartitioning isn't going to help (the hash values
						 * are probably all the same).
						 */</comment>
						<expr_stmt><expr><name>parent</name> <operator>=</operator> <name>i</name> <operator>%</operator> <name><name>pstate</name><operator>-&gt;</operator><name>old_nbatch</name></name></expr>;</expr_stmt>
						<if_stmt><if>if <condition>(<expr><name><name>batch</name><operator>-&gt;</operator><name>ntuples</name></name> <operator>==</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>parent</name></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>old_ntuples</name></name></expr>)</condition><block type="pseudo"><block_content>
							<expr_stmt><expr><name>extreme_skew_detected</name> <operator>=</operator> <name>true</name></expr>;</expr_stmt></block_content></block></if></if_stmt>
					</block_content>}</block></if></if_stmt>
				</block_content>}</block></for>

				<comment type="block">/* Don't keep growing if it's not helping or we'd overflow. */</comment>
				<if_stmt><if>if <condition>(<expr><name>extreme_skew_detected</name> <operator>||</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>&gt;=</operator> <name>INT_MAX</name> <operator>/</operator> <literal type="number">2</literal></expr>)</condition><block type="pseudo"><block_content>
					<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>=</operator> <name>PHJ_GROWTH_DISABLED</name></expr>;</expr_stmt></block_content></block></if>
				<if type="elseif">else if <condition>(<expr><name>space_exhausted</name></expr>)</condition><block type="pseudo"><block_content>
					<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>=</operator> <name>PHJ_GROWTH_NEED_MORE_BATCHES</name></expr>;</expr_stmt></block_content></block></if>
				<else>else<block type="pseudo"><block_content>
					<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>=</operator> <name>PHJ_GROWTH_OK</name></expr>;</expr_stmt></block_content></block></else></if_stmt>

				<comment type="block">/* Free the old batches in shared memory. */</comment>
				<expr_stmt><expr><call><name>dsa_free</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>old_batches</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>old_batches</name></name> <operator>=</operator> <name>InvalidDsaPointer</name></expr>;</expr_stmt>
			</block_content>}</block></if></if_stmt>
			<comment type="block">/* Fall through. */</comment>

		<case>case <expr><name>PHJ_GROW_BATCHES_FINISHING</name></expr>:</case>
			<comment type="block">/* Wait for the above to complete. */</comment>
			<expr_stmt><expr><call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_batches_barrier</name></name></expr></argument>,
								 <argument><expr><name>WAIT_EVENT_HASH_GROW_BATCHES_FINISH</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></switch>
</block_content>}</block></function>

<comment type="block">/*
 * Repartition the tuples currently loaded into memory for inner batch 0
 * because the number of batches has been increased.  Some tuples are retained
 * in memory and some are written out to a later batch.
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecParallelHashRepartitionFirst</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>dsa_pointer</name></type> <name>chunk_shared</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashMemoryChunk</name></type> <name>chunk</name></decl>;</decl_stmt>

	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>==</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name><operator>-&gt;</operator><name>nbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<while>while <condition>(<expr><operator>(</operator><name>chunk</name> <operator>=</operator> <call><name>ExecParallelHashPopChunkQueue</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>chunk_shared</name></expr></argument>)</argument_list></call><operator>)</operator></expr>)</condition>
	<block>{<block_content>
		<decl_stmt><decl><type><name>size_t</name></type>		<name>idx</name> <init>= <expr><literal type="number">0</literal></expr></init></decl>;</decl_stmt>

		<comment type="block">/* Repartition all tuples in this chunk. */</comment>
		<while>while <condition>(<expr><name>idx</name> <operator>&lt;</operator> <name><name>chunk</name><operator>-&gt;</operator><name>used</name></name></expr>)</condition>
		<block>{<block_content>
			<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name> <init>= <expr><operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <operator>(</operator><call><name>HASH_CHUNK_DATA</name><argument_list>(<argument><expr><name>chunk</name></expr></argument>)</argument_list></call> <operator>+</operator> <name>idx</name><operator>)</operator></expr></init></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>MinimalTuple</name></type> <name>tuple</name> <init>= <expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>copyTuple</name></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>dsa_pointer</name></type> <name>shared</name></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>int</name></type>			<name>bucketno</name></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>int</name></type>			<name>batchno</name></decl>;</decl_stmt>

			<expr_stmt><expr><call><name>ExecHashGetBucketAndBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name></expr></argument>,
									  <argument><expr><operator>&amp;</operator><name>bucketno</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>batchno</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>batchno</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<if_stmt><if>if <condition>(<expr><name>batchno</name> <operator>==</operator> <literal type="number">0</literal></expr>)</condition>
			<block>{<block_content>
				<comment type="block">/* It still belongs in batch 0.  Copy to a new chunk. */</comment>
				<expr_stmt><expr><name>copyTuple</name> <operator>=</operator>
					<call><name>ExecParallelHashTupleAlloc</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>,
											   <argument><expr><name>HJTUPLE_OVERHEAD</name> <operator>+</operator> <name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr></argument>,
											   <argument><expr><operator>&amp;</operator><name>shared</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>copyTuple</name><operator>-&gt;</operator><name>hashvalue</name></name> <operator>=</operator> <name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>memcpy</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>copyTuple</name></expr></argument>)</argument_list></call></expr></argument>, <argument><expr><name>tuple</name></expr></argument>, <argument><expr><name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>ExecParallelHashPushTuple</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>shared</name><index>[<expr><name>bucketno</name></expr>]</index></name></expr></argument>,
										  <argument><expr><name>copyTuple</name></expr></argument>, <argument><expr><name>shared</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			</block_content>}</block></if>
			<else>else
			<block>{<block_content>
				<decl_stmt><decl><type><name>size_t</name></type>		<name>tuple_size</name> <init>=
				<expr><call><name>MAXALIGN</name><argument_list>(<argument><expr><name>HJTUPLE_OVERHEAD</name> <operator>+</operator> <name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>

				<comment type="block">/* It belongs in a later batch. */</comment>
				<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>estimated_size</name> <operator>+=</operator> <name>tuple_size</name></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>sts_puttuple</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>inner_tuples</name></expr></argument>,
							 <argument><expr><operator>&amp;</operator><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name></expr></argument>, <argument><expr><name>tuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			</block_content>}</block></else></if_stmt>

			<comment type="block">/* Count this tuple. */</comment>
			<expr_stmt><expr><operator>++</operator><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name>old_ntuples</name></expr>;</expr_stmt>
			<expr_stmt><expr><operator>++</operator><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>ntuples</name></expr>;</expr_stmt>

			<expr_stmt><expr><name>idx</name> <operator>+=</operator> <call><name>MAXALIGN</name><argument_list>(<argument><expr><name>HJTUPLE_OVERHEAD</name> <operator>+</operator>
							<call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call><operator>-&gt;</operator><name>t_len</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		</block_content>}</block></while>

		<comment type="block">/* Free this chunk. */</comment>
		<expr_stmt><expr><call><name>dsa_free</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name>chunk_shared</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<expr_stmt><expr><call><name>CHECK_FOR_INTERRUPTS</name><argument_list>()</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></while>
</block_content>}</block></function>

<comment type="block">/*
 * Help repartition inner batches 1..n.
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecParallelHashRepartitionRest</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>old_nbatch</name> <init>= <expr><name><name>pstate</name><operator>-&gt;</operator><name>old_nbatch</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>SharedTuplestoreAccessor</name> <modifier>*</modifier><modifier>*</modifier></type><name>old_inner_tuples</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>ParallelHashJoinBatch</name> <modifier>*</modifier></type><name>old_batches</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

	<comment type="block">/* Get our hands on the previous generation of batches. */</comment>
	<expr_stmt><expr><name>old_batches</name> <operator>=</operator> <operator>(</operator><name>ParallelHashJoinBatch</name> <operator>*</operator><operator>)</operator>
		<call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>old_batches</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>old_inner_tuples</name> <operator>=</operator> <call><name>palloc0</name><argument_list>(<argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>SharedTuplestoreAccessor</name> <operator>*</operator></expr></argument>)</argument_list></sizeof> <operator>*</operator> <name>old_nbatch</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">1</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name>old_nbatch</name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control>
	<block>{<block_content>
		<decl_stmt><decl><type><name>ParallelHashJoinBatch</name> <modifier>*</modifier></type><name>shared</name> <init>=
		<expr><call><name>NthParallelHashJoinBatch</name><argument_list>(<argument><expr><name>old_batches</name></expr></argument>, <argument><expr><name>i</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>

		<expr_stmt><expr><name><name>old_inner_tuples</name><index>[<expr><name>i</name></expr>]</index></name> <operator>=</operator> <call><name>sts_attach</name><argument_list>(<argument><expr><call><name>ParallelHashJoinBatchInner</name><argument_list>(<argument><expr><name>shared</name></expr></argument>)</argument_list></call></expr></argument>,
										 <argument><expr><name>ParallelWorkerNumber</name> <operator>+</operator> <literal type="number">1</literal></expr></argument>,
										 <argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>fileset</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></for>

	<comment type="block">/* Join in the effort to repartition them. */</comment>
	<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">1</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name>old_nbatch</name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control>
	<block>{<block_content>
		<decl_stmt><decl><type><name>MinimalTuple</name></type> <name>tuple</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>uint32</name></type>		<name>hashvalue</name></decl>;</decl_stmt>

		<comment type="block">/* Scan one partition from the previous generation. */</comment>
		<expr_stmt><expr><call><name>sts_begin_parallel_scan</name><argument_list>(<argument><expr><name><name>old_inner_tuples</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<while>while <condition>(<expr><operator>(</operator><name>tuple</name> <operator>=</operator> <call><name>sts_parallel_scan_next</name><argument_list>(<argument><expr><name><name>old_inner_tuples</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>, <argument><expr><operator>&amp;</operator><name>hashvalue</name></expr></argument>)</argument_list></call><operator>)</operator></expr>)</condition>
		<block>{<block_content>
			<decl_stmt><decl><type><name>size_t</name></type>		<name>tuple_size</name> <init>= <expr><call><name>MAXALIGN</name><argument_list>(<argument><expr><name>HJTUPLE_OVERHEAD</name> <operator>+</operator> <name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>int</name></type>			<name>bucketno</name></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>int</name></type>			<name>batchno</name></decl>;</decl_stmt>

			<comment type="block">/* Decide which partition it goes to in the new generation. */</comment>
			<expr_stmt><expr><call><name>ExecHashGetBucketAndBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>hashvalue</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>bucketno</name></expr></argument>,
									  <argument><expr><operator>&amp;</operator><name>batchno</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>estimated_size</name> <operator>+=</operator> <name>tuple_size</name></expr>;</expr_stmt>
			<expr_stmt><expr><operator>++</operator><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>ntuples</name></expr>;</expr_stmt>
			<expr_stmt><expr><operator>++</operator><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name><operator>.</operator><name>old_ntuples</name></expr>;</expr_stmt>

			<comment type="block">/* Store the tuple its new batch. */</comment>
			<expr_stmt><expr><call><name>sts_puttuple</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>inner_tuples</name></expr></argument>,
						 <argument><expr><operator>&amp;</operator><name>hashvalue</name></expr></argument>, <argument><expr><name>tuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<expr_stmt><expr><call><name>CHECK_FOR_INTERRUPTS</name><argument_list>()</argument_list></call></expr>;</expr_stmt>
		</block_content>}</block></while>
		<expr_stmt><expr><call><name>sts_end_parallel_scan</name><argument_list>(<argument><expr><name><name>old_inner_tuples</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></for>

	<expr_stmt><expr><call><name>pfree</name><argument_list>(<argument><expr><name>old_inner_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Transfer the backend-local per-batch counters to the shared totals.
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecParallelHashMergeCounters</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

	<expr_stmt><expr><call><name>LWLockAcquire</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>, <argument><expr><name>LW_EXCLUSIVE</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>total_tuples</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control>
	<block>{<block_content>
		<decl_stmt><decl><type><name>ParallelHashJoinBatchAccessor</name> <modifier>*</modifier></type><name>batch</name> <init>= <expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name></expr></init></decl>;</decl_stmt>

		<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>shared</name><operator>-&gt;</operator><name>size</name></name> <operator>+=</operator> <name><name>batch</name><operator>-&gt;</operator><name>size</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>shared</name><operator>-&gt;</operator><name>estimated_size</name></name> <operator>+=</operator> <name><name>batch</name><operator>-&gt;</operator><name>estimated_size</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>shared</name><operator>-&gt;</operator><name>ntuples</name></name> <operator>+=</operator> <name><name>batch</name><operator>-&gt;</operator><name>ntuples</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>shared</name><operator>-&gt;</operator><name>old_ntuples</name></name> <operator>+=</operator> <name><name>batch</name><operator>-&gt;</operator><name>old_ntuples</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>size</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>estimated_size</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>ntuples</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>old_ntuples</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>total_tuples</name></name> <operator>+=</operator> <name><name>batch</name><operator>-&gt;</operator><name>shared</name><operator>-&gt;</operator><name>ntuples</name></name></expr>;</expr_stmt>
	</block_content>}</block></for>
	<expr_stmt><expr><call><name>LWLockRelease</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * ExecHashIncreaseNumBuckets
 *		increase the original number of buckets in order to reduce
 *		number of tuples per bucket
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecHashIncreaseNumBuckets</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>HashMemoryChunk</name></type> <name>chunk</name></decl>;</decl_stmt>

	<comment type="block">/* do nothing if not an increase (it's called increase for a reason) */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>&gt;=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name></expr>)</condition><block type="pseudo"><block_content>
		<return>return;</return></block_content></block></if></if_stmt>

<cpp:ifdef>#<cpp:directive>ifdef</cpp:directive> <name>HJDEBUG</name></cpp:ifdef>
	<expr_stmt><expr><call><name>printf</name><argument_list>(<argument><expr><literal type="string">"Hashjoin %p: increasing nbuckets %d =&gt; %d\n"</literal></expr></argument>,
		   <argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></argument>, <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
<cpp:endif>#<cpp:directive>endif</cpp:directive></cpp:endif>

	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>log2_nbuckets</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>log2_nbuckets_optimal</name></name></expr>;</expr_stmt>

	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>&gt;</operator> <literal type="number">1</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>&lt;=</operator> <operator>(</operator><name>INT_MAX</name> <operator>/</operator> <literal type="number">2</literal><operator>)</operator></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>==</operator> <operator>(</operator><literal type="number">1</literal> <operator>&lt;&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>log2_nbuckets</name></name><operator>)</operator></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * Just reallocate the proper number of buckets - we don't need to walk
	 * through them - we can walk the dense-allocated chunks (just like in
	 * ExecHashIncreaseNumBatches, but without all the copying into new
	 * chunks)
	 */</comment>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name></name> <operator>=</operator>
		<operator>(</operator><name>HashJoinTuple</name> <operator>*</operator><operator>)</operator> <call><name>repalloc</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name></name></expr></argument>,
								   <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><call><name>memset</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name></name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>,
		   <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* scan through all tuples in all chunks to rebuild the hash table */</comment>
	<for>for <control>(<init><expr><name>chunk</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name></expr>;</init> <condition><expr><name>chunk</name> <operator>!=</operator> <name>NULL</name></expr>;</condition> <incr><expr><name>chunk</name> <operator>=</operator> <name><name>chunk</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name></expr></incr>)</control>
	<block>{<block_content>
		<comment type="block">/* process all tuples stored in this chunk */</comment>
		<decl_stmt><decl><type><name>size_t</name></type>		<name>idx</name> <init>= <expr><literal type="number">0</literal></expr></init></decl>;</decl_stmt>

		<while>while <condition>(<expr><name>idx</name> <operator>&lt;</operator> <name><name>chunk</name><operator>-&gt;</operator><name>used</name></name></expr>)</condition>
		<block>{<block_content>
			<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name> <init>= <expr><operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <operator>(</operator><call><name>HASH_CHUNK_DATA</name><argument_list>(<argument><expr><name>chunk</name></expr></argument>)</argument_list></call> <operator>+</operator> <name>idx</name><operator>)</operator></expr></init></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>int</name></type>			<name>bucketno</name></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>int</name></type>			<name>batchno</name></decl>;</decl_stmt>

			<expr_stmt><expr><call><name>ExecHashGetBucketAndBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name></expr></argument>,
									  <argument><expr><operator>&amp;</operator><name>bucketno</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>batchno</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<comment type="block">/* add the tuple to the proper bucket */</comment>
			<expr_stmt><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name><index>[<expr><name>bucketno</name></expr>]</index></name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name><index>[<expr><name>bucketno</name></expr>]</index></name> <operator>=</operator> <name>hashTuple</name></expr>;</expr_stmt>

			<comment type="block">/* advance index past the tuple */</comment>
			<expr_stmt><expr><name>idx</name> <operator>+=</operator> <call><name>MAXALIGN</name><argument_list>(<argument><expr><name>HJTUPLE_OVERHEAD</name> <operator>+</operator>
							<call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call><operator>-&gt;</operator><name>t_len</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		</block_content>}</block></while>

		<comment type="block">/* allow this loop to be cancellable */</comment>
		<expr_stmt><expr><call><name>CHECK_FOR_INTERRUPTS</name><argument_list>()</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></for>
</block_content>}</block></function>

<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecParallelHashIncreaseNumBuckets</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashMemoryChunk</name></type> <name>chunk</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>dsa_pointer</name></type> <name>chunk_s</name></decl>;</decl_stmt>

	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>build_barrier</name></name></expr></argument>)</argument_list></call> <operator>==</operator> <name>PHJ_BUILD_HASHING_INNER</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * It's unlikely, but we need to be prepared for new participants to show
	 * up while we're in the middle of this operation so we need to switch on
	 * barrier phase here.
	 */</comment>
	<switch>switch <condition>(<expr><call><name>PHJ_GROW_BUCKETS_PHASE</name><argument_list>(<argument><expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_buckets_barrier</name></name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>)</condition>
	<block>{<block_content>
		<case>case <expr><name>PHJ_GROW_BUCKETS_ELECTING</name></expr>:</case>
			<comment type="block">/* Elect one participant to prepare to increase nbuckets. */</comment>
			<if_stmt><if>if <condition>(<expr><call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_buckets_barrier</name></name></expr></argument>,
									 <argument><expr><name>WAIT_EVENT_HASH_GROW_BUCKETS_ELECT</name></expr></argument>)</argument_list></call></expr>)</condition>
			<block>{<block_content>
				<decl_stmt><decl><type><name>size_t</name></type>		<name>size</name></decl>;</decl_stmt>
				<decl_stmt><decl><type><name>dsa_pointer_atomic</name> <modifier>*</modifier></type><name>buckets</name></decl>;</decl_stmt>

				<comment type="block">/* Double the size of the bucket array. */</comment>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>*=</operator> <literal type="number">2</literal></expr>;</expr_stmt>
				<expr_stmt><expr><name>size</name> <operator>=</operator> <name><name>pstate</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>dsa_pointer_atomic</name></expr></argument>)</argument_list></sizeof></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>size</name></name> <operator>+=</operator> <name>size</name> <operator>/</operator> <literal type="number">2</literal></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>dsa_free</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>buckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>buckets</name></name> <operator>=</operator>
					<call><name>dsa_allocate</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name>size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><name>buckets</name> <operator>=</operator> <operator>(</operator><name>dsa_pointer_atomic</name> <operator>*</operator><operator>)</operator>
					<call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>,
									<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>buckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>pstate</name><operator>-&gt;</operator><name>nbuckets</name></name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control><block type="pseudo"><block_content>
					<expr_stmt><expr><call><name>dsa_pointer_atomic_init</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>buckets</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>, <argument><expr><name>InvalidDsaPointer</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></for>

				<comment type="block">/* Put the chunk list onto the work queue. */</comment>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>chunk_work_queue</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>chunks</name></name></expr>;</expr_stmt>

				<comment type="block">/* Clear the flag. */</comment>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>=</operator> <name>PHJ_GROWTH_OK</name></expr>;</expr_stmt>
			</block_content>}</block></if></if_stmt>
			<comment type="block">/* Fall through. */</comment>

		<case>case <expr><name>PHJ_GROW_BUCKETS_ALLOCATING</name></expr>:</case>
			<comment type="block">/* Wait for the above to complete. */</comment>
			<expr_stmt><expr><call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_buckets_barrier</name></name></expr></argument>,
								 <argument><expr><name>WAIT_EVENT_HASH_GROW_BUCKETS_ALLOCATE</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<comment type="block">/* Fall through. */</comment>

		<case>case <expr><name>PHJ_GROW_BUCKETS_REINSERTING</name></expr>:</case>
			<comment type="block">/* Reinsert all tuples into the hash table. */</comment>
			<expr_stmt><expr><call><name>ExecParallelHashEnsureBatchAccessors</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>ExecParallelHashTableSetCurrentBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<while>while <condition>(<expr><operator>(</operator><name>chunk</name> <operator>=</operator> <call><name>ExecParallelHashPopChunkQueue</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>chunk_s</name></expr></argument>)</argument_list></call><operator>)</operator></expr>)</condition>
			<block>{<block_content>
				<decl_stmt><decl><type><name>size_t</name></type>		<name>idx</name> <init>= <expr><literal type="number">0</literal></expr></init></decl>;</decl_stmt>

				<while>while <condition>(<expr><name>idx</name> <operator>&lt;</operator> <name><name>chunk</name><operator>-&gt;</operator><name>used</name></name></expr>)</condition>
				<block>{<block_content>
					<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name> <init>= <expr><operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <operator>(</operator><call><name>HASH_CHUNK_DATA</name><argument_list>(<argument><expr><name>chunk</name></expr></argument>)</argument_list></call> <operator>+</operator> <name>idx</name><operator>)</operator></expr></init></decl>;</decl_stmt>
					<decl_stmt><decl><type><name>dsa_pointer</name></type> <name>shared</name> <init>= <expr><name>chunk_s</name> <operator>+</operator> <name>HASH_CHUNK_HEADER_SIZE</name> <operator>+</operator> <name>idx</name></expr></init></decl>;</decl_stmt>
					<decl_stmt><decl><type><name>int</name></type>			<name>bucketno</name></decl>;</decl_stmt>
					<decl_stmt><decl><type><name>int</name></type>			<name>batchno</name></decl>;</decl_stmt>

					<expr_stmt><expr><call><name>ExecHashGetBucketAndBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name></expr></argument>,
											  <argument><expr><operator>&amp;</operator><name>bucketno</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>batchno</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
					<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>batchno</name> <operator>==</operator> <literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>

					<comment type="block">/* add the tuple to the proper bucket */</comment>
					<expr_stmt><expr><call><name>ExecParallelHashPushTuple</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>shared</name><index>[<expr><name>bucketno</name></expr>]</index></name></expr></argument>,
											  <argument><expr><name>hashTuple</name></expr></argument>, <argument><expr><name>shared</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

					<comment type="block">/* advance index past the tuple */</comment>
					<expr_stmt><expr><name>idx</name> <operator>+=</operator> <call><name>MAXALIGN</name><argument_list>(<argument><expr><name>HJTUPLE_OVERHEAD</name> <operator>+</operator>
									<call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call><operator>-&gt;</operator><name>t_len</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				</block_content>}</block></while>

				<comment type="block">/* allow this loop to be cancellable */</comment>
				<expr_stmt><expr><call><name>CHECK_FOR_INTERRUPTS</name><argument_list>()</argument_list></call></expr>;</expr_stmt>
			</block_content>}</block></while>
			<expr_stmt><expr><call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>grow_buckets_barrier</name></name></expr></argument>,
								 <argument><expr><name>WAIT_EVENT_HASH_GROW_BUCKETS_REINSERT</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></switch>
</block_content>}</block></function>

<comment type="block">/*
 * ExecHashTableInsert
 *		insert a tuple into the hash table depending on the hash value
 *		it may just go to a temp file for later batches
 *
 * Note: the passed TupleTableSlot may contain a regular, minimal, or virtual
 * tuple; the minimal case in particular is certain to happen while reloading
 * tuples from batch files.  We could save some cycles in the regular-tuple
 * case by not forcing the slot contents into minimal form; not clear if it's
 * worth the messiness required.
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashTableInsert</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>,
					<parameter><decl><type><name>TupleTableSlot</name> <modifier>*</modifier></type><name>slot</name></decl></parameter>,
					<parameter><decl><type><name>uint32</name></type> <name>hashvalue</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>bool</name></type>		<name>shouldFree</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>MinimalTuple</name></type> <name>tuple</name> <init>= <expr><call><name>ExecFetchSlotMinimalTuple</name><argument_list>(<argument><expr><name>slot</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>shouldFree</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>bucketno</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>batchno</name></decl>;</decl_stmt>

	<expr_stmt><expr><call><name>ExecHashGetBucketAndBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>hashvalue</name></expr></argument>,
							  <argument><expr><operator>&amp;</operator><name>bucketno</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>batchno</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * decide whether to put the tuple in the hash table or a temp file
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name>batchno</name> <operator>==</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name></expr>)</condition>
	<block>{<block_content>
		<comment type="block">/*
		 * put the tuple in hash table
		 */</comment>
		<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>int</name></type>			<name>hashTupleSize</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>double</name></type>		<name>ntuples</name> <init>= <expr><operator>(</operator><name><name>hashtable</name><operator>-&gt;</operator><name>totalTuples</name></name> <operator>-</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>skewTuples</name></name><operator>)</operator></expr></init></decl>;</decl_stmt>

		<comment type="block">/* Create the HashJoinTuple */</comment>
		<expr_stmt><expr><name>hashTupleSize</name> <operator>=</operator> <name>HJTUPLE_OVERHEAD</name> <operator>+</operator> <name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <call><name>dense_alloc</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>hashTupleSize</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<expr_stmt><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name> <operator>=</operator> <name>hashvalue</name></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>memcpy</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>, <argument><expr><name>tuple</name></expr></argument>, <argument><expr><name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/*
		 * We always reset the tuple-matched flag on insertion.  This is okay
		 * even when reloading a tuple from a batch file, since the tuple
		 * could not possibly have been matched to an outer tuple before it
		 * went into the batch file.
		 */</comment>
		<expr_stmt><expr><call><name>HeapTupleHeaderClearMatch</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/* Push it onto the front of the bucket's list */</comment>
		<expr_stmt><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name><index>[<expr><name>bucketno</name></expr>]</index></name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name><index>[<expr><name>bucketno</name></expr>]</index></name> <operator>=</operator> <name>hashTuple</name></expr>;</expr_stmt>

		<comment type="block">/*
		 * Increase the (optimal) number of buckets if we just exceeded the
		 * NTUP_PER_BUCKET threshold, but only when there's still a single
		 * batch.
		 */</comment>
		<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>==</operator> <literal type="number">1</literal> <operator>&amp;&amp;</operator>
			<name>ntuples</name> <operator>&gt;</operator> <operator>(</operator><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name> <operator>*</operator> <name>NTUP_PER_BUCKET</name><operator>)</operator></expr>)</condition>
		<block>{<block_content>
			<comment type="block">/* Guard against integer overflow and alloc size overflow */</comment>
			<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name> <operator>&lt;=</operator> <name>INT_MAX</name> <operator>/</operator> <literal type="number">2</literal> <operator>&amp;&amp;</operator>
				<name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name> <operator>*</operator> <literal type="number">2</literal> <operator>&lt;=</operator> <name>MaxAllocSize</name> <operator>/</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof></expr>)</condition>
			<block>{<block_content>
				<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name> <operator>*=</operator> <literal type="number">2</literal></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>log2_nbuckets_optimal</name></name> <operator>+=</operator> <literal type="number">1</literal></expr>;</expr_stmt>
			</block_content>}</block></if></if_stmt>
		</block_content>}</block></if></if_stmt>

		<comment type="block">/* Account for space used, and back off if we've used too much */</comment>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>+=</operator> <name>hashTupleSize</name></expr>;</expr_stmt>
		<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>&gt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name></expr>;</expr_stmt></block_content></block></if></if_stmt>
		<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>+</operator>
			<name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_optimal</name></name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof>
			<operator>&gt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spaceAllowed</name></name></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><call><name>ExecHashIncreaseNumBatches</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
	</block_content>}</block></if>
	<else>else
	<block>{<block_content>
		<comment type="block">/*
		 * put the tuple into a temp file for later batches
		 */</comment>
		<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>batchno</name> <operator>&gt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>ExecHashJoinSaveTuple</name><argument_list>(<argument><expr><name>tuple</name></expr></argument>,
							  <argument><expr><name>hashvalue</name></expr></argument>,
							  <argument><expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name><index>[<expr><name>batchno</name></expr>]</index></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></else></if_stmt>

	<if_stmt><if>if <condition>(<expr><name>shouldFree</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>heap_free_minimal_tuple</name><argument_list>(<argument><expr><name>tuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * ExecParallelHashTableInsert
 *		insert a tuple into a shared hash table or shared batch tuplestore
 */</comment>
<function><type><name>void</name></type>
<name>ExecParallelHashTableInsert</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>,
							<parameter><decl><type><name>TupleTableSlot</name> <modifier>*</modifier></type><name>slot</name></decl></parameter>,
							<parameter><decl><type><name>uint32</name></type> <name>hashvalue</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>bool</name></type>		<name>shouldFree</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>MinimalTuple</name></type> <name>tuple</name> <init>= <expr><call><name>ExecFetchSlotMinimalTuple</name><argument_list>(<argument><expr><name>slot</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>shouldFree</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>dsa_pointer</name></type> <name>shared</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>bucketno</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>batchno</name></decl>;</decl_stmt>

<label><name>retry</name>:</label>
	<expr_stmt><expr><call><name>ExecHashGetBucketAndBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>hashvalue</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>bucketno</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>batchno</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<if_stmt><if>if <condition>(<expr><name>batchno</name> <operator>==</operator> <literal type="number">0</literal></expr>)</condition>
	<block>{<block_content>
		<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name></decl>;</decl_stmt>

		<comment type="block">/* Try to load it into memory. */</comment>
		<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name><operator>-&gt;</operator><name>build_barrier</name></name></expr></argument>)</argument_list></call> <operator>==</operator>
			   <name>PHJ_BUILD_HASHING_INNER</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <call><name>ExecParallelHashTupleAlloc</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>,
											   <argument><expr><name>HJTUPLE_OVERHEAD</name> <operator>+</operator> <name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr></argument>,
											   <argument><expr><operator>&amp;</operator><name>shared</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<if_stmt><if>if <condition>(<expr><name>hashTuple</name> <operator>==</operator> <name>NULL</name></expr>)</condition><block type="pseudo"><block_content>
			<goto>goto <name>retry</name>;</goto></block_content></block></if></if_stmt>

		<comment type="block">/* Store the hash value in the HashJoinTuple header. */</comment>
		<expr_stmt><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name> <operator>=</operator> <name>hashvalue</name></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>memcpy</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>, <argument><expr><name>tuple</name></expr></argument>, <argument><expr><name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/* Push it onto the front of the bucket's list */</comment>
		<expr_stmt><expr><call><name>ExecParallelHashPushTuple</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>shared</name><index>[<expr><name>bucketno</name></expr>]</index></name></expr></argument>,
								  <argument><expr><name>hashTuple</name></expr></argument>, <argument><expr><name>shared</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></if>
	<else>else
	<block>{<block_content>
		<decl_stmt><decl><type><name>size_t</name></type>		<name>tuple_size</name> <init>= <expr><call><name>MAXALIGN</name><argument_list>(<argument><expr><name>HJTUPLE_OVERHEAD</name> <operator>+</operator> <name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>

		<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>batchno</name> <operator>&gt;</operator> <literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/* Try to preallocate space in the batch if necessary. */</comment>
		<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>preallocated</name> <operator>&lt;</operator> <name>tuple_size</name></expr>)</condition>
		<block>{<block_content>
			<if_stmt><if>if <condition>(<expr><operator>!</operator><call><name>ExecParallelHashTuplePrealloc</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>batchno</name></expr></argument>, <argument><expr><name>tuple_size</name></expr></argument>)</argument_list></call></expr>)</condition><block type="pseudo"><block_content>
				<goto>goto <name>retry</name>;</goto></block_content></block></if></if_stmt>
		</block_content>}</block></if></if_stmt>

		<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>preallocated</name> <operator>&gt;=</operator> <name>tuple_size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>preallocated</name> <operator>-=</operator> <name>tuple_size</name></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>sts_puttuple</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>inner_tuples</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>hashvalue</name></expr></argument>,
					 <argument><expr><name>tuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></else></if_stmt>
	<expr_stmt><expr><operator>++</operator><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>ntuples</name></expr>;</expr_stmt>

	<if_stmt><if>if <condition>(<expr><name>shouldFree</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>heap_free_minimal_tuple</name><argument_list>(<argument><expr><name>tuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Insert a tuple into the current hash table.  Unlike
 * ExecParallelHashTableInsert, this version is not prepared to send the tuple
 * to other batches or to run out of memory, and should only be called with
 * tuples that belong in the current batch once growth has been disabled.
 */</comment>
<function><type><name>void</name></type>
<name>ExecParallelHashTableInsertCurrentBatch</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>,
										<parameter><decl><type><name>TupleTableSlot</name> <modifier>*</modifier></type><name>slot</name></decl></parameter>,
										<parameter><decl><type><name>uint32</name></type> <name>hashvalue</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>bool</name></type>		<name>shouldFree</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>MinimalTuple</name></type> <name>tuple</name> <init>= <expr><call><name>ExecFetchSlotMinimalTuple</name><argument_list>(<argument><expr><name>slot</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>shouldFree</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>dsa_pointer</name></type> <name>shared</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>batchno</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>bucketno</name></decl>;</decl_stmt>

	<expr_stmt><expr><call><name>ExecHashGetBucketAndBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>hashvalue</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>bucketno</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>batchno</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>batchno</name> <operator>==</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <call><name>ExecParallelHashTupleAlloc</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>,
										   <argument><expr><name>HJTUPLE_OVERHEAD</name> <operator>+</operator> <name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr></argument>,
										   <argument><expr><operator>&amp;</operator><name>shared</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name> <operator>=</operator> <name>hashvalue</name></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>memcpy</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>, <argument><expr><name>tuple</name></expr></argument>, <argument><expr><name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>HeapTupleHeaderClearMatch</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>ExecParallelHashPushTuple</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>shared</name><index>[<expr><name>bucketno</name></expr>]</index></name></expr></argument>,
							  <argument><expr><name>hashTuple</name></expr></argument>, <argument><expr><name>shared</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<if_stmt><if>if <condition>(<expr><name>shouldFree</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>heap_free_minimal_tuple</name><argument_list>(<argument><expr><name>tuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * ExecHashGetHashValue
 *		Compute the hash value for a tuple
 *
 * The tuple to be tested must be in econtext-&gt;ecxt_outertuple (thus Vars in
 * the hashkeys expressions need to have OUTER_VAR as varno). If outer_tuple
 * is false (meaning it's the HashJoin's inner node, Hash), econtext,
 * hashkeys, and slot need to be from Hash, with hashkeys/slot referencing and
 * being suitable for tuples from the node below the Hash. Conversely, if
 * outer_tuple is true, econtext is from HashJoin, and hashkeys/slot need to
 * be appropriate for tuples from HashJoin's outer node.
 *
 * A true result means the tuple's hash value has been successfully computed
 * and stored at *hashvalue.  A false result means the tuple cannot match
 * because it contains a null attribute, and hence it should be discarded
 * immediately.  (If keep_nulls is true then false is never returned.)
 */</comment>
<function><type><name>bool</name></type>
<name>ExecHashGetHashValue</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>,
					 <parameter><decl><type><name>ExprContext</name> <modifier>*</modifier></type><name>econtext</name></decl></parameter>,
					 <parameter><decl><type><name>List</name> <modifier>*</modifier></type><name>hashkeys</name></decl></parameter>,
					 <parameter><decl><type><name>bool</name></type> <name>outer_tuple</name></decl></parameter>,
					 <parameter><decl><type><name>bool</name></type> <name>keep_nulls</name></decl></parameter>,
					 <parameter><decl><type><name>uint32</name> <modifier>*</modifier></type><name>hashvalue</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>uint32</name></type>		<name>hashkey</name> <init>= <expr><literal type="number">0</literal></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>FmgrInfo</name>   <modifier>*</modifier></type><name>hashfunctions</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>ListCell</name>   <modifier>*</modifier></type><name>hk</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name> <init>= <expr><literal type="number">0</literal></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>MemoryContext</name></type> <name>oldContext</name></decl>;</decl_stmt>

	<comment type="block">/*
	 * We reset the eval context each time to reclaim any memory leaked in the
	 * hashkey expressions.
	 */</comment>
	<expr_stmt><expr><call><name>ResetExprContext</name><argument_list>(<argument><expr><name>econtext</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><name>oldContext</name> <operator>=</operator> <call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name><name>econtext</name><operator>-&gt;</operator><name>ecxt_per_tuple_memory</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<if_stmt><if>if <condition>(<expr><name>outer_tuple</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><name>hashfunctions</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>outer_hashfunctions</name></name></expr>;</expr_stmt></block_content></block></if>
	<else>else<block type="pseudo"><block_content>
		<expr_stmt><expr><name>hashfunctions</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>inner_hashfunctions</name></name></expr>;</expr_stmt></block_content></block></else></if_stmt>

	<macro><name>foreach</name><argument_list>(<argument>hk</argument>, <argument>hashkeys</argument>)</argument_list></macro>
	<block>{<block_content>
		<decl_stmt><decl><type><name>ExprState</name>  <modifier>*</modifier></type><name>keyexpr</name> <init>= <expr><operator>(</operator><name>ExprState</name> <operator>*</operator><operator>)</operator> <call><name>lfirst</name><argument_list>(<argument><expr><name>hk</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>Datum</name></type>		<name>keyval</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>bool</name></type>		<name>isNull</name></decl>;</decl_stmt>

		<comment type="block">/* rotate hashkey left 1 bit at each step */</comment>
		<expr_stmt><expr><name>hashkey</name> <operator>=</operator> <operator>(</operator><name>hashkey</name> <operator>&lt;&lt;</operator> <literal type="number">1</literal><operator>)</operator> <operator>|</operator> <operator>(</operator><ternary><condition><expr><operator>(</operator><name>hashkey</name> <operator>&amp;</operator> <literal type="number">0x80000000</literal><operator>)</operator></expr> ?</condition><then> <expr><literal type="number">1</literal></expr> </then><else>: <expr><literal type="number">0</literal></expr></else></ternary><operator>)</operator></expr>;</expr_stmt>

		<comment type="block">/*
		 * Get the join attribute value of the tuple
		 */</comment>
		<expr_stmt><expr><name>keyval</name> <operator>=</operator> <call><name>ExecEvalExpr</name><argument_list>(<argument><expr><name>keyexpr</name></expr></argument>, <argument><expr><name>econtext</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>isNull</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/*
		 * If the attribute is NULL, and the join operator is strict, then
		 * this tuple cannot pass the join qual so we can reject it
		 * immediately (unless we're scanning the outside of an outer join, in
		 * which case we must not reject it).  Otherwise we act like the
		 * hashcode of NULL is zero (this will support operators that act like
		 * IS NOT DISTINCT, though not any more-random behavior).  We treat
		 * the hash support function as strict even if the operator is not.
		 *
		 * Note: currently, all hashjoinable operators must be strict since
		 * the hash index AM assumes that.  However, it takes so little extra
		 * code here to allow non-strict that we may as well do it.
		 */</comment>
		<if_stmt><if>if <condition>(<expr><name>isNull</name></expr>)</condition>
		<block>{<block_content>
			<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>hashStrict</name><index>[<expr><name>i</name></expr>]</index></name> <operator>&amp;&amp;</operator> <operator>!</operator><name>keep_nulls</name></expr>)</condition>
			<block>{<block_content>
				<expr_stmt><expr><call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name>oldContext</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<return>return <expr><name>false</name></expr>;</return>	<comment type="block">/* cannot match */</comment>
			</block_content>}</block></if></if_stmt>
			<comment type="block">/* else, leave hashkey unmodified, equivalent to hashcode 0 */</comment>
		</block_content>}</block></if>
		<else>else
		<block>{<block_content>
			<comment type="block">/* Compute the hash function */</comment>
			<decl_stmt><decl><type><name>uint32</name></type>		<name>hkey</name></decl>;</decl_stmt>

			<expr_stmt><expr><name>hkey</name> <operator>=</operator> <call><name>DatumGetUInt32</name><argument_list>(<argument><expr><call><name>FunctionCall1Coll</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>hashfunctions</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>, <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>collations</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>, <argument><expr><name>keyval</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><name>hashkey</name> <operator>^=</operator> <name>hkey</name></expr>;</expr_stmt>
		</block_content>}</block></else></if_stmt>

		<expr_stmt><expr><name>i</name><operator>++</operator></expr>;</expr_stmt>
	</block_content>}</block>

	<expr_stmt><expr><call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name>oldContext</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><operator>*</operator><name>hashvalue</name> <operator>=</operator> <name>hashkey</name></expr>;</expr_stmt>
	<return>return <expr><name>true</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * ExecHashGetBucketAndBatch
 *		Determine the bucket number and batch number for a hash value
 *
 * Note: on-the-fly increases of nbatch must not change the bucket number
 * for a given hash code (since we don't move tuples to different hash
 * chains), and must only cause the batch number to remain the same or
 * increase.  Our algorithm is
 *		bucketno = hashvalue MOD nbuckets
 *		batchno = ROR(hashvalue, log2_nbuckets) MOD nbatch
 * where nbuckets and nbatch are both expected to be powers of 2, so we can
 * do the computations by shifting and masking.  (This assumes that all hash
 * functions are good about randomizing all their output bits, else we are
 * likely to have very skewed bucket or batch occupancy.)
 *
 * nbuckets and log2_nbuckets may change while nbatch == 1 because of dynamic
 * bucket count growth.  Once we start batching, the value is fixed and does
 * not change over the course of the join (making it possible to compute batch
 * number the way we do here).
 *
 * nbatch is always a power of 2; we increase it only by doubling it.  This
 * effectively adds one more bit to the top of the batchno.  In very large
 * joins, we might run out of bits to add, so we do this by rotating the hash
 * value.  This causes batchno to steal bits from bucketno when the number of
 * virtual buckets exceeds 2^32.  It's better to have longer bucket chains
 * than to lose the ability to divide batches.
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashGetBucketAndBatch</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>,
						  <parameter><decl><type><name>uint32</name></type> <name>hashvalue</name></decl></parameter>,
						  <parameter><decl><type><name>int</name> <modifier>*</modifier></type><name>bucketno</name></decl></parameter>,
						  <parameter><decl><type><name>int</name> <modifier>*</modifier></type><name>batchno</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>uint32</name></type>		<name>nbuckets</name> <init>= <expr><operator>(</operator><name>uint32</name><operator>)</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>uint32</name></type>		<name>nbatch</name> <init>= <expr><operator>(</operator><name>uint32</name><operator>)</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr></init></decl>;</decl_stmt>

	<if_stmt><if>if <condition>(<expr><name>nbatch</name> <operator>&gt;</operator> <literal type="number">1</literal></expr>)</condition>
	<block>{<block_content>
		<expr_stmt><expr><operator>*</operator><name>bucketno</name> <operator>=</operator> <name>hashvalue</name> <operator>&amp;</operator> <operator>(</operator><name>nbuckets</name> <operator>-</operator> <literal type="number">1</literal><operator>)</operator></expr>;</expr_stmt>
		<expr_stmt><expr><operator>*</operator><name>batchno</name> <operator>=</operator> <call><name>pg_rotate_right32</name><argument_list>(<argument><expr><name>hashvalue</name></expr></argument>,
									 <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>log2_nbuckets</name></name></expr></argument>)</argument_list></call> <operator>&amp;</operator> <operator>(</operator><name>nbatch</name> <operator>-</operator> <literal type="number">1</literal><operator>)</operator></expr>;</expr_stmt>
	</block_content>}</block></if>
	<else>else
	<block>{<block_content>
		<expr_stmt><expr><operator>*</operator><name>bucketno</name> <operator>=</operator> <name>hashvalue</name> <operator>&amp;</operator> <operator>(</operator><name>nbuckets</name> <operator>-</operator> <literal type="number">1</literal><operator>)</operator></expr>;</expr_stmt>
		<expr_stmt><expr><operator>*</operator><name>batchno</name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	</block_content>}</block></else></if_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * ExecScanHashBucket
 *		scan a hash bucket for matches to the current outer tuple
 *
 * The current outer tuple must be stored in econtext-&gt;ecxt_outertuple.
 *
 * On success, the inner tuple is stored into hjstate-&gt;hj_CurTuple and
 * econtext-&gt;ecxt_innertuple, using hjstate-&gt;hj_HashTupleSlot as the slot
 * for the latter.
 */</comment>
<function><type><name>bool</name></type>
<name>ExecScanHashBucket</name><parameter_list>(<parameter><decl><type><name>HashJoinState</name> <modifier>*</modifier></type><name>hjstate</name></decl></parameter>,
				   <parameter><decl><type><name>ExprContext</name> <modifier>*</modifier></type><name>econtext</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ExprState</name>  <modifier>*</modifier></type><name>hjclauses</name> <init>= <expr><name><name>hjstate</name><operator>-&gt;</operator><name>hashclauses</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTable</name></type> <name>hashtable</name> <init>= <expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_HashTable</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name> <init>= <expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurTuple</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>uint32</name></type>		<name>hashvalue</name> <init>= <expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurHashValue</name></name></expr></init></decl>;</decl_stmt>

	<comment type="block">/*
	 * hj_CurTuple is the address of the tuple last returned from the current
	 * bucket, or NULL if it's time to start scanning a new bucket.
	 *
	 * If the tuple hashed to a skew bucket then scan the skew bucket
	 * otherwise scan the standard hashtable bucket.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name>hashTuple</name> <operator>!=</operator> <name>NULL</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <name><name>hashTuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name></expr>;</expr_stmt></block_content></block></if>
	<if type="elseif">else if <condition>(<expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurSkewBucketNo</name></name> <operator>!=</operator> <name>INVALID_SKEW_BUCKET_NO</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurSkewBucketNo</name></name></expr>]</index></name><operator>-&gt;</operator><name>tuples</name></expr>;</expr_stmt></block_content></block></if>
	<else>else<block type="pseudo"><block_content>
		<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name><index>[<expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurBucketNo</name></name></expr>]</index></name></expr>;</expr_stmt></block_content></block></else></if_stmt>

	<while>while <condition>(<expr><name>hashTuple</name> <operator>!=</operator> <name>NULL</name></expr>)</condition>
	<block>{<block_content>
		<if_stmt><if>if <condition>(<expr><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name> <operator>==</operator> <name>hashvalue</name></expr>)</condition>
		<block>{<block_content>
			<decl_stmt><decl><type><name>TupleTableSlot</name> <modifier>*</modifier></type><name>inntuple</name></decl>;</decl_stmt>

			<comment type="block">/* insert hashtable's tuple into exec slot so ExecQual sees it */</comment>
			<expr_stmt><expr><name>inntuple</name> <operator>=</operator> <call><name>ExecStoreMinimalTuple</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>,
											 <argument><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_HashTupleSlot</name></name></expr></argument>,
											 <argument><expr><name>false</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>	<comment type="block">/* do not pfree */</comment>
			<expr_stmt><expr><name><name>econtext</name><operator>-&gt;</operator><name>ecxt_innertuple</name></name> <operator>=</operator> <name>inntuple</name></expr>;</expr_stmt>

			<if_stmt><if>if <condition>(<expr><call><name>ExecQualAndReset</name><argument_list>(<argument><expr><name>hjclauses</name></expr></argument>, <argument><expr><name>econtext</name></expr></argument>)</argument_list></call></expr>)</condition>
			<block>{<block_content>
				<expr_stmt><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurTuple</name></name> <operator>=</operator> <name>hashTuple</name></expr>;</expr_stmt>
				<return>return <expr><name>true</name></expr>;</return>
			</block_content>}</block></if></if_stmt>
		</block_content>}</block></if></if_stmt>

		<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <name><name>hashTuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name></expr>;</expr_stmt>
	</block_content>}</block></while>

	<comment type="block">/*
	 * no match
	 */</comment>
	<return>return <expr><name>false</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * ExecParallelScanHashBucket
 *		scan a hash bucket for matches to the current outer tuple
 *
 * The current outer tuple must be stored in econtext-&gt;ecxt_outertuple.
 *
 * On success, the inner tuple is stored into hjstate-&gt;hj_CurTuple and
 * econtext-&gt;ecxt_innertuple, using hjstate-&gt;hj_HashTupleSlot as the slot
 * for the latter.
 */</comment>
<function><type><name>bool</name></type>
<name>ExecParallelScanHashBucket</name><parameter_list>(<parameter><decl><type><name>HashJoinState</name> <modifier>*</modifier></type><name>hjstate</name></decl></parameter>,
						   <parameter><decl><type><name>ExprContext</name> <modifier>*</modifier></type><name>econtext</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ExprState</name>  <modifier>*</modifier></type><name>hjclauses</name> <init>= <expr><name><name>hjstate</name><operator>-&gt;</operator><name>hashclauses</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTable</name></type> <name>hashtable</name> <init>= <expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_HashTable</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name> <init>= <expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurTuple</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>uint32</name></type>		<name>hashvalue</name> <init>= <expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurHashValue</name></name></expr></init></decl>;</decl_stmt>

	<comment type="block">/*
	 * hj_CurTuple is the address of the tuple last returned from the current
	 * bucket, or NULL if it's time to start scanning a new bucket.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name>hashTuple</name> <operator>!=</operator> <name>NULL</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <call><name>ExecParallelHashNextTuple</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if>
	<else>else<block type="pseudo"><block_content>
		<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <call><name>ExecParallelHashFirstTuple</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>,
											   <argument><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurBucketNo</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></else></if_stmt>

	<while>while <condition>(<expr><name>hashTuple</name> <operator>!=</operator> <name>NULL</name></expr>)</condition>
	<block>{<block_content>
		<if_stmt><if>if <condition>(<expr><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name> <operator>==</operator> <name>hashvalue</name></expr>)</condition>
		<block>{<block_content>
			<decl_stmt><decl><type><name>TupleTableSlot</name> <modifier>*</modifier></type><name>inntuple</name></decl>;</decl_stmt>

			<comment type="block">/* insert hashtable's tuple into exec slot so ExecQual sees it */</comment>
			<expr_stmt><expr><name>inntuple</name> <operator>=</operator> <call><name>ExecStoreMinimalTuple</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>,
											 <argument><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_HashTupleSlot</name></name></expr></argument>,
											 <argument><expr><name>false</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>	<comment type="block">/* do not pfree */</comment>
			<expr_stmt><expr><name><name>econtext</name><operator>-&gt;</operator><name>ecxt_innertuple</name></name> <operator>=</operator> <name>inntuple</name></expr>;</expr_stmt>

			<if_stmt><if>if <condition>(<expr><call><name>ExecQualAndReset</name><argument_list>(<argument><expr><name>hjclauses</name></expr></argument>, <argument><expr><name>econtext</name></expr></argument>)</argument_list></call></expr>)</condition>
			<block>{<block_content>
				<expr_stmt><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurTuple</name></name> <operator>=</operator> <name>hashTuple</name></expr>;</expr_stmt>
				<return>return <expr><name>true</name></expr>;</return>
			</block_content>}</block></if></if_stmt>
		</block_content>}</block></if></if_stmt>

		<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <call><name>ExecParallelHashNextTuple</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></while>

	<comment type="block">/*
	 * no match
	 */</comment>
	<return>return <expr><name>false</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * ExecPrepHashTableForUnmatched
 *		set up for a series of ExecScanHashTableForUnmatched calls
 */</comment>
<function><type><name>void</name></type>
<name>ExecPrepHashTableForUnmatched</name><parameter_list>(<parameter><decl><type><name>HashJoinState</name> <modifier>*</modifier></type><name>hjstate</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<comment type="block">/*----------
	 * During this scan we use the HashJoinState fields as follows:
	 *
	 * hj_CurBucketNo: next regular bucket to scan
	 * hj_CurSkewBucketNo: next skew bucket (an index into skewBucketNums)
	 * hj_CurTuple: last tuple returned, or NULL to start next bucket
	 *----------
	 */</comment>
	<expr_stmt><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurBucketNo</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurSkewBucketNo</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurTuple</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * ExecScanHashTableForUnmatched
 *		scan the hash table for unmatched inner tuples
 *
 * On success, the inner tuple is stored into hjstate-&gt;hj_CurTuple and
 * econtext-&gt;ecxt_innertuple, using hjstate-&gt;hj_HashTupleSlot as the slot
 * for the latter.
 */</comment>
<function><type><name>bool</name></type>
<name>ExecScanHashTableForUnmatched</name><parameter_list>(<parameter><decl><type><name>HashJoinState</name> <modifier>*</modifier></type><name>hjstate</name></decl></parameter>, <parameter><decl><type><name>ExprContext</name> <modifier>*</modifier></type><name>econtext</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>HashJoinTable</name></type> <name>hashtable</name> <init>= <expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_HashTable</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name> <init>= <expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurTuple</name></name></expr></init></decl>;</decl_stmt>

	<for>for <control>(<init>;</init><condition>;</condition><incr/>)</control>
	<block>{<block_content>
		<comment type="block">/*
		 * hj_CurTuple is the address of the tuple last returned from the
		 * current bucket, or NULL if it's time to start scanning a new
		 * bucket.
		 */</comment>
		<if_stmt><if>if <condition>(<expr><name>hashTuple</name> <operator>!=</operator> <name>NULL</name></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <name><name>hashTuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name></expr>;</expr_stmt></block_content></block></if>
		<if type="elseif">else if <condition>(<expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurBucketNo</name></name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr>)</condition>
		<block>{<block_content>
			<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name><index>[<expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurBucketNo</name></name></expr>]</index></name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurBucketNo</name></name><operator>++</operator></expr>;</expr_stmt>
		</block_content>}</block></if>
		<if type="elseif">else if <condition>(<expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurSkewBucketNo</name></name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nSkewBuckets</name></name></expr>)</condition>
		<block>{<block_content>
			<decl_stmt><decl><type><name>int</name></type>			<name>j</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketNums</name><index>[<expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurSkewBucketNo</name></name></expr>]</index></name></expr></init></decl>;</decl_stmt>

			<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>j</name></expr>]</index></name><operator>-&gt;</operator><name>tuples</name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurSkewBucketNo</name></name><operator>++</operator></expr>;</expr_stmt>
		</block_content>}</block></if>
		<else>else<block type="pseudo"><block_content>
			<break>break;</break></block_content></block></else></if_stmt>				<comment type="block">/* finished all buckets */</comment>

		<while>while <condition>(<expr><name>hashTuple</name> <operator>!=</operator> <name>NULL</name></expr>)</condition>
		<block>{<block_content>
			<if_stmt><if>if <condition>(<expr><operator>!</operator><call><name>HeapTupleHeaderHasMatch</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>)</condition>
			<block>{<block_content>
				<decl_stmt><decl><type><name>TupleTableSlot</name> <modifier>*</modifier></type><name>inntuple</name></decl>;</decl_stmt>

				<comment type="block">/* insert hashtable's tuple into exec slot */</comment>
				<expr_stmt><expr><name>inntuple</name> <operator>=</operator> <call><name>ExecStoreMinimalTuple</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>,
												 <argument><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_HashTupleSlot</name></name></expr></argument>,
												 <argument><expr><name>false</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>	<comment type="block">/* do not pfree */</comment>
				<expr_stmt><expr><name><name>econtext</name><operator>-&gt;</operator><name>ecxt_innertuple</name></name> <operator>=</operator> <name>inntuple</name></expr>;</expr_stmt>

				<comment type="block">/*
				 * Reset temp memory each time; although this function doesn't
				 * do any qual eval, the caller will, so let's keep it
				 * parallel to ExecScanHashBucket.
				 */</comment>
				<expr_stmt><expr><call><name>ResetExprContext</name><argument_list>(<argument><expr><name>econtext</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

				<expr_stmt><expr><name><name>hjstate</name><operator>-&gt;</operator><name>hj_CurTuple</name></name> <operator>=</operator> <name>hashTuple</name></expr>;</expr_stmt>
				<return>return <expr><name>true</name></expr>;</return>
			</block_content>}</block></if></if_stmt>

			<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <name><name>hashTuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name></expr>;</expr_stmt>
		</block_content>}</block></while>

		<comment type="block">/* allow this loop to be cancellable */</comment>
		<expr_stmt><expr><call><name>CHECK_FOR_INTERRUPTS</name><argument_list>()</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></for>

	<comment type="block">/*
	 * no more unmatched tuples
	 */</comment>
	<return>return <expr><name>false</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * ExecHashTableReset
 *
 *		reset hash table header for new batch
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashTableReset</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>MemoryContext</name></type> <name>oldcxt</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>nbuckets</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></init></decl>;</decl_stmt>

	<comment type="block">/*
	 * Release all the hash buckets and tuples acquired in the prior pass, and
	 * reinitialize the context for a new pass.
	 */</comment>
	<expr_stmt><expr><call><name>MemoryContextReset</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batchCxt</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>oldcxt</name> <operator>=</operator> <call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batchCxt</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Reallocate and reinitialize the hash bucket headers. */</comment>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name></name> <operator>=</operator> <operator>(</operator><name>HashJoinTuple</name> <operator>*</operator><operator>)</operator>
		<call><name>palloc0</name><argument_list>(<argument><expr><name>nbuckets</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashJoinTuple</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>

	<expr_stmt><expr><call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name>oldcxt</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Forget the chunks (the memory was freed by the context reset above). */</comment>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * ExecHashTableResetMatchFlags
 *		Clear all the HeapTupleHeaderHasMatch flags in the table
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashTableResetMatchFlags</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>tuple</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

	<comment type="block">/* Reset all flags in the main table ... */</comment>
	<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr>;</condition> <incr><expr><name>i</name><operator>++</operator></expr></incr>)</control>
	<block>{<block_content>
		<for>for <control>(<init><expr><name>tuple</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name><index>[<expr><name>i</name></expr>]</index></name></expr>;</init> <condition><expr><name>tuple</name> <operator>!=</operator> <name>NULL</name></expr>;</condition>
			 <incr><expr><name>tuple</name> <operator>=</operator> <name><name>tuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name></expr></incr>)</control><block type="pseudo"><block_content>
			<expr_stmt><expr><call><name>HeapTupleHeaderClearMatch</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>tuple</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></for>
	</block_content>}</block></for>

	<comment type="block">/* ... and the same for the skew buckets, if any */</comment>
	<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nSkewBuckets</name></name></expr>;</condition> <incr><expr><name>i</name><operator>++</operator></expr></incr>)</control>
	<block>{<block_content>
		<decl_stmt><decl><type><name>int</name></type>			<name>j</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketNums</name><index>[<expr><name>i</name></expr>]</index></name></expr></init></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>HashSkewBucket</name> <modifier>*</modifier></type><name>skewBucket</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>j</name></expr>]</index></name></expr></init></decl>;</decl_stmt>

		<for>for <control>(<init><expr><name>tuple</name> <operator>=</operator> <name><name>skewBucket</name><operator>-&gt;</operator><name>tuples</name></name></expr>;</init> <condition><expr><name>tuple</name> <operator>!=</operator> <name>NULL</name></expr>;</condition> <incr><expr><name>tuple</name> <operator>=</operator> <name><name>tuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name></expr></incr>)</control><block type="pseudo"><block_content>
			<expr_stmt><expr><call><name>HeapTupleHeaderClearMatch</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>tuple</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></for>
	</block_content>}</block></for>
</block_content>}</block></function>


<function><type><name>void</name></type>
<name>ExecReScanHash</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<comment type="block">/*
	 * if chgParam of subnode is not null then plan will be re-scanned by
	 * first ExecProcNode.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>lefttree</name><operator>-&gt;</operator><name>chgParam</name></name> <operator>==</operator> <name>NULL</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>ExecReScan</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>lefttree</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
</block_content>}</block></function>


<comment type="block">/*
 * ExecHashBuildSkewHash
 *
 *		Set up for skew optimization if we can identify the most common values
 *		(MCVs) of the outer relation's join key.  We make a skew hash bucket
 *		for the hash value of each MCV, up to the number of slots allowed
 *		based on available memory.
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecHashBuildSkewHash</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>Hash</name> <modifier>*</modifier></type><name>node</name></decl></parameter>, <parameter><decl><type><name>int</name></type> <name>mcvsToUse</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>HeapTupleData</name> <modifier>*</modifier></type><name>statsTuple</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>AttStatsSlot</name></type> <name>sslot</name></decl>;</decl_stmt>

	<comment type="block">/* Do nothing if planner didn't identify the outer relation's join key */</comment>
	<if_stmt><if>if <condition>(<expr><operator>!</operator><call><name>OidIsValid</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>skewTable</name></name></expr></argument>)</argument_list></call></expr>)</condition><block type="pseudo"><block_content>
		<return>return;</return></block_content></block></if></if_stmt>
	<comment type="block">/* Also, do nothing if we don't have room for at least one skew bucket */</comment>
	<if_stmt><if>if <condition>(<expr><name>mcvsToUse</name> <operator>&lt;=</operator> <literal type="number">0</literal></expr>)</condition><block type="pseudo"><block_content>
		<return>return;</return></block_content></block></if></if_stmt>

	<comment type="block">/*
	 * Try to find the MCV statistics for the outer relation's join key.
	 */</comment>
	<expr_stmt><expr><name>statsTuple</name> <operator>=</operator> <call><name>SearchSysCache3</name><argument_list>(<argument><expr><name>STATRELATTINH</name></expr></argument>,
								 <argument><expr><call><name>ObjectIdGetDatum</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>skewTable</name></name></expr></argument>)</argument_list></call></expr></argument>,
								 <argument><expr><call><name>Int16GetDatum</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>skewColumn</name></name></expr></argument>)</argument_list></call></expr></argument>,
								 <argument><expr><call><name>BoolGetDatum</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>skewInherit</name></name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<if_stmt><if>if <condition>(<expr><operator>!</operator><call><name>HeapTupleIsValid</name><argument_list>(<argument><expr><name>statsTuple</name></expr></argument>)</argument_list></call></expr>)</condition><block type="pseudo"><block_content>
		<return>return;</return></block_content></block></if></if_stmt>

	<if_stmt><if>if <condition>(<expr><call><name>get_attstatsslot</name><argument_list>(<argument><expr><operator>&amp;</operator><name>sslot</name></expr></argument>, <argument><expr><name>statsTuple</name></expr></argument>,
						 <argument><expr><name>STATISTIC_KIND_MCV</name></expr></argument>, <argument><expr><name>InvalidOid</name></expr></argument>,
						 <argument><expr><name>ATTSTATSSLOT_VALUES</name> <operator>|</operator> <name>ATTSTATSSLOT_NUMBERS</name></expr></argument>)</argument_list></call></expr>)</condition>
	<block>{<block_content>
		<decl_stmt><decl><type><name>double</name></type>		<name>frac</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>int</name></type>			<name>nbuckets</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>FmgrInfo</name>   <modifier>*</modifier></type><name>hashfunctions</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

		<if_stmt><if>if <condition>(<expr><name>mcvsToUse</name> <operator>&gt;</operator> <name><name>sslot</name><operator>.</operator><name>nvalues</name></name></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><name>mcvsToUse</name> <operator>=</operator> <name><name>sslot</name><operator>.</operator><name>nvalues</name></name></expr>;</expr_stmt></block_content></block></if></if_stmt>

		<comment type="block">/*
		 * Calculate the expected fraction of outer relation that will
		 * participate in the skew optimization.  If this isn't at least
		 * SKEW_MIN_OUTER_FRACTION, don't use skew optimization.
		 */</comment>
		<expr_stmt><expr><name>frac</name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
		<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name>mcvsToUse</name></expr>;</condition> <incr><expr><name>i</name><operator>++</operator></expr></incr>)</control><block type="pseudo"><block_content>
			<expr_stmt><expr><name>frac</name> <operator>+=</operator> <name><name>sslot</name><operator>.</operator><name>numbers</name><index>[<expr><name>i</name></expr>]</index></name></expr>;</expr_stmt></block_content></block></for>
		<if_stmt><if>if <condition>(<expr><name>frac</name> <operator>&lt;</operator> <name>SKEW_MIN_OUTER_FRACTION</name></expr>)</condition>
		<block>{<block_content>
			<expr_stmt><expr><call><name>free_attstatsslot</name><argument_list>(<argument><expr><operator>&amp;</operator><name>sslot</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>ReleaseSysCache</name><argument_list>(<argument><expr><name>statsTuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<return>return;</return>
		</block_content>}</block></if></if_stmt>

		<comment type="block">/*
		 * Okay, set up the skew hashtable.
		 *
		 * skewBucket[] is an open addressing hashtable with a power of 2 size
		 * that is greater than the number of MCV values.  (This ensures there
		 * will be at least one null entry, so searches will always
		 * terminate.)
		 *
		 * Note: this code could fail if mcvsToUse exceeds INT_MAX/8 or
		 * MaxAllocSize/sizeof(void *)/8, but that is not currently possible
		 * since we limit pg_statistic entries to much less than that.
		 */</comment>
		<expr_stmt><expr><name>nbuckets</name> <operator>=</operator> <call><name>pg_nextpower2_32</name><argument_list>(<argument><expr><name>mcvsToUse</name> <operator>+</operator> <literal type="number">1</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<comment type="block">/* use two more bits just to help avoid collisions */</comment>
		<expr_stmt><expr><name>nbuckets</name> <operator>&lt;&lt;=</operator> <literal type="number">2</literal></expr>;</expr_stmt>

		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewEnabled</name></name> <operator>=</operator> <name>true</name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketLen</name></name> <operator>=</operator> <name>nbuckets</name></expr>;</expr_stmt>

		<comment type="block">/*
		 * We allocate the bucket memory in the hashtable's batch context. It
		 * is only needed during the first batch, and this ensures it will be
		 * automatically removed once the first batch is done.
		 */</comment>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name></name> <operator>=</operator> <operator>(</operator><name>HashSkewBucket</name> <operator>*</operator><operator>*</operator><operator>)</operator>
			<call><name>MemoryContextAllocZero</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batchCxt</name></name></expr></argument>,
								   <argument><expr><name>nbuckets</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashSkewBucket</name> <operator>*</operator></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketNums</name></name> <operator>=</operator> <operator>(</operator><name>int</name> <operator>*</operator><operator>)</operator>
			<call><name>MemoryContextAllocZero</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batchCxt</name></name></expr></argument>,
								   <argument><expr><name>mcvsToUse</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>int</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>+=</operator> <name>nbuckets</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashSkewBucket</name> <operator>*</operator></expr></argument>)</argument_list></sizeof>
			<operator>+</operator> <name>mcvsToUse</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>int</name></expr></argument>)</argument_list></sizeof></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsedSkew</name></name> <operator>+=</operator> <name>nbuckets</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashSkewBucket</name> <operator>*</operator></expr></argument>)</argument_list></sizeof>
			<operator>+</operator> <name>mcvsToUse</name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>int</name></expr></argument>)</argument_list></sizeof></expr>;</expr_stmt>
		<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>&gt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name></expr>;</expr_stmt></block_content></block></if></if_stmt>

		<comment type="block">/*
		 * Create a skew bucket for each MCV hash value.
		 *
		 * Note: it is very important that we create the buckets in order of
		 * decreasing MCV frequency.  If we have to remove some buckets, they
		 * must be removed in reverse order of creation (see notes in
		 * ExecHashRemoveNextSkewBucket) and we want the least common MCVs to
		 * be removed first.
		 */</comment>
		<expr_stmt><expr><name>hashfunctions</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>outer_hashfunctions</name></name></expr>;</expr_stmt>

		<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name>mcvsToUse</name></expr>;</condition> <incr><expr><name>i</name><operator>++</operator></expr></incr>)</control>
		<block>{<block_content>
			<decl_stmt><decl><type><name>uint32</name></type>		<name>hashvalue</name></decl>;</decl_stmt>
			<decl_stmt><decl><type><name>int</name></type>			<name>bucket</name></decl>;</decl_stmt>

			<expr_stmt><expr><name>hashvalue</name> <operator>=</operator> <call><name>DatumGetUInt32</name><argument_list>(<argument><expr><call><name>FunctionCall1Coll</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>hashfunctions</name><index>[<expr><literal type="number">0</literal></expr>]</index></name></expr></argument>,
														 <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>collations</name><index>[<expr><literal type="number">0</literal></expr>]</index></name></expr></argument>,
														 <argument><expr><name><name>sslot</name><operator>.</operator><name>values</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<comment type="block">/*
			 * While we have not hit a hole in the hashtable and have not hit
			 * the desired bucket, we have collided with some previous hash
			 * value, so try the next bucket location.  NB: this code must
			 * match ExecHashGetSkewBucket.
			 */</comment>
			<expr_stmt><expr><name>bucket</name> <operator>=</operator> <name>hashvalue</name> <operator>&amp;</operator> <operator>(</operator><name>nbuckets</name> <operator>-</operator> <literal type="number">1</literal><operator>)</operator></expr>;</expr_stmt>
			<while>while <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucket</name></expr>]</index></name> <operator>!=</operator> <name>NULL</name> <operator>&amp;&amp;</operator>
				   <name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucket</name></expr>]</index></name><operator>-&gt;</operator><name>hashvalue</name> <operator>!=</operator> <name>hashvalue</name></expr>)</condition><block type="pseudo"><block_content>
				<expr_stmt><expr><name>bucket</name> <operator>=</operator> <operator>(</operator><name>bucket</name> <operator>+</operator> <literal type="number">1</literal><operator>)</operator> <operator>&amp;</operator> <operator>(</operator><name>nbuckets</name> <operator>-</operator> <literal type="number">1</literal><operator>)</operator></expr>;</expr_stmt></block_content></block></while>

			<comment type="block">/*
			 * If we found an existing bucket with the same hashvalue, leave
			 * it alone.  It's okay for two MCVs to share a hashvalue.
			 */</comment>
			<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucket</name></expr>]</index></name> <operator>!=</operator> <name>NULL</name></expr>)</condition><block type="pseudo"><block_content>
				<continue>continue;</continue></block_content></block></if></if_stmt>

			<comment type="block">/* Okay, create a new skew bucket for this hashvalue. */</comment>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucket</name></expr>]</index></name> <operator>=</operator> <operator>(</operator><name>HashSkewBucket</name> <operator>*</operator><operator>)</operator>
				<call><name>MemoryContextAlloc</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batchCxt</name></name></expr></argument>,
								   <argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>HashSkewBucket</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucket</name></expr>]</index></name><operator>-&gt;</operator><name>hashvalue</name> <operator>=</operator> <name>hashvalue</name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucket</name></expr>]</index></name><operator>-&gt;</operator><name>tuples</name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketNums</name><index>[<expr><name><name>hashtable</name><operator>-&gt;</operator><name>nSkewBuckets</name></name></expr>]</index></name> <operator>=</operator> <name>bucket</name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nSkewBuckets</name></name><operator>++</operator></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>+=</operator> <name>SKEW_BUCKET_OVERHEAD</name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsedSkew</name></name> <operator>+=</operator> <name>SKEW_BUCKET_OVERHEAD</name></expr>;</expr_stmt>
			<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>&gt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name></expr>)</condition><block type="pseudo"><block_content>
				<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name></expr>;</expr_stmt></block_content></block></if></if_stmt>
		</block_content>}</block></for>

		<expr_stmt><expr><call><name>free_attstatsslot</name><argument_list>(<argument><expr><operator>&amp;</operator><name>sslot</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></if></if_stmt>

	<expr_stmt><expr><call><name>ReleaseSysCache</name><argument_list>(<argument><expr><name>statsTuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * ExecHashGetSkewBucket
 *
 *		Returns the index of the skew bucket for this hashvalue,
 *		or INVALID_SKEW_BUCKET_NO if the hashvalue is not
 *		associated with any active skew bucket.
 */</comment>
<function><type><name>int</name></type>
<name>ExecHashGetSkewBucket</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>uint32</name></type> <name>hashvalue</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>int</name></type>			<name>bucket</name></decl>;</decl_stmt>

	<comment type="block">/*
	 * Always return INVALID_SKEW_BUCKET_NO if not doing skew optimization (in
	 * particular, this happens after the initial batch is done).
	 */</comment>
	<if_stmt><if>if <condition>(<expr><operator>!</operator><name><name>hashtable</name><operator>-&gt;</operator><name>skewEnabled</name></name></expr>)</condition><block type="pseudo"><block_content>
		<return>return <expr><name>INVALID_SKEW_BUCKET_NO</name></expr>;</return></block_content></block></if></if_stmt>

	<comment type="block">/*
	 * Since skewBucketLen is a power of 2, we can do a modulo by ANDing.
	 */</comment>
	<expr_stmt><expr><name>bucket</name> <operator>=</operator> <name>hashvalue</name> <operator>&amp;</operator> <operator>(</operator><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketLen</name></name> <operator>-</operator> <literal type="number">1</literal><operator>)</operator></expr>;</expr_stmt>

	<comment type="block">/*
	 * While we have not hit a hole in the hashtable and have not hit the
	 * desired bucket, we have collided with some other hash value, so try the
	 * next bucket location.
	 */</comment>
	<while>while <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucket</name></expr>]</index></name> <operator>!=</operator> <name>NULL</name> <operator>&amp;&amp;</operator>
		   <name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucket</name></expr>]</index></name><operator>-&gt;</operator><name>hashvalue</name> <operator>!=</operator> <name>hashvalue</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><name>bucket</name> <operator>=</operator> <operator>(</operator><name>bucket</name> <operator>+</operator> <literal type="number">1</literal><operator>)</operator> <operator>&amp;</operator> <operator>(</operator><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketLen</name></name> <operator>-</operator> <literal type="number">1</literal><operator>)</operator></expr>;</expr_stmt></block_content></block></while>

	<comment type="block">/*
	 * Found the desired bucket?
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucket</name></expr>]</index></name> <operator>!=</operator> <name>NULL</name></expr>)</condition><block type="pseudo"><block_content>
		<return>return <expr><name>bucket</name></expr>;</return></block_content></block></if></if_stmt>

	<comment type="block">/*
	 * There must not be any hashtable entry for this hash value.
	 */</comment>
	<return>return <expr><name>INVALID_SKEW_BUCKET_NO</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * ExecHashSkewTableInsert
 *
 *		Insert a tuple into the skew hashtable.
 *
 * This should generally match up with the current-batch case in
 * ExecHashTableInsert.
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecHashSkewTableInsert</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>,
						<parameter><decl><type><name>TupleTableSlot</name> <modifier>*</modifier></type><name>slot</name></decl></parameter>,
						<parameter><decl><type><name>uint32</name></type> <name>hashvalue</name></decl></parameter>,
						<parameter><decl><type><name>int</name></type> <name>bucketNumber</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>bool</name></type>		<name>shouldFree</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>MinimalTuple</name></type> <name>tuple</name> <init>= <expr><call><name>ExecFetchSlotMinimalTuple</name><argument_list>(<argument><expr><name>slot</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>shouldFree</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>hashTupleSize</name></decl>;</decl_stmt>

	<comment type="block">/* Create the HashJoinTuple */</comment>
	<expr_stmt><expr><name>hashTupleSize</name> <operator>=</operator> <name>HJTUPLE_OVERHEAD</name> <operator>+</operator> <name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <call><name>MemoryContextAlloc</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batchCxt</name></name></expr></argument>,
												   <argument><expr><name>hashTupleSize</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>hashvalue</name></name> <operator>=</operator> <name>hashvalue</name></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>memcpy</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>, <argument><expr><name>tuple</name></expr></argument>, <argument><expr><name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>HeapTupleHeaderClearMatch</name><argument_list>(<argument><expr><call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Push it onto the front of the skew bucket's list */</comment>
	<expr_stmt><expr><name><name>hashTuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucketNumber</name></expr>]</index></name><operator>-&gt;</operator><name>tuples</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucketNumber</name></expr>]</index></name><operator>-&gt;</operator><name>tuples</name> <operator>=</operator> <name>hashTuple</name></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>hashTuple</name> <operator>!=</operator> <name><name>hashTuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Account for space used, and back off if we've used too much */</comment>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>+=</operator> <name>hashTupleSize</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsedSkew</name></name> <operator>+=</operator> <name>hashTupleSize</name></expr>;</expr_stmt>
	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>&gt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name></expr>;</expr_stmt></block_content></block></if></if_stmt>
	<while>while <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsedSkew</name></name> <operator>&gt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spaceAllowedSkew</name></name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>ExecHashRemoveNextSkewBucket</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></while>

	<comment type="block">/* Check we are not over the total spaceAllowed, either */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>&gt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spaceAllowed</name></name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>ExecHashIncreaseNumBatches</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>

	<if_stmt><if>if <condition>(<expr><name>shouldFree</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>heap_free_minimal_tuple</name><argument_list>(<argument><expr><name>tuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
</block_content>}</block></function>

<comment type="block">/*
 *		ExecHashRemoveNextSkewBucket
 *
 *		Remove the least valuable skew bucket by pushing its tuples into
 *		the main hash table.
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecHashRemoveNextSkewBucket</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>int</name></type>			<name>bucketToRemove</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashSkewBucket</name> <modifier>*</modifier></type><name>bucket</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>uint32</name></type>		<name>hashvalue</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>bucketno</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>batchno</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>hashTuple</name></decl>;</decl_stmt>

	<comment type="block">/* Locate the bucket to remove */</comment>
	<expr_stmt><expr><name>bucketToRemove</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketNums</name><index>[<expr><name><name>hashtable</name><operator>-&gt;</operator><name>nSkewBuckets</name></name> <operator>-</operator> <literal type="number">1</literal></expr>]</index></name></expr>;</expr_stmt>
	<expr_stmt><expr><name>bucket</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucketToRemove</name></expr>]</index></name></expr>;</expr_stmt>

	<comment type="block">/*
	 * Calculate which bucket and batch the tuples belong to in the main
	 * hashtable.  They all have the same hash value, so it's the same for all
	 * of them.  Also note that it's not possible for nbatch to increase while
	 * we are processing the tuples.
	 */</comment>
	<expr_stmt><expr><name>hashvalue</name> <operator>=</operator> <name><name>bucket</name><operator>-&gt;</operator><name>hashvalue</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>ExecHashGetBucketAndBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>hashvalue</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>bucketno</name></expr></argument>, <argument><expr><operator>&amp;</operator><name>batchno</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Process all tuples in the bucket */</comment>
	<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <name><name>bucket</name><operator>-&gt;</operator><name>tuples</name></name></expr>;</expr_stmt>
	<while>while <condition>(<expr><name>hashTuple</name> <operator>!=</operator> <name>NULL</name></expr>)</condition>
	<block>{<block_content>
		<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>nextHashTuple</name> <init>= <expr><name><name>hashTuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name></expr></init></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>MinimalTuple</name></type> <name>tuple</name></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>Size</name></type>		<name>tupleSize</name></decl>;</decl_stmt>

		<comment type="block">/*
		 * This code must agree with ExecHashTableInsert.  We do not use
		 * ExecHashTableInsert directly as ExecHashTableInsert expects a
		 * TupleTableSlot while we already have HashJoinTuples.
		 */</comment>
		<expr_stmt><expr><name>tuple</name> <operator>=</operator> <call><name>HJTUPLE_MINTUPLE</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name>tupleSize</name> <operator>=</operator> <name>HJTUPLE_OVERHEAD</name> <operator>+</operator> <name><name>tuple</name><operator>-&gt;</operator><name>t_len</name></name></expr>;</expr_stmt>

		<comment type="block">/* Decide whether to put the tuple in the hash table or a temp file */</comment>
		<if_stmt><if>if <condition>(<expr><name>batchno</name> <operator>==</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name></expr>)</condition>
		<block>{<block_content>
			<comment type="block">/* Move the tuple to the main hash table */</comment>
			<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>copyTuple</name></decl>;</decl_stmt>

			<comment type="block">/*
			 * We must copy the tuple into the dense storage, else it will not
			 * be found by, eg, ExecHashIncreaseNumBatches.
			 */</comment>
			<expr_stmt><expr><name>copyTuple</name> <operator>=</operator> <operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <call><name>dense_alloc</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>, <argument><expr><name>tupleSize</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>memcpy</name><argument_list>(<argument><expr><name>copyTuple</name></expr></argument>, <argument><expr><name>hashTuple</name></expr></argument>, <argument><expr><name>tupleSize</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>pfree</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<expr_stmt><expr><name><name>copyTuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name><index>[<expr><name>bucketno</name></expr>]</index></name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>unshared</name><index>[<expr><name>bucketno</name></expr>]</index></name> <operator>=</operator> <name>copyTuple</name></expr>;</expr_stmt>

			<comment type="block">/* We have reduced skew space, but overall space doesn't change */</comment>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsedSkew</name></name> <operator>-=</operator> <name>tupleSize</name></expr>;</expr_stmt>
		</block_content>}</block></if>
		<else>else
		<block>{<block_content>
			<comment type="block">/* Put the tuple into a temp file for later batches */</comment>
			<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>batchno</name> <operator>&gt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>ExecHashJoinSaveTuple</name><argument_list>(<argument><expr><name>tuple</name></expr></argument>, <argument><expr><name>hashvalue</name></expr></argument>,
								  <argument><expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>innerBatchFile</name><index>[<expr><name>batchno</name></expr>]</index></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>pfree</name><argument_list>(<argument><expr><name>hashTuple</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>-=</operator> <name>tupleSize</name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsedSkew</name></name> <operator>-=</operator> <name>tupleSize</name></expr>;</expr_stmt>
		</block_content>}</block></else></if_stmt>

		<expr_stmt><expr><name>hashTuple</name> <operator>=</operator> <name>nextHashTuple</name></expr>;</expr_stmt>

		<comment type="block">/* allow this loop to be cancellable */</comment>
		<expr_stmt><expr><call><name>CHECK_FOR_INTERRUPTS</name><argument_list>()</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></while>

	<comment type="block">/*
	 * Free the bucket struct itself and reset the hashtable entry to NULL.
	 *
	 * NOTE: this is not nearly as simple as it looks on the surface, because
	 * of the possibility of collisions in the hashtable.  Suppose that hash
	 * values A and B collide at a particular hashtable entry, and that A was
	 * entered first so B gets shifted to a different table entry.  If we were
	 * to remove A first then ExecHashGetSkewBucket would mistakenly start
	 * reporting that B is not in the hashtable, because it would hit the NULL
	 * before finding B.  However, we always remove entries in the reverse
	 * order of creation, so this failure cannot happen.
	 */</comment>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name><index>[<expr><name>bucketToRemove</name></expr>]</index></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nSkewBuckets</name></name><operator>--</operator></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>pfree</name><argument_list>(<argument><expr><name>bucket</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>-=</operator> <name>SKEW_BUCKET_OVERHEAD</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsedSkew</name></name> <operator>-=</operator> <name>SKEW_BUCKET_OVERHEAD</name></expr>;</expr_stmt>

	<comment type="block">/*
	 * If we have removed all skew buckets then give up on skew optimization.
	 * Release the arrays since they aren't useful any more.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>nSkewBuckets</name></name> <operator>==</operator> <literal type="number">0</literal></expr>)</condition>
	<block>{<block_content>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewEnabled</name></name> <operator>=</operator> <name>false</name></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>pfree</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>pfree</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketNums</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucket</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>skewBucketNums</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsed</name></name> <operator>-=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsedSkew</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spaceUsedSkew</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
	</block_content>}</block></if></if_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Reserve space in the DSM segment for instrumentation data.
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashEstimate</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>, <parameter><decl><type><name>ParallelContext</name> <modifier>*</modifier></type><name>pcxt</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>size_t</name></type>		<name>size</name></decl>;</decl_stmt>

	<comment type="block">/* don't need this if not instrumenting or no workers */</comment>
	<if_stmt><if>if <condition>(<expr><operator>!</operator><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>instrument</name></name> <operator>||</operator> <name><name>pcxt</name><operator>-&gt;</operator><name>nworkers</name></name> <operator>==</operator> <literal type="number">0</literal></expr>)</condition><block type="pseudo"><block_content>
		<return>return;</return></block_content></block></if></if_stmt>

	<expr_stmt><expr><name>size</name> <operator>=</operator> <call><name>mul_size</name><argument_list>(<argument><expr><name><name>pcxt</name><operator>-&gt;</operator><name>nworkers</name></name></expr></argument>, <argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>HashInstrumentation</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>size</name> <operator>=</operator> <call><name>add_size</name><argument_list>(<argument><expr><name>size</name></expr></argument>, <argument><expr><call><name>offsetof</name><argument_list>(<argument><expr><name>SharedHashInfo</name></expr></argument>, <argument><expr><name>hinstrument</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>shm_toc_estimate_chunk</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pcxt</name><operator>-&gt;</operator><name>estimator</name></name></expr></argument>, <argument><expr><name>size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>shm_toc_estimate_keys</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pcxt</name><operator>-&gt;</operator><name>estimator</name></name></expr></argument>, <argument><expr><literal type="number">1</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Set up a space in the DSM for all workers to record instrumentation data
 * about their hash table.
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashInitializeDSM</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>, <parameter><decl><type><name>ParallelContext</name> <modifier>*</modifier></type><name>pcxt</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>size_t</name></type>		<name>size</name></decl>;</decl_stmt>

	<comment type="block">/* don't need this if not instrumenting or no workers */</comment>
	<if_stmt><if>if <condition>(<expr><operator>!</operator><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>instrument</name></name> <operator>||</operator> <name><name>pcxt</name><operator>-&gt;</operator><name>nworkers</name></name> <operator>==</operator> <literal type="number">0</literal></expr>)</condition><block type="pseudo"><block_content>
		<return>return;</return></block_content></block></if></if_stmt>

	<expr_stmt><expr><name>size</name> <operator>=</operator> <call><name>offsetof</name><argument_list>(<argument><expr><name>SharedHashInfo</name></expr></argument>, <argument><expr><name>hinstrument</name></expr></argument>)</argument_list></call> <operator>+</operator>
		<name><name>pcxt</name><operator>-&gt;</operator><name>nworkers</name></name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashInstrumentation</name></expr></argument>)</argument_list></sizeof></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>node</name><operator>-&gt;</operator><name>shared_info</name></name> <operator>=</operator> <operator>(</operator><name>SharedHashInfo</name> <operator>*</operator><operator>)</operator> <call><name>shm_toc_allocate</name><argument_list>(<argument><expr><name><name>pcxt</name><operator>-&gt;</operator><name>toc</name></name></expr></argument>, <argument><expr><name>size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Each per-worker area must start out as zeroes. */</comment>
	<expr_stmt><expr><call><name>memset</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>shared_info</name></name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>, <argument><expr><name>size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><name><name>node</name><operator>-&gt;</operator><name>shared_info</name><operator>-&gt;</operator><name>num_workers</name></name> <operator>=</operator> <name><name>pcxt</name><operator>-&gt;</operator><name>nworkers</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>shm_toc_insert</name><argument_list>(<argument><expr><name><name>pcxt</name><operator>-&gt;</operator><name>toc</name></name></expr></argument>, <argument><expr><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>plan</name><operator>-&gt;</operator><name>plan_node_id</name></name></expr></argument>,
				   <argument><expr><name><name>node</name><operator>-&gt;</operator><name>shared_info</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Locate the DSM space for hash table instrumentation data that we'll write
 * to at shutdown time.
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashInitializeWorker</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>, <parameter><decl><type><name>ParallelWorkerContext</name> <modifier>*</modifier></type><name>pwcxt</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>SharedHashInfo</name> <modifier>*</modifier></type><name>shared_info</name></decl>;</decl_stmt>

	<comment type="block">/* don't need this if not instrumenting */</comment>
	<if_stmt><if>if <condition>(<expr><operator>!</operator><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>instrument</name></name></expr>)</condition><block type="pseudo"><block_content>
		<return>return;</return></block_content></block></if></if_stmt>

	<comment type="block">/*
	 * Find our entry in the shared area, and set up a pointer to it so that
	 * we'll accumulate stats there when shutting down or rebuilding the hash
	 * table.
	 */</comment>
	<expr_stmt><expr><name>shared_info</name> <operator>=</operator> <operator>(</operator><name>SharedHashInfo</name> <operator>*</operator><operator>)</operator>
		<call><name>shm_toc_lookup</name><argument_list>(<argument><expr><name><name>pwcxt</name><operator>-&gt;</operator><name>toc</name></name></expr></argument>, <argument><expr><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>plan</name><operator>-&gt;</operator><name>plan_node_id</name></name></expr></argument>, <argument><expr><name>false</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>node</name><operator>-&gt;</operator><name>hinstrument</name></name> <operator>=</operator> <operator>&amp;</operator><name><name>shared_info</name><operator>-&gt;</operator><name>hinstrument</name><index>[<expr><name>ParallelWorkerNumber</name></expr>]</index></name></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Collect EXPLAIN stats if needed, saving them into DSM memory if
 * ExecHashInitializeWorker was called, or local storage if not.  In the
 * parallel case, this must be done in ExecShutdownHash() rather than
 * ExecEndHash() because the latter runs after we've detached from the DSM
 * segment.
 */</comment>
<function><type><name>void</name></type>
<name>ExecShutdownHash</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<comment type="block">/* Allocate save space if EXPLAIN'ing and we didn't do so already */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>node</name><operator>-&gt;</operator><name>ps</name><operator>.</operator><name>instrument</name></name> <operator>&amp;&amp;</operator> <operator>!</operator><name><name>node</name><operator>-&gt;</operator><name>hinstrument</name></name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><name><name>node</name><operator>-&gt;</operator><name>hinstrument</name></name> <operator>=</operator> <operator>(</operator><name>HashInstrumentation</name> <operator>*</operator><operator>)</operator>
			<call><name>palloc0</name><argument_list>(<argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>HashInstrumentation</name></expr></argument>)</argument_list></sizeof></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
	<comment type="block">/* Now accumulate data for the current (final) hash table */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>node</name><operator>-&gt;</operator><name>hinstrument</name></name> <operator>&amp;&amp;</operator> <name><name>node</name><operator>-&gt;</operator><name>hashtable</name></name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>ExecHashAccumInstrumentation</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>hinstrument</name></name></expr></argument>, <argument><expr><name><name>node</name><operator>-&gt;</operator><name>hashtable</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Retrieve instrumentation data from workers before the DSM segment is
 * detached, so that EXPLAIN can access it.
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashRetrieveInstrumentation</name><parameter_list>(<parameter><decl><type><name>HashState</name> <modifier>*</modifier></type><name>node</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>SharedHashInfo</name> <modifier>*</modifier></type><name>shared_info</name> <init>= <expr><name><name>node</name><operator>-&gt;</operator><name>shared_info</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>size_t</name></type>		<name>size</name></decl>;</decl_stmt>

	<if_stmt><if>if <condition>(<expr><name>shared_info</name> <operator>==</operator> <name>NULL</name></expr>)</condition><block type="pseudo"><block_content>
		<return>return;</return></block_content></block></if></if_stmt>

	<comment type="block">/* Replace node-&gt;shared_info with a copy in backend-local memory. */</comment>
	<expr_stmt><expr><name>size</name> <operator>=</operator> <call><name>offsetof</name><argument_list>(<argument><expr><name>SharedHashInfo</name></expr></argument>, <argument><expr><name>hinstrument</name></expr></argument>)</argument_list></call> <operator>+</operator>
		<name><name>shared_info</name><operator>-&gt;</operator><name>num_workers</name></name> <operator>*</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>HashInstrumentation</name></expr></argument>)</argument_list></sizeof></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>node</name><operator>-&gt;</operator><name>shared_info</name></name> <operator>=</operator> <call><name>palloc</name><argument_list>(<argument><expr><name>size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>memcpy</name><argument_list>(<argument><expr><name><name>node</name><operator>-&gt;</operator><name>shared_info</name></name></expr></argument>, <argument><expr><name>shared_info</name></expr></argument>, <argument><expr><name>size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Accumulate instrumentation data from 'hashtable' into an
 * initially-zeroed HashInstrumentation struct.
 *
 * This is used to merge information across successive hash table instances
 * within a single plan node.  We take the maximum values of each interesting
 * number.  The largest nbuckets and largest nbatch values might have occurred
 * in different instances, so there's some risk of confusion from reporting
 * unrelated numbers; but there's a bigger risk of misdiagnosing a performance
 * issue if we don't report the largest values.  Similarly, we want to report
 * the largest spacePeak regardless of whether it happened in the same
 * instance as the largest nbuckets or nbatch.  All the instances should have
 * the same nbuckets_original and nbatch_original; but there's little value
 * in depending on that here, so handle them the same way.
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashAccumInstrumentation</name><parameter_list>(<parameter><decl><type><name>HashInstrumentation</name> <modifier>*</modifier></type><name>instrument</name></decl></parameter>,
							 <parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<expr_stmt><expr><name><name>instrument</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>=</operator> <call><name>Max</name><argument_list>(<argument><expr><name><name>instrument</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></argument>,
							   <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>instrument</name><operator>-&gt;</operator><name>nbuckets_original</name></name> <operator>=</operator> <call><name>Max</name><argument_list>(<argument><expr><name><name>instrument</name><operator>-&gt;</operator><name>nbuckets_original</name></name></expr></argument>,
										<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets_original</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>instrument</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>=</operator> <call><name>Max</name><argument_list>(<argument><expr><name><name>instrument</name><operator>-&gt;</operator><name>nbatch</name></name></expr></argument>,
							 <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>instrument</name><operator>-&gt;</operator><name>nbatch_original</name></name> <operator>=</operator> <call><name>Max</name><argument_list>(<argument><expr><name><name>instrument</name><operator>-&gt;</operator><name>nbatch_original</name></name></expr></argument>,
									  <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch_original</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>instrument</name><operator>-&gt;</operator><name>space_peak</name></name> <operator>=</operator> <call><name>Max</name><argument_list>(<argument><expr><name><name>instrument</name><operator>-&gt;</operator><name>space_peak</name></name></expr></argument>,
								 <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Allocate 'size' bytes from the currently active HashMemoryChunk
 */</comment>
<function><type><specifier>static</specifier> <name>void</name> <modifier>*</modifier></type>
<name>dense_alloc</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>Size</name></type> <name>size</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>HashMemoryChunk</name></type> <name>newChunk</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>char</name>	   <modifier>*</modifier></type><name>ptr</name></decl>;</decl_stmt>

	<comment type="block">/* just in case the size is not already aligned properly */</comment>
	<expr_stmt><expr><name>size</name> <operator>=</operator> <call><name>MAXALIGN</name><argument_list>(<argument><expr><name>size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * If tuple size is larger than threshold, allocate a separate chunk.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name>size</name> <operator>&gt;</operator> <name>HASH_CHUNK_THRESHOLD</name></expr>)</condition>
	<block>{<block_content>
		<comment type="block">/* allocate new chunk and put it at the beginning of the list */</comment>
		<expr_stmt><expr><name>newChunk</name> <operator>=</operator> <operator>(</operator><name>HashMemoryChunk</name><operator>)</operator> <call><name>MemoryContextAlloc</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batchCxt</name></name></expr></argument>,
														<argument><expr><name>HASH_CHUNK_HEADER_SIZE</name> <operator>+</operator> <name>size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>newChunk</name><operator>-&gt;</operator><name>maxlen</name></name> <operator>=</operator> <name>size</name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>newChunk</name><operator>-&gt;</operator><name>used</name></name> <operator>=</operator> <name>size</name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>newChunk</name><operator>-&gt;</operator><name>ntuples</name></name> <operator>=</operator> <literal type="number">1</literal></expr>;</expr_stmt>

		<comment type="block">/*
		 * Add this chunk to the list after the first existing chunk, so that
		 * we don't lose the remaining space in the "current" chunk.
		 */</comment>
		<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name> <operator>!=</operator> <name>NULL</name></expr>)</condition>
		<block>{<block_content>
			<expr_stmt><expr><name><name>newChunk</name><operator>-&gt;</operator><name>next</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name><operator>-&gt;</operator><name>next</name></name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name> <operator>=</operator> <name>newChunk</name></expr>;</expr_stmt>
		</block_content>}</block></if>
		<else>else
		<block>{<block_content>
			<expr_stmt><expr><name><name>newChunk</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name> <operator>=</operator> <name>newChunk</name></expr>;</expr_stmt>
		</block_content>}</block></else></if_stmt>

		<return>return <expr><call><name>HASH_CHUNK_DATA</name><argument_list>(<argument><expr><name>newChunk</name></expr></argument>)</argument_list></call></expr>;</return>
	</block_content>}</block></if></if_stmt>

	<comment type="block">/*
	 * See if we have enough space for it in the current chunk (if any). If
	 * not, allocate a fresh chunk.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><operator>(</operator><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name> <operator>==</operator> <name>NULL</name><operator>)</operator> <operator>||</operator>
		<operator>(</operator><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name><operator>-&gt;</operator><name>maxlen</name></name> <operator>-</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name><operator>-&gt;</operator><name>used</name></name><operator>)</operator> <operator>&lt;</operator> <name>size</name></expr>)</condition>
	<block>{<block_content>
		<comment type="block">/* allocate new chunk and put it at the beginning of the list */</comment>
		<expr_stmt><expr><name>newChunk</name> <operator>=</operator> <operator>(</operator><name>HashMemoryChunk</name><operator>)</operator> <call><name>MemoryContextAlloc</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batchCxt</name></name></expr></argument>,
														<argument><expr><name>HASH_CHUNK_HEADER_SIZE</name> <operator>+</operator> <name>HASH_CHUNK_SIZE</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<expr_stmt><expr><name><name>newChunk</name><operator>-&gt;</operator><name>maxlen</name></name> <operator>=</operator> <name>HASH_CHUNK_SIZE</name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>newChunk</name><operator>-&gt;</operator><name>used</name></name> <operator>=</operator> <name>size</name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>newChunk</name><operator>-&gt;</operator><name>ntuples</name></name> <operator>=</operator> <literal type="number">1</literal></expr>;</expr_stmt>

		<expr_stmt><expr><name><name>newChunk</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>unshared</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name> <operator>=</operator> <name>newChunk</name></expr>;</expr_stmt>

		<return>return <expr><call><name>HASH_CHUNK_DATA</name><argument_list>(<argument><expr><name>newChunk</name></expr></argument>)</argument_list></call></expr>;</return>
	</block_content>}</block></if></if_stmt>

	<comment type="block">/* There is enough space in the current chunk, let's add the tuple */</comment>
	<expr_stmt><expr><name>ptr</name> <operator>=</operator> <call><name>HASH_CHUNK_DATA</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name></name></expr></argument>)</argument_list></call> <operator>+</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name><operator>-&gt;</operator><name>used</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name><operator>-&gt;</operator><name>used</name></name> <operator>+=</operator> <name>size</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>chunks</name><operator>-&gt;</operator><name>ntuples</name></name> <operator>+=</operator> <literal type="number">1</literal></expr>;</expr_stmt>

	<comment type="block">/* return pointer to the start of the tuple memory */</comment>
	<return>return <expr><name>ptr</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * Allocate space for a tuple in shared dense storage.  This is equivalent to
 * dense_alloc but for Parallel Hash using shared memory.
 *
 * While loading a tuple into shared memory, we might run out of memory and
 * decide to repartition, or determine that the load factor is too high and
 * decide to expand the bucket array, or discover that another participant has
 * commanded us to help do that.  Return NULL if number of buckets or batches
 * has changed, indicating that the caller must retry (considering the
 * possibility that the tuple no longer belongs in the same batch).
 */</comment>
<function><type><specifier>static</specifier> <name>HashJoinTuple</name></type>
<name>ExecParallelHashTupleAlloc</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>size_t</name></type> <name>size</name></decl></parameter>,
						   <parameter><decl><type><name>dsa_pointer</name> <modifier>*</modifier></type><name>shared</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>dsa_pointer</name></type> <name>chunk_shared</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashMemoryChunk</name></type> <name>chunk</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>Size</name></type>		<name>chunk_size</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>result</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>curbatch</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name></expr></init></decl>;</decl_stmt>

	<expr_stmt><expr><name>size</name> <operator>=</operator> <call><name>MAXALIGN</name><argument_list>(<argument><expr><name>size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * Fast path: if there is enough space in this backend's current chunk,
	 * then we can allocate without any locking.
	 */</comment>
	<expr_stmt><expr><name>chunk</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>current_chunk</name></name></expr>;</expr_stmt>
	<if_stmt><if>if <condition>(<expr><name>chunk</name> <operator>!=</operator> <name>NULL</name> <operator>&amp;&amp;</operator>
		<name>size</name> <operator>&lt;=</operator> <name>HASH_CHUNK_THRESHOLD</name> <operator>&amp;&amp;</operator>
		<name><name>chunk</name><operator>-&gt;</operator><name>maxlen</name></name> <operator>-</operator> <name><name>chunk</name><operator>-&gt;</operator><name>used</name></name> <operator>&gt;=</operator> <name>size</name></expr>)</condition>
	<block>{<block_content>

		<expr_stmt><expr><name>chunk_shared</name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>current_chunk_shared</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>chunk</name> <operator>==</operator> <call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name>chunk_shared</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><operator>*</operator><name>shared</name> <operator>=</operator> <name>chunk_shared</name> <operator>+</operator> <name>HASH_CHUNK_HEADER_SIZE</name> <operator>+</operator> <name><name>chunk</name><operator>-&gt;</operator><name>used</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><name>result</name> <operator>=</operator> <operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <operator>(</operator><call><name>HASH_CHUNK_DATA</name><argument_list>(<argument><expr><name>chunk</name></expr></argument>)</argument_list></call> <operator>+</operator> <name><name>chunk</name><operator>-&gt;</operator><name>used</name></name><operator>)</operator></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>chunk</name><operator>-&gt;</operator><name>used</name></name> <operator>+=</operator> <name>size</name></expr>;</expr_stmt>

		<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>chunk</name><operator>-&gt;</operator><name>used</name></name> <operator>&lt;=</operator> <name><name>chunk</name><operator>-&gt;</operator><name>maxlen</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>result</name> <operator>==</operator> <call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><operator>*</operator><name>shared</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<return>return <expr><name>result</name></expr>;</return>
	</block_content>}</block></if></if_stmt>

	<comment type="block">/* Slow path: try to allocate a new chunk. */</comment>
	<expr_stmt><expr><call><name>LWLockAcquire</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>, <argument><expr><name>LW_EXCLUSIVE</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/*
	 * Check if we need to help increase the number of buckets or batches.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>==</operator> <name>PHJ_GROWTH_NEED_MORE_BATCHES</name> <operator>||</operator>
		<name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>==</operator> <name>PHJ_GROWTH_NEED_MORE_BUCKETS</name></expr>)</condition>
	<block>{<block_content>
		<decl_stmt><decl><type><name>ParallelHashGrowth</name></type> <name>growth</name> <init>= <expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name></expr></init></decl>;</decl_stmt>

		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>current_chunk</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>LWLockRelease</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/* Another participant has commanded us to help grow. */</comment>
		<if_stmt><if>if <condition>(<expr><name>growth</name> <operator>==</operator> <name>PHJ_GROWTH_NEED_MORE_BATCHES</name></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><call><name>ExecParallelHashIncreaseNumBatches</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if>
		<if type="elseif">else if <condition>(<expr><name>growth</name> <operator>==</operator> <name>PHJ_GROWTH_NEED_MORE_BUCKETS</name></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><call><name>ExecParallelHashIncreaseNumBuckets</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>

		<comment type="block">/* The caller must retry. */</comment>
		<return>return <expr><name>NULL</name></expr>;</return>
	</block_content>}</block></if></if_stmt>

	<comment type="block">/* Oversized tuples get their own chunk. */</comment>
	<if_stmt><if>if <condition>(<expr><name>size</name> <operator>&gt;</operator> <name>HASH_CHUNK_THRESHOLD</name></expr>)</condition><block type="pseudo"><block_content>
		<expr_stmt><expr><name>chunk_size</name> <operator>=</operator> <name>size</name> <operator>+</operator> <name>HASH_CHUNK_HEADER_SIZE</name></expr>;</expr_stmt></block_content></block></if>
	<else>else<block type="pseudo"><block_content>
		<expr_stmt><expr><name>chunk_size</name> <operator>=</operator> <name>HASH_CHUNK_SIZE</name></expr>;</expr_stmt></block_content></block></else></if_stmt>

	<comment type="block">/* Check if it's time to grow batches or buckets. */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>!=</operator> <name>PHJ_GROWTH_DISABLED</name></expr>)</condition>
	<block>{<block_content>
		<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>curbatch</name> <operator>==</operator> <literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>build_barrier</name></name></expr></argument>)</argument_list></call> <operator>==</operator> <name>PHJ_BUILD_HASHING_INNER</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/*
		 * Check if our space limit would be exceeded.  To avoid choking on
		 * very large tuples or very low hash_mem setting, we'll always allow
		 * each backend to allocate at least one chunk.
		 */</comment>
		<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name>at_least_one_chunk</name> <operator>&amp;&amp;</operator>
			<name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>size</name></name> <operator>+</operator>
			<name>chunk_size</name> <operator>&gt;</operator> <name><name>pstate</name><operator>-&gt;</operator><name>space_allowed</name></name></expr>)</condition>
		<block>{<block_content>
			<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>=</operator> <name>PHJ_GROWTH_NEED_MORE_BATCHES</name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>space_exhausted</name></name> <operator>=</operator> <name>true</name></expr>;</expr_stmt>
			<expr_stmt><expr><call><name>LWLockRelease</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<return>return <expr><name>NULL</name></expr>;</return>
		</block_content>}</block></if></if_stmt>

		<comment type="block">/* Check if our load factor limit would be exceeded. */</comment>
		<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>==</operator> <literal type="number">1</literal></expr>)</condition>
		<block>{<block_content>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>ntuples</name></name> <operator>+=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name>ntuples</name></expr>;</expr_stmt>
			<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name>ntuples</name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
			<comment type="block">/* Guard against integer overflow and alloc size overflow */</comment>
			<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><literal type="number">0</literal></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>ntuples</name></name> <operator>+</operator> <literal type="number">1</literal> <operator>&gt;</operator>
				<name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>*</operator> <name>NTUP_PER_BUCKET</name> <operator>&amp;&amp;</operator>
				<name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>&lt;</operator> <operator>(</operator><name>INT_MAX</name> <operator>/</operator> <literal type="number">2</literal><operator>)</operator> <operator>&amp;&amp;</operator>
				<name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>*</operator> <literal type="number">2</literal> <operator>&lt;=</operator>
				<name>MaxAllocSize</name> <operator>/</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>dsa_pointer_atomic</name></expr></argument>)</argument_list></sizeof></expr>)</condition>
			<block>{<block_content>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>=</operator> <name>PHJ_GROWTH_NEED_MORE_BUCKETS</name></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>LWLockRelease</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

				<return>return <expr><name>NULL</name></expr>;</return>
			</block_content>}</block></if></if_stmt>
		</block_content>}</block></if></if_stmt>
	</block_content>}</block></if></if_stmt>

	<comment type="block">/* We are cleared to allocate a new chunk. */</comment>
	<expr_stmt><expr><name>chunk_shared</name> <operator>=</operator> <call><name>dsa_allocate</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name>chunk_size</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>curbatch</name></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>size</name></name> <operator>+=</operator> <name>chunk_size</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>curbatch</name></expr>]</index></name><operator>.</operator><name>at_least_one_chunk</name> <operator>=</operator> <name>true</name></expr>;</expr_stmt>

	<comment type="block">/* Set up the chunk. */</comment>
	<expr_stmt><expr><name>chunk</name> <operator>=</operator> <operator>(</operator><name>HashMemoryChunk</name><operator>)</operator> <call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name>chunk_shared</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><operator>*</operator><name>shared</name> <operator>=</operator> <name>chunk_shared</name> <operator>+</operator> <name>HASH_CHUNK_HEADER_SIZE</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>chunk</name><operator>-&gt;</operator><name>maxlen</name></name> <operator>=</operator> <name>chunk_size</name> <operator>-</operator> <name>HASH_CHUNK_HEADER_SIZE</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>chunk</name><operator>-&gt;</operator><name>used</name></name> <operator>=</operator> <name>size</name></expr>;</expr_stmt>

	<comment type="block">/*
	 * Push it onto the list of chunks, so that it can be found if we need to
	 * increase the number of buckets or batches (batch 0 only) and later for
	 * freeing the memory (all batches).
	 */</comment>
	<expr_stmt><expr><name><name>chunk</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>shared</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>curbatch</name></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>chunks</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>curbatch</name></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>chunks</name></name> <operator>=</operator> <name>chunk_shared</name></expr>;</expr_stmt>

	<if_stmt><if>if <condition>(<expr><name>size</name> <operator>&lt;=</operator> <name>HASH_CHUNK_THRESHOLD</name></expr>)</condition>
	<block>{<block_content>
		<comment type="block">/*
		 * Make this the current chunk so that we can use the fast path to
		 * fill the rest of it up in future calls.
		 */</comment>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>current_chunk</name></name> <operator>=</operator> <name>chunk</name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>current_chunk_shared</name></name> <operator>=</operator> <name>chunk_shared</name></expr>;</expr_stmt>
	</block_content>}</block></if></if_stmt>
	<expr_stmt><expr><call><name>LWLockRelease</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><call><name>HASH_CHUNK_DATA</name><argument_list>(<argument><expr><name>chunk</name></expr></argument>)</argument_list></call> <operator>==</operator> <call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><operator>*</operator><name>shared</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>result</name> <operator>=</operator> <operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <call><name>HASH_CHUNK_DATA</name><argument_list>(<argument><expr><name>chunk</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<return>return <expr><name>result</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * One backend needs to set up the shared batch state including tuplestores.
 * Other backends will ensure they have correctly configured accessors by
 * called ExecParallelHashEnsureBatchAccessors().
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecParallelHashJoinSetUpBatches</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>int</name></type> <name>nbatch</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>ParallelHashJoinBatch</name> <modifier>*</modifier></type><name>batches</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>MemoryContext</name></type> <name>oldcxt</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name></name> <operator>==</operator> <name>NULL</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Allocate space. */</comment>
	<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>batches</name></name> <operator>=</operator>
		<call><name>dsa_allocate0</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>,
					  <argument><expr><call><name>EstimateParallelHashJoinBatch</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call> <operator>*</operator> <name>nbatch</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>=</operator> <name>nbatch</name></expr>;</expr_stmt>
	<expr_stmt><expr><name>batches</name> <operator>=</operator> <call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>batches</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Use hash join memory context. */</comment>
	<expr_stmt><expr><name>oldcxt</name> <operator>=</operator> <call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>hashCxt</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Allocate this backend's accessor array. */</comment>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>=</operator> <name>nbatch</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name></name> <operator>=</operator> <operator>(</operator><name>ParallelHashJoinBatchAccessor</name> <operator>*</operator><operator>)</operator>
		<call><name>palloc0</name><argument_list>(<argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>ParallelHashJoinBatchAccessor</name></expr></argument>)</argument_list></sizeof> <operator>*</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Set up the shared state, tuplestores and backend-local accessors. */</comment>
	<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control>
	<block>{<block_content>
		<decl_stmt><decl><type><name>ParallelHashJoinBatchAccessor</name> <modifier>*</modifier></type><name>accessor</name> <init>= <expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name></expr></init></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>ParallelHashJoinBatch</name> <modifier>*</modifier></type><name>shared</name> <init>= <expr><call><name>NthParallelHashJoinBatch</name><argument_list>(<argument><expr><name>batches</name></expr></argument>, <argument><expr><name>i</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>char</name></type>		<name><name>name</name><index>[<expr><name>MAXPGPATH</name></expr>]</index></name></decl>;</decl_stmt>

		<comment type="block">/*
		 * All members of shared were zero-initialized.  We just need to set
		 * up the Barrier.
		 */</comment>
		<expr_stmt><expr><call><name>BarrierInit</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>shared</name><operator>-&gt;</operator><name>batch_barrier</name></name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<if_stmt><if>if <condition>(<expr><name>i</name> <operator>==</operator> <literal type="number">0</literal></expr>)</condition>
		<block>{<block_content>
			<comment type="block">/* Batch 0 doesn't need to be loaded. */</comment>
			<expr_stmt><expr><call><name>BarrierAttach</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>shared</name><operator>-&gt;</operator><name>batch_barrier</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			<while>while <condition>(<expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>shared</name><operator>-&gt;</operator><name>batch_barrier</name></name></expr></argument>)</argument_list></call> <operator>&lt;</operator> <name>PHJ_BATCH_PROBING</name></expr>)</condition><block type="pseudo"><block_content>
				<expr_stmt><expr><call><name>BarrierArriveAndWait</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>shared</name><operator>-&gt;</operator><name>batch_barrier</name></name></expr></argument>, <argument><expr><literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></while>
			<expr_stmt><expr><call><name>BarrierDetach</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>shared</name><operator>-&gt;</operator><name>batch_barrier</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		</block_content>}</block></if></if_stmt>

		<comment type="block">/* Initialize accessor state.  All members were zero-initialized. */</comment>
		<expr_stmt><expr><name><name>accessor</name><operator>-&gt;</operator><name>shared</name></name> <operator>=</operator> <name>shared</name></expr>;</expr_stmt>

		<comment type="block">/* Initialize the shared tuplestores. */</comment>
		<expr_stmt><expr><call><name>snprintf</name><argument_list>(<argument><expr><name>name</name></expr></argument>, <argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>name</name></expr></argument>)</argument_list></sizeof></expr></argument>, <argument><expr><literal type="string">"i%dof%d"</literal></expr></argument>, <argument><expr><name>i</name></expr></argument>, <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>accessor</name><operator>-&gt;</operator><name>inner_tuples</name></name> <operator>=</operator>
			<call><name>sts_initialize</name><argument_list>(<argument><expr><call><name>ParallelHashJoinBatchInner</name><argument_list>(<argument><expr><name>shared</name></expr></argument>)</argument_list></call></expr></argument>,
						   <argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>nparticipants</name></name></expr></argument>,
						   <argument><expr><name>ParallelWorkerNumber</name> <operator>+</operator> <literal type="number">1</literal></expr></argument>,
						   <argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>uint32</name></expr></argument>)</argument_list></sizeof></expr></argument>,
						   <argument><expr><name>SHARED_TUPLESTORE_SINGLE_PASS</name></expr></argument>,
						   <argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>fileset</name></name></expr></argument>,
						   <argument><expr><name>name</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>snprintf</name><argument_list>(<argument><expr><name>name</name></expr></argument>, <argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>name</name></expr></argument>)</argument_list></sizeof></expr></argument>, <argument><expr><literal type="string">"o%dof%d"</literal></expr></argument>, <argument><expr><name>i</name></expr></argument>, <argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>accessor</name><operator>-&gt;</operator><name>outer_tuples</name></name> <operator>=</operator>
			<call><name>sts_initialize</name><argument_list>(<argument><expr><call><name>ParallelHashJoinBatchOuter</name><argument_list>(<argument><expr><name>shared</name></expr></argument>,
													  <argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>nparticipants</name></name></expr></argument>)</argument_list></call></expr></argument>,
						   <argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>nparticipants</name></name></expr></argument>,
						   <argument><expr><name>ParallelWorkerNumber</name> <operator>+</operator> <literal type="number">1</literal></expr></argument>,
						   <argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>uint32</name></expr></argument>)</argument_list></sizeof></expr></argument>,
						   <argument><expr><name>SHARED_TUPLESTORE_SINGLE_PASS</name></expr></argument>,
						   <argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>fileset</name></name></expr></argument>,
						   <argument><expr><name>name</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></for>

	<expr_stmt><expr><call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name>oldcxt</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Free the current set of ParallelHashJoinBatchAccessor objects.
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecParallelHashCloseBatchAccessors</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

	<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control>
	<block>{<block_content>
		<comment type="block">/* Make sure no files are left open. */</comment>
		<expr_stmt><expr><call><name>sts_end_write</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name><operator>.</operator><name>inner_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>sts_end_write</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name><operator>.</operator><name>outer_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>sts_end_parallel_scan</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name><operator>.</operator><name>inner_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>sts_end_parallel_scan</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name><operator>.</operator><name>outer_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></for>
	<expr_stmt><expr><call><name>pfree</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Make sure this backend has up-to-date accessors for the current set of
 * batches.
 */</comment>
<function><type><specifier>static</specifier> <name>void</name></type>
<name>ExecParallelHashEnsureBatchAccessors</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>ParallelHashJoinBatch</name> <modifier>*</modifier></type><name>batches</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>MemoryContext</name></type> <name>oldcxt</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name></name> <operator>!=</operator> <name>NULL</name></expr>)</condition>
	<block>{<block_content>
		<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>==</operator> <name><name>pstate</name><operator>-&gt;</operator><name>nbatch</name></name></expr>)</condition><block type="pseudo"><block_content>
			<return>return;</return></block_content></block></if></if_stmt>
		<expr_stmt><expr><call><name>ExecParallelHashCloseBatchAccessors</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></if></if_stmt>

	<comment type="block">/*
	 * It's possible for a backend to start up very late so that the whole
	 * join is finished and the shm state for tracking batches has already
	 * been freed by ExecHashTableDetach().  In that case we'll just leave
	 * hashtable-&gt;batches as NULL so that ExecParallelHashJoinNewBatch() gives
	 * up early.
	 */</comment>
	<if_stmt><if>if <condition>(<expr><operator>!</operator><call><name>DsaPointerIsValid</name><argument_list>(<argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>batches</name></name></expr></argument>)</argument_list></call></expr>)</condition><block type="pseudo"><block_content>
		<return>return;</return></block_content></block></if></if_stmt>

	<comment type="block">/* Use hash join memory context. */</comment>
	<expr_stmt><expr><name>oldcxt</name> <operator>=</operator> <call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>hashCxt</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Allocate this backend's accessor array. */</comment>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name> <operator>=</operator> <name><name>pstate</name><operator>-&gt;</operator><name>nbatch</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name></name> <operator>=</operator> <operator>(</operator><name>ParallelHashJoinBatchAccessor</name> <operator>*</operator><operator>)</operator>
		<call><name>palloc0</name><argument_list>(<argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>ParallelHashJoinBatchAccessor</name></expr></argument>)</argument_list></sizeof> <operator>*</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Find the base of the pseudo-array of ParallelHashJoinBatch objects. */</comment>
	<expr_stmt><expr><name>batches</name> <operator>=</operator> <operator>(</operator><name>ParallelHashJoinBatch</name> <operator>*</operator><operator>)</operator>
		<call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>batches</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Set up the accessor array and attach to the tuplestores. */</comment>
	<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control>
	<block>{<block_content>
		<decl_stmt><decl><type><name>ParallelHashJoinBatchAccessor</name> <modifier>*</modifier></type><name>accessor</name> <init>= <expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name></expr></init></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>ParallelHashJoinBatch</name> <modifier>*</modifier></type><name>shared</name> <init>= <expr><call><name>NthParallelHashJoinBatch</name><argument_list>(<argument><expr><name>batches</name></expr></argument>, <argument><expr><name>i</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>

		<expr_stmt><expr><name><name>accessor</name><operator>-&gt;</operator><name>shared</name></name> <operator>=</operator> <name>shared</name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>accessor</name><operator>-&gt;</operator><name>preallocated</name></name> <operator>=</operator> <literal type="number">0</literal></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>accessor</name><operator>-&gt;</operator><name>done</name></name> <operator>=</operator> <name>false</name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>accessor</name><operator>-&gt;</operator><name>inner_tuples</name></name> <operator>=</operator>
			<call><name>sts_attach</name><argument_list>(<argument><expr><call><name>ParallelHashJoinBatchInner</name><argument_list>(<argument><expr><name>shared</name></expr></argument>)</argument_list></call></expr></argument>,
					   <argument><expr><name>ParallelWorkerNumber</name> <operator>+</operator> <literal type="number">1</literal></expr></argument>,
					   <argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>fileset</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>accessor</name><operator>-&gt;</operator><name>outer_tuples</name></name> <operator>=</operator>
			<call><name>sts_attach</name><argument_list>(<argument><expr><call><name>ParallelHashJoinBatchOuter</name><argument_list>(<argument><expr><name>shared</name></expr></argument>,
												  <argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>nparticipants</name></name></expr></argument>)</argument_list></call></expr></argument>,
					   <argument><expr><name>ParallelWorkerNumber</name> <operator>+</operator> <literal type="number">1</literal></expr></argument>,
					   <argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>fileset</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	</block_content>}</block></for>

	<expr_stmt><expr><call><name>MemoryContextSwitchTo</name><argument_list>(<argument><expr><name>oldcxt</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Allocate an empty shared memory hash table for a given batch.
 */</comment>
<function><type><name>void</name></type>
<name>ExecParallelHashTableAlloc</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>int</name></type> <name>batchno</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ParallelHashJoinBatch</name> <modifier>*</modifier></type><name>batch</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>shared</name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>dsa_pointer_atomic</name> <modifier>*</modifier></type><name>buckets</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>nbuckets</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

	<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>buckets</name></name> <operator>=</operator>
		<call><name>dsa_allocate</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><sizeof>sizeof<argument_list>(<argument><expr><name>dsa_pointer_atomic</name></expr></argument>)</argument_list></sizeof> <operator>*</operator> <name>nbuckets</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>buckets</name> <operator>=</operator> <operator>(</operator><name>dsa_pointer_atomic</name> <operator>*</operator><operator>)</operator>
		<call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>batch</name><operator>-&gt;</operator><name>buckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name>nbuckets</name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control><block type="pseudo"><block_content>
		<expr_stmt><expr><call><name>dsa_pointer_atomic_init</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>buckets</name><index>[<expr><name>i</name></expr>]</index></name></expr></argument>, <argument><expr><name>InvalidDsaPointer</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></for>
</block_content>}</block></function>

<comment type="block">/*
 * If we are currently attached to a shared hash join batch, detach.  If we
 * are last to detach, clean up.
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashTableDetachBatch</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name> <operator>!=</operator> <name>NULL</name> <operator>&amp;&amp;</operator>
		<name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name> <operator>&gt;=</operator> <literal type="number">0</literal></expr>)</condition>
	<block>{<block_content>
		<decl_stmt><decl><type><name>int</name></type>			<name>curbatch</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name></expr></init></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>ParallelHashJoinBatch</name> <modifier>*</modifier></type><name>batch</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>curbatch</name></expr>]</index></name><operator>.</operator><name>shared</name></expr></init></decl>;</decl_stmt>

		<comment type="block">/* Make sure any temporary files are closed. */</comment>
		<expr_stmt><expr><call><name>sts_end_parallel_scan</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>curbatch</name></expr>]</index></name><operator>.</operator><name>inner_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>sts_end_parallel_scan</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>curbatch</name></expr>]</index></name><operator>.</operator><name>outer_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/* Detach from the batch we were last working on. */</comment>
		<if_stmt><if>if <condition>(<expr><call><name>BarrierArriveAndDetach</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>batch</name><operator>-&gt;</operator><name>batch_barrier</name></name></expr></argument>)</argument_list></call></expr>)</condition>
		<block>{<block_content>
			<comment type="block">/*
			 * Technically we shouldn't access the barrier because we're no
			 * longer attached, but since there is no way it's moving after
			 * this point it seems safe to make the following assertion.
			 */</comment>
			<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><call><name>BarrierPhase</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>batch</name><operator>-&gt;</operator><name>batch_barrier</name></name></expr></argument>)</argument_list></call> <operator>==</operator> <name>PHJ_BATCH_DONE</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

			<comment type="block">/* Free shared chunks and buckets. */</comment>
			<while>while <condition>(<expr><call><name>DsaPointerIsValid</name><argument_list>(<argument><expr><name><name>batch</name><operator>-&gt;</operator><name>chunks</name></name></expr></argument>)</argument_list></call></expr>)</condition>
			<block>{<block_content>
				<decl_stmt><decl><type><name>HashMemoryChunk</name></type> <name>chunk</name> <init>=
				<expr><call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>batch</name><operator>-&gt;</operator><name>chunks</name></name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>
				<decl_stmt><decl><type><name>dsa_pointer</name></type> <name>next</name> <init>= <expr><name><name>chunk</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>shared</name></name></expr></init></decl>;</decl_stmt>

				<expr_stmt><expr><call><name>dsa_free</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>batch</name><operator>-&gt;</operator><name>chunks</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>chunks</name></name> <operator>=</operator> <name>next</name></expr>;</expr_stmt>
			</block_content>}</block></while>
			<if_stmt><if>if <condition>(<expr><call><name>DsaPointerIsValid</name><argument_list>(<argument><expr><name><name>batch</name><operator>-&gt;</operator><name>buckets</name></name></expr></argument>)</argument_list></call></expr>)</condition>
			<block>{<block_content>
				<expr_stmt><expr><call><name>dsa_free</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>batch</name><operator>-&gt;</operator><name>buckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>buckets</name></name> <operator>=</operator> <name>InvalidDsaPointer</name></expr>;</expr_stmt>
			</block_content>}</block></if></if_stmt>
		</block_content>}</block></if></if_stmt>

		<comment type="block">/*
		 * Track the largest batch we've been attached to.  Though each
		 * backend might see a different subset of batches, explain.c will
		 * scan the results from all backends to find the largest value.
		 */</comment>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name> <operator>=</operator>
			<call><name>Max</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>spacePeak</name></name></expr></argument>,
				<argument><expr><name><name>batch</name><operator>-&gt;</operator><name>size</name></name> <operator>+</operator> <sizeof>sizeof<argument_list>(<argument><expr><name>dsa_pointer_atomic</name></expr></argument>)</argument_list></sizeof> <operator>*</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<comment type="block">/* Remember that we are not attached to a batch. */</comment>
		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name> <operator>=</operator> <operator>-</operator><literal type="number">1</literal></expr>;</expr_stmt>
	</block_content>}</block></if></if_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Detach from all shared resources.  If we are last to detach, clean up.
 */</comment>
<function><type><name>void</name></type>
<name>ExecHashTableDetach</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr>)</condition>
	<block>{<block_content>
		<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></init></decl>;</decl_stmt>
		<decl_stmt><decl><type><name>int</name></type>			<name>i</name></decl>;</decl_stmt>

		<comment type="block">/* Make sure any temporary files are closed. */</comment>
		<if_stmt><if>if <condition>(<expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name></name></expr>)</condition>
		<block>{<block_content>
			<for>for <control>(<init><expr><name>i</name> <operator>=</operator> <literal type="number">0</literal></expr>;</init> <condition><expr><name>i</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr>;</condition> <incr><expr><operator>++</operator><name>i</name></expr></incr>)</control>
			<block>{<block_content>
				<expr_stmt><expr><call><name>sts_end_write</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name><operator>.</operator><name>inner_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>sts_end_write</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name><operator>.</operator><name>outer_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>sts_end_parallel_scan</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name><operator>.</operator><name>inner_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><call><name>sts_end_parallel_scan</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>i</name></expr>]</index></name><operator>.</operator><name>outer_tuples</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
			</block_content>}</block></for>
		</block_content>}</block></if></if_stmt>

		<comment type="block">/* If we're last to detach, clean up shared memory. */</comment>
		<if_stmt><if>if <condition>(<expr><call><name>BarrierDetach</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>build_barrier</name></name></expr></argument>)</argument_list></call></expr>)</condition>
		<block>{<block_content>
			<if_stmt><if>if <condition>(<expr><call><name>DsaPointerIsValid</name><argument_list>(<argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>batches</name></name></expr></argument>)</argument_list></call></expr>)</condition>
			<block>{<block_content>
				<expr_stmt><expr><call><name>dsa_free</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>batches</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
				<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>batches</name></name> <operator>=</operator> <name>InvalidDsaPointer</name></expr>;</expr_stmt>
			</block_content>}</block></if></if_stmt>
		</block_content>}</block></if></if_stmt>

		<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
	</block_content>}</block></if></if_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Get the first tuple in a given bucket identified by number.
 */</comment>
<function><type><specifier>static</specifier> <specifier>inline</specifier> <name>HashJoinTuple</name></type>
<name>ExecParallelHashFirstTuple</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>int</name></type> <name>bucketno</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>tuple</name></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>dsa_pointer</name></type> <name>p</name></decl>;</decl_stmt>

	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>p</name> <operator>=</operator> <call><name>dsa_pointer_atomic_read</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>shared</name><index>[<expr><name>bucketno</name></expr>]</index></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>tuple</name> <operator>=</operator> <operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name>p</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<return>return <expr><name>tuple</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * Get the next tuple in the same bucket as 'tuple'.
 */</comment>
<function><type><specifier>static</specifier> <specifier>inline</specifier> <name>HashJoinTuple</name></type>
<name>ExecParallelHashNextTuple</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>HashJoinTuple</name></type> <name>tuple</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>HashJoinTuple</name></type> <name>next</name></decl>;</decl_stmt>

	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name>next</name> <operator>=</operator> <operator>(</operator><name>HashJoinTuple</name><operator>)</operator> <call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><name><name>tuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>shared</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<return>return <expr><name>next</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * Insert a tuple at the front of a chain of tuples in DSA memory atomically.
 */</comment>
<function><type><specifier>static</specifier> <specifier>inline</specifier> <name>void</name></type>
<name>ExecParallelHashPushTuple</name><parameter_list>(<parameter><decl><type><name>dsa_pointer_atomic</name> <modifier>*</modifier></type><name>head</name></decl></parameter>,
						  <parameter><decl><type><name>HashJoinTuple</name></type> <name>tuple</name></decl></parameter>,
						  <parameter><decl><type><name>dsa_pointer</name></type> <name>tuple_shared</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<for>for <control>(<init>;</init><condition>;</condition><incr/>)</control>
	<block>{<block_content>
		<expr_stmt><expr><name><name>tuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>shared</name></name> <operator>=</operator> <call><name>dsa_pointer_atomic_read</name><argument_list>(<argument><expr><name>head</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<if_stmt><if>if <condition>(<expr><call><name>dsa_pointer_atomic_compare_exchange</name><argument_list>(<argument><expr><name>head</name></expr></argument>,
												<argument><expr><operator>&amp;</operator><name><name>tuple</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>shared</name></name></expr></argument>,
												<argument><expr><name>tuple_shared</name></expr></argument>)</argument_list></call></expr>)</condition><block type="pseudo"><block_content>
			<break>break;</break></block_content></block></if></if_stmt>
	</block_content>}</block></for>
</block_content>}</block></function>

<comment type="block">/*
 * Prepare to work on a given batch.
 */</comment>
<function><type><name>void</name></type>
<name>ExecParallelHashTableSetCurrentBatch</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>int</name></type> <name>batchno</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>buckets</name></name> <operator>!=</operator> <name>InvalidDsaPointer</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>curbatch</name></name> <operator>=</operator> <name>batchno</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>buckets</name><operator>.</operator><name>shared</name></name> <operator>=</operator> <operator>(</operator><name>dsa_pointer_atomic</name> <operator>*</operator><operator>)</operator>
		<call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>,
						<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name><name>shared</name><operator>-&gt;</operator><name>buckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name> <operator>=</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name><operator>-&gt;</operator><name>nbuckets</name></name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>log2_nbuckets</name></name> <operator>=</operator> <call><name>my_log2</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>nbuckets</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>current_chunk</name></name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>current_chunk_shared</name></name> <operator>=</operator> <name>InvalidDsaPointer</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name><operator>.</operator><name>at_least_one_chunk</name> <operator>=</operator> <name>false</name></expr>;</expr_stmt>
</block_content>}</block></function>

<comment type="block">/*
 * Take the next available chunk from the queue of chunks being worked on in
 * parallel.  Return NULL if there are none left.  Otherwise return a pointer
 * to the chunk, and set *shared to the DSA pointer to the chunk.
 */</comment>
<function><type><specifier>static</specifier> <name>HashMemoryChunk</name></type>
<name>ExecParallelHashPopChunkQueue</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>dsa_pointer</name> <modifier>*</modifier></type><name>shared</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>HashMemoryChunk</name></type> <name>chunk</name></decl>;</decl_stmt>

	<expr_stmt><expr><call><name>LWLockAcquire</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>, <argument><expr><name>LW_EXCLUSIVE</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<if_stmt><if>if <condition>(<expr><call><name>DsaPointerIsValid</name><argument_list>(<argument><expr><name><name>pstate</name><operator>-&gt;</operator><name>chunk_work_queue</name></name></expr></argument>)</argument_list></call></expr>)</condition>
	<block>{<block_content>
		<expr_stmt><expr><operator>*</operator><name>shared</name> <operator>=</operator> <name><name>pstate</name><operator>-&gt;</operator><name>chunk_work_queue</name></name></expr>;</expr_stmt>
		<expr_stmt><expr><name>chunk</name> <operator>=</operator> <operator>(</operator><name>HashMemoryChunk</name><operator>)</operator>
			<call><name>dsa_get_address</name><argument_list>(<argument><expr><name><name>hashtable</name><operator>-&gt;</operator><name>area</name></name></expr></argument>, <argument><expr><operator>*</operator><name>shared</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>chunk_work_queue</name></name> <operator>=</operator> <name><name>chunk</name><operator>-&gt;</operator><name>next</name><operator>.</operator><name>shared</name></name></expr>;</expr_stmt>
	</block_content>}</block></if>
	<else>else<block type="pseudo"><block_content>
		<expr_stmt><expr><name>chunk</name> <operator>=</operator> <name>NULL</name></expr>;</expr_stmt></block_content></block></else></if_stmt>
	<expr_stmt><expr><call><name>LWLockRelease</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<return>return <expr><name>chunk</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * Increase the space preallocated in this backend for a given inner batch by
 * at least a given amount.  This allows us to track whether a given batch
 * would fit in memory when loaded back in.  Also increase the number of
 * batches or buckets if required.
 *
 * This maintains a running estimation of how much space will be taken when we
 * load the batch back into memory by simulating the way chunks will be handed
 * out to workers.  It's not perfectly accurate because the tuples will be
 * packed into memory chunks differently by ExecParallelHashTupleAlloc(), but
 * it should be pretty close.  It tends to overestimate by a fraction of a
 * chunk per worker since all workers gang up to preallocate during hashing,
 * but workers tend to reload batches alone if there are enough to go around,
 * leaving fewer partially filled chunks.  This effect is bounded by
 * nparticipants.
 *
 * Return false if the number of batches or buckets has changed, and the
 * caller should reconsider which batch a given tuple now belongs in and call
 * again.
 */</comment>
<function><type><specifier>static</specifier> <name>bool</name></type>
<name>ExecParallelHashTuplePrealloc</name><parameter_list>(<parameter><decl><type><name>HashJoinTable</name></type> <name>hashtable</name></decl></parameter>, <parameter><decl><type><name>int</name></type> <name>batchno</name></decl></parameter>, <parameter><decl><type><name>size_t</name></type> <name>size</name></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>ParallelHashJoinState</name> <modifier>*</modifier></type><name>pstate</name> <init>= <expr><name><name>hashtable</name><operator>-&gt;</operator><name>parallel_state</name></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>ParallelHashJoinBatchAccessor</name> <modifier>*</modifier></type><name>batch</name> <init>= <expr><operator>&amp;</operator><name><name>hashtable</name><operator>-&gt;</operator><name>batches</name><index>[<expr><name>batchno</name></expr>]</index></name></expr></init></decl>;</decl_stmt>
	<decl_stmt><decl><type><name>size_t</name></type>		<name>want</name> <init>= <expr><call><name>Max</name><argument_list>(<argument><expr><name>size</name></expr></argument>, <argument><expr><name>HASH_CHUNK_SIZE</name> <operator>-</operator> <name>HASH_CHUNK_HEADER_SIZE</name></expr></argument>)</argument_list></call></expr></init></decl>;</decl_stmt>

	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>batchno</name> <operator>&gt;</operator> <literal type="number">0</literal></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>batchno</name> <operator>&lt;</operator> <name><name>hashtable</name><operator>-&gt;</operator><name>nbatch</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>Assert</name><argument_list>(<argument><expr><name>size</name> <operator>==</operator> <call><name>MAXALIGN</name><argument_list>(<argument><expr><name>size</name></expr></argument>)</argument_list></call></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<expr_stmt><expr><call><name>LWLockAcquire</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>, <argument><expr><name>LW_EXCLUSIVE</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<comment type="block">/* Has another participant commanded us to help grow? */</comment>
	<if_stmt><if>if <condition>(<expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>==</operator> <name>PHJ_GROWTH_NEED_MORE_BATCHES</name> <operator>||</operator>
		<name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>==</operator> <name>PHJ_GROWTH_NEED_MORE_BUCKETS</name></expr>)</condition>
	<block>{<block_content>
		<decl_stmt><decl><type><name>ParallelHashGrowth</name></type> <name>growth</name> <init>= <expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name></expr></init></decl>;</decl_stmt>

		<expr_stmt><expr><call><name>LWLockRelease</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>
		<if_stmt><if>if <condition>(<expr><name>growth</name> <operator>==</operator> <name>PHJ_GROWTH_NEED_MORE_BATCHES</name></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><call><name>ExecParallelHashIncreaseNumBatches</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if>
		<if type="elseif">else if <condition>(<expr><name>growth</name> <operator>==</operator> <name>PHJ_GROWTH_NEED_MORE_BUCKETS</name></expr>)</condition><block type="pseudo"><block_content>
			<expr_stmt><expr><call><name>ExecParallelHashIncreaseNumBuckets</name><argument_list>(<argument><expr><name>hashtable</name></expr></argument>)</argument_list></call></expr>;</expr_stmt></block_content></block></if></if_stmt>

		<return>return <expr><name>false</name></expr>;</return>
	</block_content>}</block></if></if_stmt>

	<if_stmt><if>if <condition>(<expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>!=</operator> <name>PHJ_GROWTH_DISABLED</name> <operator>&amp;&amp;</operator>
		<name><name>batch</name><operator>-&gt;</operator><name>at_least_one_chunk</name></name> <operator>&amp;&amp;</operator>
		<operator>(</operator><name><name>batch</name><operator>-&gt;</operator><name>shared</name><operator>-&gt;</operator><name>estimated_size</name></name> <operator>+</operator> <name>want</name> <operator>+</operator> <name>HASH_CHUNK_HEADER_SIZE</name>
		 <operator>&gt;</operator> <name><name>pstate</name><operator>-&gt;</operator><name>space_allowed</name></name><operator>)</operator></expr>)</condition>
	<block>{<block_content>
		<comment type="block">/*
		 * We have determined that this batch would exceed the space budget if
		 * loaded into memory.  Command all participants to help repartition.
		 */</comment>
		<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>shared</name><operator>-&gt;</operator><name>space_exhausted</name></name> <operator>=</operator> <name>true</name></expr>;</expr_stmt>
		<expr_stmt><expr><name><name>pstate</name><operator>-&gt;</operator><name>growth</name></name> <operator>=</operator> <name>PHJ_GROWTH_NEED_MORE_BATCHES</name></expr>;</expr_stmt>
		<expr_stmt><expr><call><name>LWLockRelease</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

		<return>return <expr><name>false</name></expr>;</return>
	</block_content>}</block></if></if_stmt>

	<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>at_least_one_chunk</name></name> <operator>=</operator> <name>true</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>shared</name><operator>-&gt;</operator><name>estimated_size</name></name> <operator>+=</operator> <name>want</name> <operator>+</operator> <name>HASH_CHUNK_HEADER_SIZE</name></expr>;</expr_stmt>
	<expr_stmt><expr><name><name>batch</name><operator>-&gt;</operator><name>preallocated</name></name> <operator>=</operator> <name>want</name></expr>;</expr_stmt>
	<expr_stmt><expr><call><name>LWLockRelease</name><argument_list>(<argument><expr><operator>&amp;</operator><name><name>pstate</name><operator>-&gt;</operator><name>lock</name></name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<return>return <expr><name>true</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * Calculate the limit on how much memory can be used by Hash and similar
 * plan types.  This is work_mem times hash_mem_multiplier, and is
 * expressed in bytes.
 *
 * Exported for use by the planner, as well as other hash-like executor
 * nodes.  This is a rather random place for this, but there is no better
 * place.
 */</comment>
<function><type><name>size_t</name></type>
<name>get_hash_memory_limit</name><parameter_list>(<parameter><decl><type><name>void</name></type></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>double</name></type>		<name>mem_limit</name></decl>;</decl_stmt>

	<comment type="block">/* Do initial calculation in double arithmetic */</comment>
	<expr_stmt><expr><name>mem_limit</name> <operator>=</operator> <operator>(</operator><name>double</name><operator>)</operator> <name>work_mem</name> <operator>*</operator> <name>hash_mem_multiplier</name> <operator>*</operator> <literal type="number">1024.0</literal></expr>;</expr_stmt>

	<comment type="block">/* Clamp in case it doesn't fit in size_t */</comment>
	<expr_stmt><expr><name>mem_limit</name> <operator>=</operator> <call><name>Min</name><argument_list>(<argument><expr><name>mem_limit</name></expr></argument>, <argument><expr><operator>(</operator><name>double</name><operator>)</operator> <name>SIZE_MAX</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<return>return <expr><operator>(</operator><name>size_t</name><operator>)</operator> <name>mem_limit</name></expr>;</return>
</block_content>}</block></function>

<comment type="block">/*
 * Convert the hash memory limit to an integer number of kilobytes,
 * that is something comparable to work_mem.  Like work_mem, we clamp
 * the result to ensure that multiplying it by 1024 fits in a long int.
 *
 * This is deprecated since it may understate the actual memory limit.
 * It is unused in core and will eventually be removed.
 */</comment>
<function><type><name>int</name></type>
<name>get_hash_mem</name><parameter_list>(<parameter><decl><type><name>void</name></type></decl></parameter>)</parameter_list>
<block>{<block_content>
	<decl_stmt><decl><type><name>size_t</name></type>		<name>mem_limit</name> <init>= <expr><call><name>get_hash_memory_limit</name><argument_list>()</argument_list></call></expr></init></decl>;</decl_stmt>

	<comment type="block">/* Remove the kilobyte factor */</comment>
	<expr_stmt><expr><name>mem_limit</name> <operator>/=</operator> <literal type="number">1024</literal></expr>;</expr_stmt>

	<comment type="block">/* Clamp to MAX_KILOBYTES, like work_mem */</comment>
	<expr_stmt><expr><name>mem_limit</name> <operator>=</operator> <call><name>Min</name><argument_list>(<argument><expr><name>mem_limit</name></expr></argument>, <argument><expr><operator>(</operator><name>size_t</name><operator>)</operator> <name>MAX_KILOBYTES</name></expr></argument>)</argument_list></call></expr>;</expr_stmt>

	<return>return <expr><operator>(</operator><name>int</name><operator>)</operator> <name>mem_limit</name></expr>;</return>
</block_content>}</block></function>
</unit>
